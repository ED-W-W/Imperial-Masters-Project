{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5945f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import chex\n",
    "import optax\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from typing import Sequence, NamedTuple, Any, Dict\n",
    "from flax.training.train_state import TrainState\n",
    "import distrax\n",
    "\n",
    "from jaxmarl import make\n",
    "from jaxmarl.wrappers.baselines import (\n",
    "    SMAXLogWrapper,\n",
    "    MPELogWrapper,\n",
    "    LogWrapper,\n",
    "    CTRolloutManager,\n",
    ")\n",
    "from jaxmarl.environments.smax import map_name_to_scenario, HeuristicEnemySMAX, LearnedPolicyEnemySMAX\n",
    "from jaxmarl.environments.smax.heuristic_enemy_smax_env import EnemySMAX\n",
    "from jaxmarl.viz.visualizer import Visualizer, SMAXVisualizer\n",
    "\n",
    "import functools\n",
    "from functools import partial\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qdax.core.map_elites import MAPElites\n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids, compute_euclidean_centroids, MapElitesRepertoire\n",
    "#import qdax.tasks.brax.v1 as environments\n",
    "#from qdax.tasks.brax.v1.env_creators import scoring_function_brax_envs as scoring_function\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.utils.plotting import plot_map_elites_results\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from qdax.core.emitters.repertoire_selectors.selector import Selector\n",
    "from qdax.core.emitters.qpg_emitter import QualityPGConfig, QualityPGEmitterState\n",
    "from qdax.tasks.brax.v1.envs.base_env import QDEnv\n",
    "\n",
    "from qdax.core.emitters.multi_emitter import MultiEmitter\n",
    "from qdax.core.containers.ga_repertoire import GARepertoire\n",
    "from qdax.core.containers.repertoire import Repertoire\n",
    "#from qdax.core.neuroevolution.losses.td3_loss import make_td3_loss_fn\n",
    "from qdax.core.emitters.emitter import Emitter\n",
    "#from qdax.core.neuroevolution.networks.networks import QModule\n",
    "#from qdax.core.neuroevolution.buffers.buffer import ReplayBuffer\n",
    "\n",
    "from qdax.core.emitters.pga_me_emitter import PGAMEConfig, PGAMEEmitter\n",
    "\n",
    "import flashbax as fbx\n",
    "## Brax version conflict with JaxMARL(0.10.3) and QDax(0.10.4 / 0.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff85aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Tuple\n",
    "from qdax.custom_types import (\n",
    "    Descriptor,\n",
    "    EnvState,\n",
    "    ExtraScores,\n",
    "    Fitness,\n",
    "    Genotype,\n",
    "    Observation,\n",
    "    Params,\n",
    "    RNGKey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac7fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {    \n",
    "    # valid for iql, vdn, qmix\n",
    "    \"TOTAL_TIMESTEPS\": 10e7, #1e7,\n",
    "    \"NUM_ENVS\": 16, #16,\n",
    "    \"NUM_STEPS\": 100,\n",
    "    \"BUFFER_SIZE\": 12000, #5000,\n",
    "    \"BUFFER_BATCH_SIZE\": 32,\n",
    "    \"HIDDEN_SIZE\": 256, #64, #512,\n",
    "    \"MIXER_EMBEDDING_DIM\": 16, #64,\n",
    "    \"MIXER_HYPERNET_HIDDEN_DIM\": 64, #256,\n",
    "    \"MIXER_INIT_SCALE\": 0.001,\n",
    "    \"EPS_START\": 1.0,\n",
    "    \"EPS_FINISH\": 0.05,\n",
    "    \"EPS_DECAY\": 0.1, # percentage of updates\n",
    "    \"MAX_GRAD_NORM\": 10,\n",
    "    \"TARGET_UPDATE_INTERVAL\": 1, #10,\n",
    "    \"TAU\": 0.1, #1.,\n",
    "    \"NUM_EPOCHS\": 8,\n",
    "    \"LR\": 0.00005,\n",
    "    \"LEARNING_STARTS\": 10000, # timesteps\n",
    "    \"LR_LINEAR_DECAY\": False,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"REW_SCALE\": 10., # scale the reward to the original scale of SMAC\n",
    "\n",
    "    # ENV\n",
    "    \"ENV_NAME\": \"HeuristicEnemySMAX\",\n",
    "    #\"MAP_NAME\": \"3s_vs_5z\",\n",
    "    #\"MAP_NAME\":\"smacv2_5_units\", # 5 random units for each size\n",
    "    \"MAP_NAME\": \"2s3z\",\n",
    "    #\"MAP_NAME\": \"5m_vs_6m\",\n",
    "    \"ENV_KWARGS\": {\n",
    "        \"see_enemy_actions\": True,\n",
    "        \"walls_cause_death\": True,\n",
    "        \"attack_mode\": \"closest\", # uncomment when using heuristic policy\n",
    "        #\"won_battle_bonus\": 10.0, # To test if increasing winning reward gets solution to beat enemy\n",
    "    },\n",
    "\n",
    "    \"NUM_SEEDS\": 1, # number of vmapped seeds (not used)\n",
    "    \"SEED\": 88,\n",
    "\n",
    "    \"HYP_TUNE\": False, # perform hyp tune\n",
    "\n",
    "    # evaluate\n",
    "    \"TEST_DURING_TRAINING\": False, #True,\n",
    "    \"TEST_INTERVAL\": 0.05, # as a fraction of updates, i.e. log every 5% of training process\n",
    "    \"TEST_NUM_STEPS\": 128,\n",
    "    \"TEST_NUM_ENVS\": 512, # number of episodes to average over, can affect performance\n",
    "}\n",
    "batch_size = 5# 128 # Num of offsprings \n",
    "#env_name = 'walker2d_uni'\n",
    "episode_length = config[\"NUM_STEPS\"] #128  # NUM_STEPS\n",
    "num_iterations = int(config[\"TOTAL_TIMESTEPS\"] / (batch_size * config[\"NUM_ENVS\"] * config[\"NUM_STEPS\"]))\n",
    "seed = 88 \n",
    "policy_hidden_layer_sizes = (128, 128, 128) #(64, 64)\n",
    "iso_sigma = 0.005 #0.005 \n",
    "line_sigma = 0.05 #0.05 \n",
    "num_init_cvt_samples = 20000 #50000 \n",
    "num_centroids = 1024 #1024 \n",
    "min_descriptor = 0. \n",
    "max_descriptor = 1.0 \n",
    "number_of_descriptors=2\n",
    "\n",
    "\n",
    "proportion_mutation_ga = 0.5 \n",
    "\n",
    "# IQL params\n",
    "env_batch_size = batch_size #100 \n",
    "replay_buffer_size = config[\"BUFFER_SIZE\"] #1000000 \n",
    "critic_hidden_layer_size = (256, 256) \n",
    "critic_learning_rate = 3e-4 \n",
    "greedy_learning_rate = 3e-4 \n",
    "policy_learning_rate = 0.00005 #1e-3 \n",
    "noise_clip = 0.5\n",
    "policy_noise = 0.2 \n",
    "discount = config[\"GAMMA\"] #0.99 \n",
    "reward_scaling = 1.0 \n",
    "transitions_batch_size = config[\"BUFFER_BATCH_SIZE\"] #256 \n",
    "soft_tau_update = 0.005\n",
    "num_critic_training_steps = 300 \n",
    "num_pg_training_steps = 10 #100 \n",
    "policy_delay = 2\n",
    "\n",
    "# Define the PG-emitter config\n",
    "@dataclass\n",
    "class CustomPGAMEConfig(PGAMEConfig):\n",
    "    num_envs: Any = None\n",
    "    num_steps: Any = None\n",
    "    target_update_interval: Any = None\n",
    "    tau: Any = None\n",
    "\n",
    "pga_emitter_config = CustomPGAMEConfig(\n",
    "    env_batch_size=env_batch_size,\n",
    "    batch_size=transitions_batch_size,\n",
    "    proportion_mutation_ga=proportion_mutation_ga,\n",
    "    critic_hidden_layer_size=critic_hidden_layer_size,\n",
    "    critic_learning_rate=critic_learning_rate,\n",
    "    greedy_learning_rate=greedy_learning_rate,\n",
    "    policy_learning_rate=policy_learning_rate,\n",
    "    noise_clip=noise_clip,\n",
    "    policy_noise=policy_noise,\n",
    "    discount=discount,\n",
    "    reward_scaling=reward_scaling,\n",
    "    replay_buffer_size=replay_buffer_size,\n",
    "    soft_tau_update=soft_tau_update,\n",
    "    num_critic_training_steps=num_critic_training_steps,\n",
    "    num_pg_training_steps=num_pg_training_steps,\n",
    "    policy_delay=policy_delay,\n",
    "\n",
    "    num_envs = config[\"NUM_ENVS\"],\n",
    "    num_steps = config[\"NUM_STEPS\"],\n",
    "    target_update_interval = config[\"TARGET_UPDATE_INTERVAL\"],\n",
    "    tau = config[\"TAU\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07479b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScannedRNN(nn.Module):\n",
    "\n",
    "    @partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"params\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"Applies the module.\"\"\"\n",
    "        rnn_state = carry\n",
    "        ins, resets = x\n",
    "        hidden_size = ins.shape[-1]\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, np.newaxis],\n",
    "            self.initialize_carry(hidden_size, *ins.shape[:-1]),\n",
    "            rnn_state,\n",
    "        )\n",
    "        new_rnn_state, y = nn.GRUCell(hidden_size)(rnn_state, ins)\n",
    "        return new_rnn_state, y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(hidden_size, *batch_size):\n",
    "        # Use a dummy key since the default state init fn is just zeros.\n",
    "        return nn.GRUCell(hidden_size, parent=None).initialize_carry(\n",
    "            jax.random.PRNGKey(0), (*batch_size, hidden_size)\n",
    "        )\n",
    "\n",
    "\n",
    "class RNNQNetwork(nn.Module):\n",
    "    # homogenous agent for parameters sharing, assumes all agents have same obs and action dim\n",
    "    action_dim: int\n",
    "    hidden_dim: int\n",
    "    init_scale: float = 1.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden, obs, dones):\n",
    "        embedding = nn.Dense(\n",
    "            self.hidden_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(obs)\n",
    "        embedding = nn.relu(embedding)\n",
    "\n",
    "        rnn_in = (embedding, dones)\n",
    "        hidden, embedding = ScannedRNN()(hidden, rnn_in)\n",
    "\n",
    "        q_vals = nn.Dense(\n",
    "            self.action_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(embedding)\n",
    "\n",
    "        return hidden, q_vals\n",
    "    \n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"HyperNetwork for generating weights of QMix' mixing network.\"\"\"\n",
    "\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(\n",
    "            self.hidden_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(\n",
    "            self.output_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        return x\n",
    "'''   \n",
    "# 1 layer hypernetwork\n",
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"HyperNetwork for generating weights of QMix' mixing network.\"\"\"\n",
    "\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(\n",
    "            self.output_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        return x\n",
    "'''\n",
    "\n",
    "class MixingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixing network for projecting individual agent Q-values into Q_tot. Follows the original QMix implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dim: int\n",
    "    hypernet_hidden_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, q_vals, states):\n",
    "\n",
    "        n_agents, time_steps, batch_size = q_vals.shape\n",
    "        q_vals = jnp.transpose(q_vals, (1, 2, 0))  # (time_steps, batch_size, n_agents)\n",
    "\n",
    "        # hypernetwork\n",
    "        w_1 = HyperNetwork(\n",
    "            hidden_dim=self.hypernet_hidden_dim,\n",
    "            output_dim=self.embedding_dim * n_agents,\n",
    "            init_scale=self.init_scale,\n",
    "        )(states)\n",
    "        b_1 = nn.Dense(\n",
    "            self.embedding_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(states)\n",
    "        w_2 = HyperNetwork(\n",
    "            hidden_dim=self.hypernet_hidden_dim,\n",
    "            output_dim=self.embedding_dim,\n",
    "            init_scale=self.init_scale,\n",
    "        )(states)\n",
    "        b_2 = HyperNetwork(\n",
    "            hidden_dim=self.embedding_dim, output_dim=1, init_scale=self.init_scale\n",
    "        )(states)\n",
    "\n",
    "        # monotonicity and reshaping\n",
    "        w_1 = jnp.abs(w_1.reshape(time_steps, batch_size, n_agents, self.embedding_dim))\n",
    "        b_1 = b_1.reshape(time_steps, batch_size, 1, self.embedding_dim)\n",
    "        w_2 = jnp.abs(w_2.reshape(time_steps, batch_size, self.embedding_dim, 1))\n",
    "        b_2 = b_2.reshape(time_steps, batch_size, 1, 1)\n",
    "\n",
    "        # mix\n",
    "        hidden = nn.elu(jnp.matmul(q_vals[:, :, None, :], w_1) + b_1)\n",
    "        q_tot = jnp.matmul(hidden, w_2) + b_2\n",
    "\n",
    "        return q_tot.squeeze()  # (time_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec87de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Transition(NamedTuple):\n",
    "#    global_done: jnp.ndarray\n",
    "#    done: jnp.ndarray\n",
    "#    action: jnp.ndarray\n",
    "#    reward: jnp.ndarray\n",
    "#    obs: jnp.ndarray\n",
    "#    env_state: jnp.ndarray\n",
    "#    info: jnp.ndarray\n",
    "#    avail_actions: jnp.ndarray\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    #global_done: jnp.ndarray\n",
    "    #reward: jnp.ndarray\n",
    "    env_state: jnp.ndarray\n",
    "    infos: jnp.ndarray\n",
    "\n",
    "@chex.dataclass(frozen=True)\n",
    "class Timestep:\n",
    "    obs: dict\n",
    "    actions: dict\n",
    "    rewards: dict\n",
    "    dones: dict\n",
    "    avail_actions: dict\n",
    "\n",
    "\n",
    "class CustomTrainState(TrainState):\n",
    "    target_network_params: Any\n",
    "    timesteps: int = 0\n",
    "    n_updates: int = 0\n",
    "    grad_steps: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051ce603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom flax.serialization import from_bytes\\n\\nclass ScannedRNNIPPO(nn.Module):\\n    @functools.partial(\\n        nn.scan,\\n        variable_broadcast=\"params\",\\n        in_axes=0,\\n        out_axes=0,\\n        split_rngs={\"params\": False},\\n    )\\n    @nn.compact\\n    def __call__(self, carry, x):\\n        \"\"\"Applies the module.\"\"\"\\n        rnn_state = carry\\n        ins, resets = x\\n        resets = jnp.atleast_1d(resets)\\n        rnn_state = jnp.where(\\n            resets[:, np.newaxis],\\n            self.initialize_carry(*rnn_state.shape),\\n            rnn_state,\\n        )\\n        new_rnn_state, y = nn.GRUCell(features=ins.shape[1])(rnn_state, ins)\\n        return new_rnn_state, y\\n\\n    @staticmethod\\n    def initialize_carry(batch_size, hidden_size):\\n        # Use a dummy key since the default state init fn is just zeros.\\n        cell = nn.GRUCell(features=hidden_size)\\n        return cell.initialize_carry(jax.random.PRNGKey(0), (batch_size, hidden_size))\\n\\n\\nclass ActorCriticRNN(nn.Module):\\n    action_dim: Sequence[int]\\n    config: Dict\\n\\n    @nn.compact\\n    def __call__(self, hidden, x):\\n        obs, dones, avail_actions = x\\n        embedding = nn.Dense(\\n            self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\\n        )(obs)\\n        embedding = nn.relu(embedding)\\n\\n        rnn_in = (embedding, dones)\\n        hidden, embedding = ScannedRNNIPPO(name=\"ScannedRNN_0\")(hidden, rnn_in)\\n\\n        actor_mean = nn.Dense(self.config[\"GRU_HIDDEN_DIM\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\\n            embedding\\n        )\\n        actor_mean = nn.relu(actor_mean)\\n        actor_mean = nn.Dense(\\n            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\\n        )(actor_mean)\\n        unavail_actions = 1 - avail_actions\\n        action_logits = actor_mean - (unavail_actions * 1e10)\\n\\n        pi = distrax.Categorical(logits=action_logits)\\n\\n        critic = nn.Dense(self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\\n            embedding\\n        )\\n        critic = nn.relu(critic)\\n        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\\n            critic\\n        )\\n\\n        return hidden, pi, jnp.squeeze(critic, axis=-1)\\n\\nippo_config = {\\n    \"LR\": 0.004,\\n    \"NUM_ENVS\": 128,\\n    \"NUM_STEPS\": 128,\\n    \"GRU_HIDDEN_DIM\": 128,\\n    \"FC_DIM_SIZE\": 128,\\n    \"TOTAL_TIMESTEPS\": 1e7,\\n    \"UPDATE_EPOCHS\": 4,\\n    \"NUM_MINIBATCHES\": 4,\\n    \"GAMMA\": 0.99,\\n    \"GAE_LAMBDA\": 0.95,\\n    \"CLIP_EPS\": 0.05,\\n    \"SCALE_CLIP_EPS\": False,\\n    \"ENT_COEF\": 0.01,\\n    \"VF_COEF\": 0.5,\\n    \"MAX_GRAD_NORM\": 0.25,\\n    \"ACTIVATION\": \"relu\",\\n    \"ENV_NAME\": \"HeuristicEnemySMAX\",\\n    \"MAP_NAME\": \"2s3z\",\\n    \"SEED\": 88,\\n    \"ENV_KWARGS\": {\\n        \"see_enemy_actions\": True,\\n        \"walls_cause_death\": True,\\n        \"attack_mode\": \"closest\"\\n    },\\n    \"ANNEAL_LR\": True,\\n}\\n\\n# Create dummy env\\nscenario = map_name_to_scenario(ippo_config[\"MAP_NAME\"])\\ndummy_env = HeuristicEnemySMAX(scenario=scenario, **ippo_config[\"ENV_KWARGS\"])\\ndummy_env = SMAXLogWrapper(dummy_env)\\n\\n# Create dummy model instance\\ndummy_network = ActorCriticRNN(dummy_env.action_space(dummy_env.agents[0]).n, config=ippo_config)\\n\\n# Prepare dummy input for param loading\\ndummy_hstate = ScannedRNNIPPO.initialize_carry(ippo_config[\"NUM_ENVS\"], ippo_config[\"GRU_HIDDEN_DIM\"])\\ndummy_obs = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.observation_space(dummy_env.agents[0]).shape[0]))\\ndummy_dones = jnp.zeros((1, ippo_config[\"NUM_ENVS\"]))\\ndummy_avail = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.action_space(dummy_env.agents[0]).n))\\ndummy_input = (dummy_obs, dummy_dones, dummy_avail)\\n\\n# Create dummy params to use as template\\nrng = jax.random.PRNGKey(0)\\ndummy_params = dummy_network.init(rng, dummy_hstate, dummy_input)\\n#trained_ippo_params = dummy_params\\n\\n# Load trained parameters\\nwith open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_ippo_params.msgpack\", \"rb\") as f:\\n    trained_ippo_params = from_bytes(dummy_params, f.read())\\nprint(\"Params loaded\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained IPPO policy\n",
    "'''\n",
    "from flax.serialization import from_bytes\n",
    "\n",
    "class ScannedRNNIPPO(nn.Module):\n",
    "    @functools.partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"params\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"Applies the module.\"\"\"\n",
    "        rnn_state = carry\n",
    "        ins, resets = x\n",
    "        resets = jnp.atleast_1d(resets)\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, np.newaxis],\n",
    "            self.initialize_carry(*rnn_state.shape),\n",
    "            rnn_state,\n",
    "        )\n",
    "        new_rnn_state, y = nn.GRUCell(features=ins.shape[1])(rnn_state, ins)\n",
    "        return new_rnn_state, y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(batch_size, hidden_size):\n",
    "        # Use a dummy key since the default state init fn is just zeros.\n",
    "        cell = nn.GRUCell(features=hidden_size)\n",
    "        return cell.initialize_carry(jax.random.PRNGKey(0), (batch_size, hidden_size))\n",
    "\n",
    "\n",
    "class ActorCriticRNN(nn.Module):\n",
    "    action_dim: Sequence[int]\n",
    "    config: Dict\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden, x):\n",
    "        obs, dones, avail_actions = x\n",
    "        embedding = nn.Dense(\n",
    "            self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(obs)\n",
    "        embedding = nn.relu(embedding)\n",
    "\n",
    "        rnn_in = (embedding, dones)\n",
    "        hidden, embedding = ScannedRNNIPPO(name=\"ScannedRNN_0\")(hidden, rnn_in)\n",
    "\n",
    "        actor_mean = nn.Dense(self.config[\"GRU_HIDDEN_DIM\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\n",
    "            embedding\n",
    "        )\n",
    "        actor_mean = nn.relu(actor_mean)\n",
    "        actor_mean = nn.Dense(\n",
    "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
    "        )(actor_mean)\n",
    "        unavail_actions = 1 - avail_actions\n",
    "        action_logits = actor_mean - (unavail_actions * 1e10)\n",
    "\n",
    "        pi = distrax.Categorical(logits=action_logits)\n",
    "\n",
    "        critic = nn.Dense(self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\n",
    "            embedding\n",
    "        )\n",
    "        critic = nn.relu(critic)\n",
    "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
    "            critic\n",
    "        )\n",
    "\n",
    "        return hidden, pi, jnp.squeeze(critic, axis=-1)\n",
    "    \n",
    "ippo_config = {\n",
    "    \"LR\": 0.004,\n",
    "    \"NUM_ENVS\": 128,\n",
    "    \"NUM_STEPS\": 128,\n",
    "    \"GRU_HIDDEN_DIM\": 128,\n",
    "    \"FC_DIM_SIZE\": 128,\n",
    "    \"TOTAL_TIMESTEPS\": 1e7,\n",
    "    \"UPDATE_EPOCHS\": 4,\n",
    "    \"NUM_MINIBATCHES\": 4,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"GAE_LAMBDA\": 0.95,\n",
    "    \"CLIP_EPS\": 0.05,\n",
    "    \"SCALE_CLIP_EPS\": False,\n",
    "    \"ENT_COEF\": 0.01,\n",
    "    \"VF_COEF\": 0.5,\n",
    "    \"MAX_GRAD_NORM\": 0.25,\n",
    "    \"ACTIVATION\": \"relu\",\n",
    "    \"ENV_NAME\": \"HeuristicEnemySMAX\",\n",
    "    \"MAP_NAME\": \"2s3z\",\n",
    "    \"SEED\": 88,\n",
    "    \"ENV_KWARGS\": {\n",
    "        \"see_enemy_actions\": True,\n",
    "        \"walls_cause_death\": True,\n",
    "        \"attack_mode\": \"closest\"\n",
    "    },\n",
    "    \"ANNEAL_LR\": True,\n",
    "}\n",
    "\n",
    "# Create dummy env\n",
    "scenario = map_name_to_scenario(ippo_config[\"MAP_NAME\"])\n",
    "dummy_env = HeuristicEnemySMAX(scenario=scenario, **ippo_config[\"ENV_KWARGS\"])\n",
    "dummy_env = SMAXLogWrapper(dummy_env)\n",
    "\n",
    "# Create dummy model instance\n",
    "dummy_network = ActorCriticRNN(dummy_env.action_space(dummy_env.agents[0]).n, config=ippo_config)\n",
    "\n",
    "# Prepare dummy input for param loading\n",
    "dummy_hstate = ScannedRNNIPPO.initialize_carry(ippo_config[\"NUM_ENVS\"], ippo_config[\"GRU_HIDDEN_DIM\"])\n",
    "dummy_obs = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.observation_space(dummy_env.agents[0]).shape[0]))\n",
    "dummy_dones = jnp.zeros((1, ippo_config[\"NUM_ENVS\"]))\n",
    "dummy_avail = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.action_space(dummy_env.agents[0]).n))\n",
    "dummy_input = (dummy_obs, dummy_dones, dummy_avail)\n",
    "\n",
    "# Create dummy params to use as template\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_params = dummy_network.init(rng, dummy_hstate, dummy_input)\n",
    "#trained_ippo_params = dummy_params\n",
    "\n",
    "# Load trained parameters\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_ippo_params.msgpack\", \"rb\") as f:\n",
    "    trained_ippo_params = from_bytes(dummy_params, f.read())\n",
    "print(\"Params loaded\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853d4116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dataclasses\\nfrom jaxmarl.environments.smax.smax_env import SMAX\\nfrom jaxmarl.environments.smax.smax_env import State as SMAXState\\nfrom jaxmarl.environments.multi_agent_env import MultiAgentEnv\\n\\nfrom flax import struct\\n\\n@struct.dataclass\\nclass State:\\n    # underlying jaxmarl env state\\n    state: ...\\n    # the enemy policy state. Needed for recurrent policies or\\n    # remembering details about previous observations for heuristics.\\n    enemy_policy_state: ...\\n\\nclass EnemySMAX(MultiAgentEnv):\\n    \"\"\"Class that presents the SMAX environment as a single-player\\n    (but still multi-agent) environment. Functions like a wrapper, but\\n    not linked with any of the wrapper code because that is used differently.\"\"\"\\n\\n\\n\\n    def __init__(self, **env_kwargs):\\n        self._env = SMAX(**env_kwargs)\\n        # only one team\\n        self.num_agents = self._env.num_allies\\n        self.num_enemies = self._env.num_enemies\\n        # want to provide a consistent API between this and SMAX\\n        self.num_allies = self._env.num_allies\\n        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\\n        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\\n        self.all_agents = self.agents + self.enemy_agents\\n        self.observation_spaces = {\\n            i: self._env.observation_spaces[i] for i in self.agents\\n        }\\n        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\\n\\n    def __getattr__(self, name: str):\\n        return getattr(self._env, name)\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\\n        key, reset_key = jax.random.split(key)\\n        obs, state = self._env.reset(reset_key)\\n        enemy_policy_state = self.get_enemy_policy_initial_state(key)\\n        new_obs = {agent: obs[agent] for agent in self.agents}\\n        new_obs[\"world_state\"] = obs[\"world_state\"]\\n        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\\n\\n    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\\n        raise NotImplementedError\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        raise NotImplementedError\\n\\n    @partial(jax.jit, static_argnums=(0, 4))\\n    def step_env(\\n        self,\\n        key: chex.PRNGKey,\\n        state: State,\\n        actions: Dict[str, chex.Array],\\n        get_state_sequence=False,\\n    ):\\n        jaxmarl_state = state.state\\n        obs = self._env.get_obs(jaxmarl_state)\\n        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\\n        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\\n\\n        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\\n        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\\n\\n        enemy_dones = {\\n            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\\n        }\\n        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\\n\\n        #enemy_x = (    \\n        #    enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\\n        #    enemy_dones[jnp.newaxis, :],    # [1, num_agents]\\n        #    enemy_avail_actions              # [1, num_agents, num_actions]\\n        #)\\n\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        key, action_key = jax.random.split(key)\\n        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n        #    action_key, state.enemy_policy_state, enemy_obs\\n        #)\\n        enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n            action_key, state.enemy_policy_state, enemy_obs, enemy_dones, enemy_avail_actions #enemy_x\\n        )\\n\\n        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \\n        actions = jnp.array([actions[i] for i in self.agents])\\n        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        #print(\"enemy_actions:\", enemy_actions)\\n        #print(\"actions shape:\", actions.shape)\\n        enemy_movement_actions, enemy_attack_actions = (\\n            self._env._decode_discrete_actions(enemy_actions)\\n        )\\n        if self._env.action_type == \"continuous\":\\n            cont_actions = jnp.zeros((len(self.all_agents), 4))\\n            cont_actions = cont_actions.at[: self.num_allies].set(actions)\\n            key, action_key = jax.random.split(key)\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_continuous_actions(\\n                    action_key, jaxmarl_state, cont_actions\\n                )\\n            )\\n            ally_movement_actions = ally_movement_actions[: self.num_allies]\\n            ally_attack_actions = ally_attack_actions[: self.num_allies]\\n        else:\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_discrete_actions(actions)\\n            )\\n\\n        movement_actions = jnp.concatenate(\\n            [ally_movement_actions, enemy_movement_actions], axis=0\\n        )\\n        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\\n\\n        if not get_state_sequence:\\n            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            new_obs = {agent: obs[agent] for agent in self.agents}\\n            new_obs[\"world_state\"] = obs[\"world_state\"]\\n            rewards = {agent: rewards[agent] for agent in self.agents}\\n            all_done = dones[\"__all__\"]\\n            dones = {agent: dones[agent] for agent in self.agents}\\n            dones[\"__all__\"] = all_done\\n\\n            state = state.replace(\\n                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\\n            )\\n            return new_obs, state, rewards, dones, infos\\n        else:\\n            states = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            return states\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def get_avail_actions(self, state: State):\\n        avail_actions = self._env.get_avail_actions(state.state)\\n        return {agent: avail_actions[agent] for agent in self.agents}\\n\\n    def get_all_unit_obs(self, state: State):\\n        return self._env.get_obs(state.state)\\n\\n    def get_obs(self, state: State) -> Dict[str, chex.Array]:\\n        obs = self.get_all_unit_obs(state)\\n        return {agent: obs[agent] for agent in self.agents}\\n\\n    def get_world_state(self, state: State):\\n        return self._env.get_world_state(state.state)\\n\\n    def is_terminal(self, state: State):\\n        return self._env.is_terminal(state.state)\\n\\n    def expand_state_seq(self, state_seq):\\n        # TODO jit/scan this\\n        expanded_state_seq = []\\n\\n        # TODO this actually can\\'t take a key because recording this key is really hard\\n        # it\\'s not exposed to the user so we can\\'t ask them to store it. Not a problem\\n        # for now but will have to get creative in the future potentially.\\n        for key, state, actions in state_seq:\\n            # There is a split in the step function of MultiAgentEnv\\n            # We call split here so that the action key is the same.\\n            key, _ = jax.random.split(key)\\n            states = self.step_env(key, state, actions, get_state_sequence=True)\\n            states = list(map(SMAXState, *dataclasses.astuple(states)))\\n            viz_actions = {\\n                agent: states[-1].prev_attack_actions[i]\\n                for i, agent in enumerate(self.all_agents)\\n            }\\n\\n            expanded_state_seq.append((key, state.state, viz_actions))\\n            expanded_state_seq.extend(\\n                zip([key] * len(states), states, [viz_actions] * len(states))\\n            )\\n            state = state.replace(\\n                state=state.state.replace(terminal=self.is_terminal(state))\\n            )\\n        return expanded_state_seq\\n\\n\\n# wrapper for creation of env playing against user specified policy\\nclass LearnedPolicyEnemySMAX(EnemySMAX):\\n    def __init__(self, policy, params, config, **env_kwargs):\\n        super().__init__(**env_kwargs)\\n        self.policy = policy\\n        self.params = params\\n        #self.hstate = hstate\\n        self.config = config\\n\\n\\n    def preprocess_obs_with_id(self, enemy_obs):\\n        \"\"\"Add one-hot agent ID encoding to enemy obs.\"\"\"\\n        num_enemies = self._env.num_enemies\\n        new_obs = []\\n        for i, obs in enumerate(enemy_obs):\\n            one_hot = jax.nn.one_hot(i, num_classes=num_enemies)\\n            new_obs.append(jnp.concatenate([obs, one_hot]))\\n        return jnp.stack(new_obs)  # shape: [num_enemies, obs_dim + num_enemies]\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        #self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\\n        self.hstate = ScannedRNN.initialize_carry(config[\"HIDDEN_SIZE\"], self._env.num_enemies) # use num envs from config instead of ippo_config\\n        return (self.params, self.hstate)\\n\\n    def mirror_obs_unit_list(self, obs_array):\\n        \"\"\"Mirror enemy obs to ally POV.\"\"\"\\n        obs_dim = obs_array.shape[-1]\\n        num_units_other = (self.num_enemies - 1) + self.num_allies\\n        unit_feat_len = len(self._env.unit_features)\\n        own_feat_len = len(self._env.own_features)\\n\\n        # Split into \"other units\" block and \"own\" block\\n        other_units_flat = obs_array[..., :num_units_other * unit_feat_len]\\n        own_block = obs_array[..., num_units_other * unit_feat_len:]\\n\\n        # Reshape to [num_units_other, unit_feat_len]\\n        other_units = other_units_flat.reshape(obs_array.shape[0], num_units_other, unit_feat_len)\\n\\n        # Flip X-related features\\n        x_idx = self._env.unit_features.index(\"position_x\")\\n        last_x_idx = self._env.unit_features.index(\"last_movement_x\")\\n        other_units = other_units.at[..., x_idx].set(1.0 - other_units[..., x_idx])\\n        other_units = other_units.at[..., last_x_idx].set(-other_units[..., last_x_idx])\\n\\n        # Reverse order to swap ally/enemy view\\n        other_units = other_units[..., ::-1, :]\\n\\n        # Mirror own features\\n        own_feats = own_block\\n        ox_idx = self._env.own_features.index(\"position_x\")\\n        own_feats = own_feats.at[..., ox_idx].set(1.0 - own_feats[..., ox_idx])\\n\\n        # Recombine\\n        mirrored = jnp.concatenate([other_units.reshape(obs_array.shape[0], -1), own_feats], axis=-1)\\n        return mirrored\\n\\n    def mirror_policy_to_env_actions_no_attack_mirror(self, policy_actions):\\n        \"\"\"\\n        Mirror movement only. Keep attack indices as-is.\\n        \"\"\"\\n        num_move = self._env.num_movement_actions  # 5\\n        # Movement mapping for 0:N, 1:E, 2:S, 3:W, 4:Stop\\n        move_map = jnp.array([0, 3, 2, 1, num_move - 1], dtype=jnp.int32)\\n\\n        is_move = policy_actions < num_move\\n        mapped_moves = move_map[policy_actions]\\n\\n        # Attacks are unchanged\\n        mapped_attacks = policy_actions\\n\\n        env_actions = jnp.where(is_move, mapped_moves, mapped_attacks)\\n        return env_actions.astype(jnp.int32)\\n\\n    def get_enemy_actions(self, key, policy_state, enemy_obs, enemy_dones, enemy_avail_actions): #enemy_x):\\n        params, hstate = policy_state\\n\\n        # mirror the obs\\n        enemy_obs = self.mirror_obs_unit_list(enemy_obs)\\n        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\\n        enemy_obs = self.preprocess_obs_with_id(enemy_obs)\\n        #enemy_obs = jnp.array(enemy_obs)  # ensure JAX array\\n        enemy_obs = enemy_obs[jnp.newaxis, :]  # shape [1, num_enemies, obs_dim + num_enemies]\\n\\n        #enemy_dones = jnp.array(enemy_dones)  # ensure JAX array\\n        enemy_dones = enemy_dones[jnp.newaxis, :]  # [1, num_enemies]\\n        #enemy_avail_actions = jnp.array(enemy_avail_actions)  # ensure JAX array\\n        enemy_avail_actions = enemy_avail_actions[jnp.newaxis, :]  # [1, num_enemies, num_actions]\\n\\n        #print(\"hstate shape:\", hstate.shape)\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        #pi, _ = self.policy.apply(policy_state, enemy_obs)\\n        hstate, q_vals = self.policy.apply(params, hstate, enemy_obs, enemy_dones) #enemy_x)\\n        #print(\"q_val shape:\", q_vals.shape)\\n\\n        unavail_actions = 1 - enemy_avail_actions\\n        q_vals = q_vals - (unavail_actions * 1e10)\\n        enemy_actions = jnp.argmax(q_vals, axis=-1).squeeze(0)\\n\\n        # Mirror the actions\\n        enemy_actions = self.mirror_policy_to_env_actions_no_attack_mirror(enemy_actions)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        enemy_actions = {\\n            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\\n            for agent in self.enemy_agents\\n        }\\n        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\\n        policy_state = (params, hstate)\\n        return enemy_actions, policy_state\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for the RNNActor policy network\n",
    "'''\n",
    "import dataclasses\n",
    "from jaxmarl.environments.smax.smax_env import SMAX\n",
    "from jaxmarl.environments.smax.smax_env import State as SMAXState\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "from flax import struct\n",
    "\n",
    "@struct.dataclass\n",
    "class State:\n",
    "    # underlying jaxmarl env state\n",
    "    state: ...\n",
    "    # the enemy policy state. Needed for recurrent policies or\n",
    "    # remembering details about previous observations for heuristics.\n",
    "    enemy_policy_state: ...\n",
    "\n",
    "class EnemySMAX(MultiAgentEnv):\n",
    "    \"\"\"Class that presents the SMAX environment as a single-player\n",
    "    (but still multi-agent) environment. Functions like a wrapper, but\n",
    "    not linked with any of the wrapper code because that is used differently.\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, **env_kwargs):\n",
    "        self._env = SMAX(**env_kwargs)\n",
    "        # only one team\n",
    "        self.num_agents = self._env.num_allies\n",
    "        self.num_enemies = self._env.num_enemies\n",
    "        # want to provide a consistent API between this and SMAX\n",
    "        self.num_allies = self._env.num_allies\n",
    "        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\n",
    "        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\n",
    "        self.all_agents = self.agents + self.enemy_agents\n",
    "        self.observation_spaces = {\n",
    "            i: self._env.observation_spaces[i] for i in self.agents\n",
    "        }\n",
    "        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\n",
    "        key, reset_key = jax.random.split(key)\n",
    "        obs, state = self._env.reset(reset_key)\n",
    "        enemy_policy_state = self.get_enemy_policy_initial_state(key)\n",
    "        new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "        new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\n",
    "\n",
    "    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0, 4))\n",
    "    def step_env(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: State,\n",
    "        actions: Dict[str, chex.Array],\n",
    "        get_state_sequence=False,\n",
    "    ):\n",
    "        jaxmarl_state = state.state\n",
    "        obs = self._env.get_obs(jaxmarl_state)\n",
    "        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\n",
    "        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\n",
    "        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_dones = {\n",
    "            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\n",
    "        \n",
    "        #enemy_x = (    \n",
    "        #    enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\n",
    "        #    enemy_dones[jnp.newaxis, :],    # [1, num_agents]\n",
    "        #    enemy_avail_actions              # [1, num_agents, num_actions]\n",
    "        #)\n",
    "\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "\n",
    "        key, action_key = jax.random.split(key)\n",
    "        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "        #    action_key, state.enemy_policy_state, enemy_obs\n",
    "        #)\n",
    "        enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "            action_key, state.enemy_policy_state, enemy_obs, enemy_dones, enemy_avail_actions #enemy_x\n",
    "        )\n",
    "        \n",
    "        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \n",
    "        actions = jnp.array([actions[i] for i in self.agents])\n",
    "        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        #print(\"enemy_actions:\", enemy_actions)\n",
    "        #print(\"actions shape:\", actions.shape)\n",
    "        enemy_movement_actions, enemy_attack_actions = (\n",
    "            self._env._decode_discrete_actions(enemy_actions)\n",
    "        )\n",
    "        if self._env.action_type == \"continuous\":\n",
    "            cont_actions = jnp.zeros((len(self.all_agents), 4))\n",
    "            cont_actions = cont_actions.at[: self.num_allies].set(actions)\n",
    "            key, action_key = jax.random.split(key)\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_continuous_actions(\n",
    "                    action_key, jaxmarl_state, cont_actions\n",
    "                )\n",
    "            )\n",
    "            ally_movement_actions = ally_movement_actions[: self.num_allies]\n",
    "            ally_attack_actions = ally_attack_actions[: self.num_allies]\n",
    "        else:\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_discrete_actions(actions)\n",
    "            )\n",
    "\n",
    "        movement_actions = jnp.concatenate(\n",
    "            [ally_movement_actions, enemy_movement_actions], axis=0\n",
    "        )\n",
    "        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\n",
    "\n",
    "        if not get_state_sequence:\n",
    "            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "            new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "            rewards = {agent: rewards[agent] for agent in self.agents}\n",
    "            all_done = dones[\"__all__\"]\n",
    "            dones = {agent: dones[agent] for agent in self.agents}\n",
    "            dones[\"__all__\"] = all_done\n",
    "\n",
    "            state = state.replace(\n",
    "                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\n",
    "            )\n",
    "            return new_obs, state, rewards, dones, infos\n",
    "        else:\n",
    "            states = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            return states\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def get_avail_actions(self, state: State):\n",
    "        avail_actions = self._env.get_avail_actions(state.state)\n",
    "        return {agent: avail_actions[agent] for agent in self.agents}\n",
    "\n",
    "    def get_all_unit_obs(self, state: State):\n",
    "        return self._env.get_obs(state.state)\n",
    "\n",
    "    def get_obs(self, state: State) -> Dict[str, chex.Array]:\n",
    "        obs = self.get_all_unit_obs(state)\n",
    "        return {agent: obs[agent] for agent in self.agents}\n",
    "\n",
    "    def get_world_state(self, state: State):\n",
    "        return self._env.get_world_state(state.state)\n",
    "\n",
    "    def is_terminal(self, state: State):\n",
    "        return self._env.is_terminal(state.state)\n",
    "\n",
    "    def expand_state_seq(self, state_seq):\n",
    "        # TODO jit/scan this\n",
    "        expanded_state_seq = []\n",
    "\n",
    "        # TODO this actually can't take a key because recording this key is really hard\n",
    "        # it's not exposed to the user so we can't ask them to store it. Not a problem\n",
    "        # for now but will have to get creative in the future potentially.\n",
    "        for key, state, actions in state_seq:\n",
    "            # There is a split in the step function of MultiAgentEnv\n",
    "            # We call split here so that the action key is the same.\n",
    "            key, _ = jax.random.split(key)\n",
    "            states = self.step_env(key, state, actions, get_state_sequence=True)\n",
    "            states = list(map(SMAXState, *dataclasses.astuple(states)))\n",
    "            viz_actions = {\n",
    "                agent: states[-1].prev_attack_actions[i]\n",
    "                for i, agent in enumerate(self.all_agents)\n",
    "            }\n",
    "\n",
    "            expanded_state_seq.append((key, state.state, viz_actions))\n",
    "            expanded_state_seq.extend(\n",
    "                zip([key] * len(states), states, [viz_actions] * len(states))\n",
    "            )\n",
    "            state = state.replace(\n",
    "                state=state.state.replace(terminal=self.is_terminal(state))\n",
    "            )\n",
    "        return expanded_state_seq\n",
    "\n",
    "\n",
    "# wrapper for creation of env playing against user specified policy\n",
    "class LearnedPolicyEnemySMAX(EnemySMAX):\n",
    "    def __init__(self, policy, params, config, **env_kwargs):\n",
    "        super().__init__(**env_kwargs)\n",
    "        self.policy = policy\n",
    "        self.params = params\n",
    "        #self.hstate = hstate\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def preprocess_obs_with_id(self, enemy_obs):\n",
    "        \"\"\"Add one-hot agent ID encoding to enemy obs.\"\"\"\n",
    "        num_enemies = self._env.num_enemies\n",
    "        new_obs = []\n",
    "        for i, obs in enumerate(enemy_obs):\n",
    "            one_hot = jax.nn.one_hot(i, num_classes=num_enemies)\n",
    "            new_obs.append(jnp.concatenate([obs, one_hot]))\n",
    "        return jnp.stack(new_obs)  # shape: [num_enemies, obs_dim + num_enemies]\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        #self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "        self.hstate = ScannedRNN.initialize_carry(config[\"HIDDEN_SIZE\"], self._env.num_enemies) # use num envs from config instead of ippo_config\n",
    "        return (self.params, self.hstate)\n",
    "    \n",
    "    def mirror_obs_unit_list(self, obs_array):\n",
    "        \"\"\"Mirror enemy obs to ally POV.\"\"\"\n",
    "        obs_dim = obs_array.shape[-1]\n",
    "        num_units_other = (self.num_enemies - 1) + self.num_allies\n",
    "        unit_feat_len = len(self._env.unit_features)\n",
    "        own_feat_len = len(self._env.own_features)\n",
    "\n",
    "        # Split into \"other units\" block and \"own\" block\n",
    "        other_units_flat = obs_array[..., :num_units_other * unit_feat_len]\n",
    "        own_block = obs_array[..., num_units_other * unit_feat_len:]\n",
    "\n",
    "        # Reshape to [num_units_other, unit_feat_len]\n",
    "        other_units = other_units_flat.reshape(obs_array.shape[0], num_units_other, unit_feat_len)\n",
    "\n",
    "        # Flip X-related features\n",
    "        x_idx = self._env.unit_features.index(\"position_x\")\n",
    "        last_x_idx = self._env.unit_features.index(\"last_movement_x\")\n",
    "        other_units = other_units.at[..., x_idx].set(1.0 - other_units[..., x_idx])\n",
    "        other_units = other_units.at[..., last_x_idx].set(-other_units[..., last_x_idx])\n",
    "\n",
    "        # Reverse order to swap ally/enemy view\n",
    "        other_units = other_units[..., ::-1, :]\n",
    "\n",
    "        # Mirror own features\n",
    "        own_feats = own_block\n",
    "        ox_idx = self._env.own_features.index(\"position_x\")\n",
    "        own_feats = own_feats.at[..., ox_idx].set(1.0 - own_feats[..., ox_idx])\n",
    "\n",
    "        # Recombine\n",
    "        mirrored = jnp.concatenate([other_units.reshape(obs_array.shape[0], -1), own_feats], axis=-1)\n",
    "        return mirrored\n",
    "    \n",
    "    def mirror_policy_to_env_actions_no_attack_mirror(self, policy_actions):\n",
    "        \"\"\"\n",
    "        Mirror movement only. Keep attack indices as-is.\n",
    "        \"\"\"\n",
    "        num_move = self._env.num_movement_actions  # 5\n",
    "        # Movement mapping for 0:N, 1:E, 2:S, 3:W, 4:Stop\n",
    "        move_map = jnp.array([0, 3, 2, 1, num_move - 1], dtype=jnp.int32)\n",
    "\n",
    "        is_move = policy_actions < num_move\n",
    "        mapped_moves = move_map[policy_actions]\n",
    "\n",
    "        # Attacks are unchanged\n",
    "        mapped_attacks = policy_actions\n",
    "\n",
    "        env_actions = jnp.where(is_move, mapped_moves, mapped_attacks)\n",
    "        return env_actions.astype(jnp.int32)\n",
    "\n",
    "    def get_enemy_actions(self, key, policy_state, enemy_obs, enemy_dones, enemy_avail_actions): #enemy_x):\n",
    "        params, hstate = policy_state\n",
    "\n",
    "        # mirror the obs\n",
    "        enemy_obs = self.mirror_obs_unit_list(enemy_obs)\n",
    "        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\n",
    "        enemy_obs = self.preprocess_obs_with_id(enemy_obs)\n",
    "        #enemy_obs = jnp.array(enemy_obs)  # ensure JAX array\n",
    "        enemy_obs = enemy_obs[jnp.newaxis, :]  # shape [1, num_enemies, obs_dim + num_enemies]\n",
    "\n",
    "        #enemy_dones = jnp.array(enemy_dones)  # ensure JAX array\n",
    "        enemy_dones = enemy_dones[jnp.newaxis, :]  # [1, num_enemies]\n",
    "        #enemy_avail_actions = jnp.array(enemy_avail_actions)  # ensure JAX array\n",
    "        enemy_avail_actions = enemy_avail_actions[jnp.newaxis, :]  # [1, num_enemies, num_actions]\n",
    "\n",
    "        #print(\"hstate shape:\", hstate.shape)\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        #pi, _ = self.policy.apply(policy_state, enemy_obs)\n",
    "        hstate, q_vals = self.policy.apply(params, hstate, enemy_obs, enemy_dones) #enemy_x)\n",
    "        #print(\"q_val shape:\", q_vals.shape)\n",
    "\n",
    "        unavail_actions = 1 - enemy_avail_actions\n",
    "        q_vals = q_vals - (unavail_actions * 1e10)\n",
    "        enemy_actions = jnp.argmax(q_vals, axis=-1).squeeze(0)\n",
    "        \n",
    "        # Mirror the actions\n",
    "        enemy_actions = self.mirror_policy_to_env_actions_no_attack_mirror(enemy_actions)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        enemy_actions = {\n",
    "            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\n",
    "            for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\n",
    "        policy_state = (params, hstate)\n",
    "        return enemy_actions, policy_state\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bdd397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dataclasses\\nfrom jaxmarl.environments.smax.smax_env import SMAX\\nfrom jaxmarl.environments.smax.smax_env import State as SMAXState\\nfrom jaxmarl.environments.multi_agent_env import MultiAgentEnv\\n\\nfrom flax import struct\\n\\n@struct.dataclass\\nclass State:\\n    # underlying jaxmarl env state\\n    state: ...\\n    # the enemy policy state. Needed for recurrent policies or\\n    # remembering details about previous observations for heuristics.\\n    enemy_policy_state: ...\\n\\nclass EnemySMAX(MultiAgentEnv):\\n    \"\"\"Class that presents the SMAX environment as a single-player\\n    (but still multi-agent) environment. Functions like a wrapper, but\\n    not linked with any of the wrapper code because that is used differently.\"\"\"\\n\\n\\n\\n    def __init__(self, **env_kwargs):\\n        self._env = SMAX(**env_kwargs)\\n        # only one team\\n        self.num_agents = self._env.num_allies\\n        self.num_enemies = self._env.num_enemies\\n        # want to provide a consistent API between this and SMAX\\n        self.num_allies = self._env.num_allies\\n        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\\n        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\\n        self.all_agents = self.agents + self.enemy_agents\\n        self.observation_spaces = {\\n            i: self._env.observation_spaces[i] for i in self.agents\\n        }\\n        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\\n\\n    def __getattr__(self, name: str):\\n        return getattr(self._env, name)\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\\n        key, reset_key = jax.random.split(key)\\n        obs, state = self._env.reset(reset_key)\\n        enemy_policy_state = self.get_enemy_policy_initial_state(key)\\n        new_obs = {agent: obs[agent] for agent in self.agents}\\n        new_obs[\"world_state\"] = obs[\"world_state\"]\\n        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\\n\\n    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\\n        raise NotImplementedError\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        raise NotImplementedError\\n\\n    @partial(jax.jit, static_argnums=(0, 4))\\n    def step_env(\\n        self,\\n        key: chex.PRNGKey,\\n        state: State,\\n        actions: Dict[str, chex.Array],\\n        get_state_sequence=False,\\n    ):\\n        jaxmarl_state = state.state\\n        obs = self._env.get_obs(jaxmarl_state)\\n        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\\n        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\\n\\n        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\\n        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\\n\\n        enemy_dones = {\\n            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\\n        }\\n        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\\n\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        enemy_x = (    \\n            enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\\n            enemy_dones[jnp.newaxis, :],    # [1, num_agents]\\n            enemy_avail_actions              # [1, num_agents, num_actions]\\n        )\\n\\n        key, action_key = jax.random.split(key)\\n        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n        #    action_key, state.enemy_policy_state, enemy_obs\\n        #)\\n        enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n            action_key, state.enemy_policy_state, enemy_x\\n        )\\n\\n        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \\n        actions = jnp.array([actions[i] for i in self.agents])\\n        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        #print(\"enemy_actions:\", enemy_actions)\\n        #print(\"actions shape:\", actions.shape)\\n        enemy_movement_actions, enemy_attack_actions = (\\n            self._env._decode_discrete_actions(enemy_actions)\\n        )\\n        if self._env.action_type == \"continuous\":\\n            cont_actions = jnp.zeros((len(self.all_agents), 4))\\n            cont_actions = cont_actions.at[: self.num_allies].set(actions)\\n            key, action_key = jax.random.split(key)\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_continuous_actions(\\n                    action_key, jaxmarl_state, cont_actions\\n                )\\n            )\\n            ally_movement_actions = ally_movement_actions[: self.num_allies]\\n            ally_attack_actions = ally_attack_actions[: self.num_allies]\\n        else:\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_discrete_actions(actions)\\n            )\\n\\n        movement_actions = jnp.concatenate(\\n            [ally_movement_actions, enemy_movement_actions], axis=0\\n        )\\n        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\\n\\n        if not get_state_sequence:\\n            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            new_obs = {agent: obs[agent] for agent in self.agents}\\n            new_obs[\"world_state\"] = obs[\"world_state\"]\\n            rewards = {agent: rewards[agent] for agent in self.agents}\\n            all_done = dones[\"__all__\"]\\n            dones = {agent: dones[agent] for agent in self.agents}\\n            dones[\"__all__\"] = all_done\\n\\n            state = state.replace(\\n                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\\n            )\\n            return new_obs, state, rewards, dones, infos\\n        else:\\n            states = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            return states\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def get_avail_actions(self, state: State):\\n        avail_actions = self._env.get_avail_actions(state.state)\\n        return {agent: avail_actions[agent] for agent in self.agents}\\n\\n    def get_all_unit_obs(self, state: State):\\n        return self._env.get_obs(state.state)\\n\\n    def get_obs(self, state: State) -> Dict[str, chex.Array]:\\n        obs = self.get_all_unit_obs(state)\\n        return {agent: obs[agent] for agent in self.agents}\\n\\n    def get_world_state(self, state: State):\\n        return self._env.get_world_state(state.state)\\n\\n    def is_terminal(self, state: State):\\n        return self._env.is_terminal(state.state)\\n\\n    def expand_state_seq(self, state_seq):\\n        # TODO jit/scan this\\n        expanded_state_seq = []\\n\\n        # TODO this actually can\\'t take a key because recording this key is really hard\\n        # it\\'s not exposed to the user so we can\\'t ask them to store it. Not a problem\\n        # for now but will have to get creative in the future potentially.\\n        for key, state, actions in state_seq:\\n            # There is a split in the step function of MultiAgentEnv\\n            # We call split here so that the action key is the same.\\n            key, _ = jax.random.split(key)\\n            states = self.step_env(key, state, actions, get_state_sequence=True)\\n            states = list(map(SMAXState, *dataclasses.astuple(states)))\\n            viz_actions = {\\n                agent: states[-1].prev_attack_actions[i]\\n                for i, agent in enumerate(self.all_agents)\\n            }\\n\\n            expanded_state_seq.append((key, state.state, viz_actions))\\n            expanded_state_seq.extend(\\n                zip([key] * len(states), states, [viz_actions] * len(states))\\n            )\\n            state = state.replace(\\n                state=state.state.replace(terminal=self.is_terminal(state))\\n            )\\n        return expanded_state_seq\\n\\n\\n\\n# wrapper for creation of env playing against user specified policy\\nclass LearnedPolicyEnemySMAX(EnemySMAX):\\n    def __init__(self, policy, params, config, **env_kwargs):\\n        super().__init__(**env_kwargs)\\n        self.policy = policy\\n        self.params = params\\n        #self.hstate = hstate\\n        self.config = config\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\\n        return (self.params, self.hstate)\\n\\n    def get_enemy_actions(self, key, policy_state, enemy_x):\\n        params, hstate = policy_state\\n        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\\n\\n        #print(\"hstate shape:\", hstate.shape)\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        #pi, _ = self.policy.apply(policy_state, enemy_obs)\\n        hstate, pi, _ = self.policy.apply(params, hstate, enemy_x)\\n        enemy_actions = pi.sample(seed=key) \\n        enemy_actions = jnp.squeeze(enemy_actions, axis=0)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        enemy_actions = {\\n            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\\n            for agent in self.enemy_agents\\n        }\\n        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\\n        policy_state = (params, hstate)\\n        return enemy_actions, policy_state\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for the IPPO ActorCriticRNN policy network\n",
    "'''\n",
    "import dataclasses\n",
    "from jaxmarl.environments.smax.smax_env import SMAX\n",
    "from jaxmarl.environments.smax.smax_env import State as SMAXState\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "from flax import struct\n",
    "\n",
    "@struct.dataclass\n",
    "class State:\n",
    "    # underlying jaxmarl env state\n",
    "    state: ...\n",
    "    # the enemy policy state. Needed for recurrent policies or\n",
    "    # remembering details about previous observations for heuristics.\n",
    "    enemy_policy_state: ...\n",
    "\n",
    "class EnemySMAX(MultiAgentEnv):\n",
    "    \"\"\"Class that presents the SMAX environment as a single-player\n",
    "    (but still multi-agent) environment. Functions like a wrapper, but\n",
    "    not linked with any of the wrapper code because that is used differently.\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, **env_kwargs):\n",
    "        self._env = SMAX(**env_kwargs)\n",
    "        # only one team\n",
    "        self.num_agents = self._env.num_allies\n",
    "        self.num_enemies = self._env.num_enemies\n",
    "        # want to provide a consistent API between this and SMAX\n",
    "        self.num_allies = self._env.num_allies\n",
    "        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\n",
    "        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\n",
    "        self.all_agents = self.agents + self.enemy_agents\n",
    "        self.observation_spaces = {\n",
    "            i: self._env.observation_spaces[i] for i in self.agents\n",
    "        }\n",
    "        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\n",
    "        key, reset_key = jax.random.split(key)\n",
    "        obs, state = self._env.reset(reset_key)\n",
    "        enemy_policy_state = self.get_enemy_policy_initial_state(key)\n",
    "        new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "        new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\n",
    "\n",
    "    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0, 4))\n",
    "    def step_env(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: State,\n",
    "        actions: Dict[str, chex.Array],\n",
    "        get_state_sequence=False,\n",
    "    ):\n",
    "        jaxmarl_state = state.state\n",
    "        obs = self._env.get_obs(jaxmarl_state)\n",
    "        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\n",
    "        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\n",
    "        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_dones = {\n",
    "            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        enemy_x = (    \n",
    "            enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\n",
    "            enemy_dones[jnp.newaxis, :],    # [1, num_agents]\n",
    "            enemy_avail_actions              # [1, num_agents, num_actions]\n",
    "        )\n",
    "\n",
    "        key, action_key = jax.random.split(key)\n",
    "        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "        #    action_key, state.enemy_policy_state, enemy_obs\n",
    "        #)\n",
    "        enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "            action_key, state.enemy_policy_state, enemy_x\n",
    "        )\n",
    "        \n",
    "        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \n",
    "        actions = jnp.array([actions[i] for i in self.agents])\n",
    "        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        #print(\"enemy_actions:\", enemy_actions)\n",
    "        #print(\"actions shape:\", actions.shape)\n",
    "        enemy_movement_actions, enemy_attack_actions = (\n",
    "            self._env._decode_discrete_actions(enemy_actions)\n",
    "        )\n",
    "        if self._env.action_type == \"continuous\":\n",
    "            cont_actions = jnp.zeros((len(self.all_agents), 4))\n",
    "            cont_actions = cont_actions.at[: self.num_allies].set(actions)\n",
    "            key, action_key = jax.random.split(key)\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_continuous_actions(\n",
    "                    action_key, jaxmarl_state, cont_actions\n",
    "                )\n",
    "            )\n",
    "            ally_movement_actions = ally_movement_actions[: self.num_allies]\n",
    "            ally_attack_actions = ally_attack_actions[: self.num_allies]\n",
    "        else:\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_discrete_actions(actions)\n",
    "            )\n",
    "\n",
    "        movement_actions = jnp.concatenate(\n",
    "            [ally_movement_actions, enemy_movement_actions], axis=0\n",
    "        )\n",
    "        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\n",
    "\n",
    "        if not get_state_sequence:\n",
    "            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "            new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "            rewards = {agent: rewards[agent] for agent in self.agents}\n",
    "            all_done = dones[\"__all__\"]\n",
    "            dones = {agent: dones[agent] for agent in self.agents}\n",
    "            dones[\"__all__\"] = all_done\n",
    "\n",
    "            state = state.replace(\n",
    "                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\n",
    "            )\n",
    "            return new_obs, state, rewards, dones, infos\n",
    "        else:\n",
    "            states = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            return states\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def get_avail_actions(self, state: State):\n",
    "        avail_actions = self._env.get_avail_actions(state.state)\n",
    "        return {agent: avail_actions[agent] for agent in self.agents}\n",
    "\n",
    "    def get_all_unit_obs(self, state: State):\n",
    "        return self._env.get_obs(state.state)\n",
    "\n",
    "    def get_obs(self, state: State) -> Dict[str, chex.Array]:\n",
    "        obs = self.get_all_unit_obs(state)\n",
    "        return {agent: obs[agent] for agent in self.agents}\n",
    "\n",
    "    def get_world_state(self, state: State):\n",
    "        return self._env.get_world_state(state.state)\n",
    "\n",
    "    def is_terminal(self, state: State):\n",
    "        return self._env.is_terminal(state.state)\n",
    "\n",
    "    def expand_state_seq(self, state_seq):\n",
    "        # TODO jit/scan this\n",
    "        expanded_state_seq = []\n",
    "\n",
    "        # TODO this actually can't take a key because recording this key is really hard\n",
    "        # it's not exposed to the user so we can't ask them to store it. Not a problem\n",
    "        # for now but will have to get creative in the future potentially.\n",
    "        for key, state, actions in state_seq:\n",
    "            # There is a split in the step function of MultiAgentEnv\n",
    "            # We call split here so that the action key is the same.\n",
    "            key, _ = jax.random.split(key)\n",
    "            states = self.step_env(key, state, actions, get_state_sequence=True)\n",
    "            states = list(map(SMAXState, *dataclasses.astuple(states)))\n",
    "            viz_actions = {\n",
    "                agent: states[-1].prev_attack_actions[i]\n",
    "                for i, agent in enumerate(self.all_agents)\n",
    "            }\n",
    "\n",
    "            expanded_state_seq.append((key, state.state, viz_actions))\n",
    "            expanded_state_seq.extend(\n",
    "                zip([key] * len(states), states, [viz_actions] * len(states))\n",
    "            )\n",
    "            state = state.replace(\n",
    "                state=state.state.replace(terminal=self.is_terminal(state))\n",
    "            )\n",
    "        return expanded_state_seq\n",
    "\n",
    "\n",
    "\n",
    "# wrapper for creation of env playing against user specified policy\n",
    "class LearnedPolicyEnemySMAX(EnemySMAX):\n",
    "    def __init__(self, policy, params, config, **env_kwargs):\n",
    "        super().__init__(**env_kwargs)\n",
    "        self.policy = policy\n",
    "        self.params = params\n",
    "        #self.hstate = hstate\n",
    "        self.config = config\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "        return (self.params, self.hstate)\n",
    "\n",
    "    def get_enemy_actions(self, key, policy_state, enemy_x):\n",
    "        params, hstate = policy_state\n",
    "        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\n",
    "\n",
    "        #print(\"hstate shape:\", hstate.shape)\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        #pi, _ = self.policy.apply(policy_state, enemy_obs)\n",
    "        hstate, pi, _ = self.policy.apply(params, hstate, enemy_x)\n",
    "        enemy_actions = pi.sample(seed=key) \n",
    "        enemy_actions = jnp.squeeze(enemy_actions, axis=0)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        enemy_actions = {\n",
    "            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\n",
    "            for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\n",
    "        policy_state = (params, hstate)\n",
    "        return enemy_actions, policy_state\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c27f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent params\n",
      "Loaded mixer params\n"
     ]
    }
   ],
   "source": [
    "# Init environment\n",
    "from flax.serialization import from_bytes # For loading pretrained params\n",
    "\n",
    "#env = environments.create(env_name, episode_length=episode_length)\n",
    "scenario = map_name_to_scenario(config[\"MAP_NAME\"])\n",
    "env = HeuristicEnemySMAX(scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "#ippo_hstate = ScannedRNNIPPO.initialize_carry(config[\"NUM_ACTORS\"], ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "#env = LearnedPolicyEnemySMAX(policy = dummy_network, params=trained_ippo_params, config=config, scenario=scenario, **config[\"ENV_KWARGS\"]) # env against trained IPPO policy\n",
    "env = SMAXLogWrapper(env)\n",
    "wrapped_env = CTRolloutManager(env, batch_size=config[\"NUM_ENVS\"])\n",
    "\n",
    "rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "reset_fn = jax.jit(wrapped_env.batch_reset)\n",
    "#reset_fn = jax.jit(env.reset)\n",
    "\n",
    "config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
    "config[\"NUM_UPDATES\"] = (\n",
    "    config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Init a random key\n",
    "key = jax.random.key(seed)\n",
    "\n",
    "# Init policy network\n",
    "policy_layer_sizes = policy_hidden_layer_sizes + (env.action_space(env.agents[0]).n,) # Not actually used\n",
    "#policy_network = ActorRNN(env.action_space(env.agents[0]).n, config=config)\n",
    "policy_network = RNNQNetwork(\n",
    "            action_dim=wrapped_env.max_action_space,\n",
    "            hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "        )\n",
    "\n",
    "# Init mixer used in qmix\n",
    "mixer = MixingNetwork(\n",
    "    config[\"MIXER_EMBEDDING_DIM\"],\n",
    "    config[\"MIXER_HYPERNET_HIDDEN_DIM\"],\n",
    "    config[\"MIXER_INIT_SCALE\"],\n",
    ")\n",
    "\n",
    "# Init population of controllers\n",
    "key, subkey = jax.random.split(key)\n",
    "#keys = jax.random.split(subkey, num=batch_size)\n",
    "# fake_batch = jnp.zeros(shape=(batch_size, env.observation_size)) # Not needed as on-policy is used for no batches?\n",
    "# init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "init_x = (\n",
    "    jnp.zeros(\n",
    "        (1, 1, wrapped_env.obs_size)\n",
    "    ),  # (time_step, batch_size, obs_size)\n",
    "    jnp.zeros((1, 1)),  # (time_step, batch size)\n",
    ")\n",
    "init_hstate = ScannedRNN.initialize_carry(\n",
    "    config[\"HIDDEN_SIZE\"], 1\n",
    ")  # (batch_size, hidden_dim)\n",
    "\n",
    "keys = jax.random.split(subkey, batch_size-1) # subtract 1 from batch size for loaded params added later\n",
    "\n",
    "# Assume init_hstate: [H], init_x: [X]\n",
    "#fake_hstate = jnp.stack([init_hstate] * batch_size)  # [N, H]\n",
    "#fake_x = tuple(jnp.stack([x] * batch_size) for x in init_x)\n",
    "\n",
    "# Add leading batch dim and broadcast fake hidden state\n",
    "fake_hstate = jnp.broadcast_to(jnp.expand_dims(init_hstate, 0), (batch_size-1, *init_hstate.shape))  # [batch_size, H]\n",
    "# Same for each element in init_x tuple (assuming init_x is a tuple of arrays)\n",
    "fake_x = tuple(\n",
    "    jnp.broadcast_to(jnp.expand_dims(x, 0), (batch_size-1, *x.shape)) for x in init_x\n",
    ")\n",
    "\n",
    "# Load trained parameters\n",
    "dummy_params = policy_network.init(key, init_hstate, *init_x)\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_qmix_params_v2.msgpack\", \"rb\") as f:\n",
    "    loaded_agent_params = from_bytes(dummy_params, f.read())\n",
    "print(\"Loaded agent params\")\n",
    "\n",
    "#network_params = policy_network.init(subkey, init_hstate, init_x)\n",
    "agent_params = jax.vmap(\n",
    "    policy_network.init\n",
    ")(keys, fake_hstate, *fake_x)\n",
    "\n",
    "# init mixer\n",
    "def _env_sample_step(env_state, unused):\n",
    "    rng, key_a, key_s = jax.random.split(\n",
    "        jax.random.PRNGKey(0), 3\n",
    "    )  # use a dummy rng here\n",
    "    key_a = jax.random.split(key_a, env.num_agents)\n",
    "    actions = {\n",
    "        agent: wrapped_env.batch_sample(key_a[i], agent)\n",
    "        for i, agent in enumerate(env.agents)\n",
    "    }\n",
    "    avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "    obs, env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        key_s, env_state, actions\n",
    "    )\n",
    "    timestep = Timestep(\n",
    "        obs=obs,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        dones=dones,\n",
    "        avail_actions=avail_actions,\n",
    "    )\n",
    "    return env_state, timestep\n",
    "\n",
    "_, _env_state = wrapped_env.batch_reset(rng)\n",
    "_, sample_traj = jax.lax.scan(\n",
    "    _env_sample_step, _env_state, None, config[\"NUM_STEPS\"]\n",
    ")\n",
    "init_x = jnp.zeros((len(env.agents), 1, 1)) # q vals: agents, time, batch\n",
    "state_size = sample_traj.obs[\"__all__\"].shape[\n",
    "    -1\n",
    "]  # get the state shape from the buffer\n",
    "init_state = jnp.zeros((1, 1, state_size)) # (time_step, batch_size, obs_size)\n",
    "\n",
    "# Load trained mixer parameters\n",
    "dummy_mixer_params = mixer.init(key, init_x, init_state)\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_qmix_mixer_params_v2.msgpack\", \"rb\") as f:\n",
    "    loaded_mixer_params = from_bytes(dummy_mixer_params, f.read())\n",
    "print(\"Loaded mixer params\")\n",
    "\n",
    "init_x_batched = jnp.broadcast_to(jnp.expand_dims(init_x, 0), (batch_size-1, *init_x.shape))\n",
    "init_state_batched = jnp.broadcast_to(jnp.expand_dims(init_state, 0), (batch_size-1, *init_state.shape)) \n",
    "#mixer_params = mixer.init(subkey, init_x, init_state)\n",
    "mixer_params = jax.vmap(\n",
    "    mixer.init\n",
    ")(keys, init_x_batched, init_state_batched)\n",
    "\n",
    "# Add pretained solution \n",
    "# Add a batch axis \n",
    "loaded_agent_params = jax.tree.map(lambda p: jnp.expand_dims(p, 0), loaded_agent_params)\n",
    "loaded_mixer_params = jax.tree.map(lambda p: jnp.expand_dims(p, 0), loaded_mixer_params)\n",
    "# Append pretrained params at the end of the random ones\n",
    "combined_agent_params = jax.tree.map(\n",
    "    lambda rand, pre: jnp.concatenate([rand, pre], axis=0),\n",
    "    agent_params, loaded_agent_params\n",
    ")\n",
    "\n",
    "combined_mixer_params = jax.tree.map(\n",
    "    lambda rand, pre: jnp.concatenate([rand, pre], axis=0),\n",
    "    mixer_params, loaded_mixer_params\n",
    ")\n",
    "\n",
    "#network_params = {'agent': agent_params, 'mixer': mixer_params}\n",
    "\n",
    "network_params = {\"agent\": combined_agent_params, \"mixer\": combined_mixer_params,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ca9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(x: dict):\n",
    "    return jnp.stack([x[agent] for agent in env.agents], axis=0)\n",
    "\n",
    "def unbatchify(x: jnp.ndarray):\n",
    "    return {agent: x[i] for i, agent in enumerate(env.agents)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1703911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to play a step with the policy in the environment\n",
    "def play_step_fn(\n",
    "    runner_state\n",
    "):\n",
    "    \"\"\"\n",
    "    Play an environment step and return the updated state and the transition.\n",
    "    \"\"\"\n",
    "    #hs, last_obs, last_dones, env_state, rng = carry\n",
    "    policy_params, env_state, last_obs, last_dones, hstate, rng = runner_state\n",
    "\n",
    "    rng, rng_a, rng_s = jax.random.split(rng, 3)\n",
    "\n",
    "    # (num_agents, 1 (dummy time), num_envs, obs_size)\n",
    "    _obs = batchify(last_obs)[:, np.newaxis]\n",
    "    _dones = batchify(last_dones)[:, np.newaxis]\n",
    "    #_obs = batchify_multi(last_obs)[:, :, np.newaxis]    # [batch, num_agents, 1, num_envs, obs_dim]\n",
    "    #_dones = batchify_multi(last_dones)[:, :, np.newaxis] # [batch, num_agents, 1, num_envs]\n",
    "\n",
    "    #print(\"hstate shape:\", hstate.shape)  # should be [BATCH_SIZE, NUM_ENVS, NUM_AGENTS, HIDDEN_SIZE]\n",
    "    #print(\"_obs shape:\", _obs.shape)      # should be [BATCH_SIZE, NUM_ENVS, OBS_DIM]\n",
    "    #print(\"_dones shape:\", _dones.shape)  # should be [BATCH_SIZE, NUM_ENVS, OBS_DIM]\n",
    "\n",
    "    new_hstate, q_vals = jax.vmap(\n",
    "        policy_network.apply, in_axes=(None, 0, 0, 0)\n",
    "    )(  # vmap across the agent dim\n",
    "        policy_params['agent'],\n",
    "        hstate,\n",
    "        _obs,\n",
    "        _dones,\n",
    "    )\n",
    "    #print(\"new_hstate shape:\", new_hstate.shape)  # should be [BATCH_SIZE, NUM_ENVS, NUM_AGENTS, HIDDEN_SIZE]\n",
    "\n",
    "    q_vals = q_vals.squeeze(\n",
    "        axis=1\n",
    "    )  # (num_agents, num_envs, num_actions) remove the time dim\n",
    "\n",
    "    # explore\n",
    "    avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "    avail_actions_batchified = batchify(avail_actions)\n",
    "\n",
    "    #eps = eps_scheduler(train_state.n_updates)\n",
    "    #_rngs = jax.random.split(rng_a, env.num_agents)\n",
    "    #actions = jax.vmap(eps_greedy_exploration, in_axes=(0, 0, None, 0))(\n",
    "    #    _rngs, q_vals, eps, batchify(avail_actions)\n",
    "    #)\n",
    "    \n",
    "    unavail_actions = 1 - avail_actions_batchified\n",
    "    q_vals = q_vals - (unavail_actions * 1e10)\n",
    "    actions_array = jnp.argmax(q_vals, axis=-1)\n",
    "    actions_dict = unbatchify(actions_array)\n",
    "    #print(\"avail_actions_batchified\", avail_actions_batchified.shape)\n",
    "    #print(\"q_vals\", q_vals.shape)\n",
    "    #print(\"actions\", actions_array.shape)\n",
    "    #print(\"actions\", actions_dict)\n",
    "\n",
    "    #print(\"keys shape: {}\", rng_s.shape)\n",
    "    #print(\"states shape: {}\", jax.tree.map(lambda x: x.shape, env_state))\n",
    "    #print(\"actions_dict shapes: {}\", {k: v.shape for k, v in actions_dict.items()})\n",
    "\n",
    "\n",
    "    new_obs, new_env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        rng_s, env_state, actions_dict\n",
    "    )\n",
    "    \n",
    "    rewards = jax.tree.map(lambda x:config[\"REW_SCALE\"]*x, rewards)\n",
    "\n",
    "    timestep = Timestep(\n",
    "        obs=last_obs,\n",
    "        actions=actions_dict,\n",
    "        rewards=rewards, #jax.tree.map(lambda x:config.get(\"REW_SCALE\", 1)*x, rewards),\n",
    "        dones=last_dones,\n",
    "        avail_actions=avail_actions,\n",
    "    )\n",
    "\n",
    "    #per_agent_dones = jnp.stack(\n",
    "    #    [dones[agent] for agent in env.agents], axis=-1\n",
    "    #)  # shape: [num_envs, num_agents]\n",
    "\n",
    "    transition = Transition(\n",
    "        #jnp.tile(dones[\"__all__\"], env.num_agents),\n",
    "        #last_dones,\n",
    "        #actions_array.squeeze(),\n",
    "        #batchify(rewards).reshape(-1),#.reshape(batch_size, config[\"NUM_ENVS\"], -1),  #batchify(rewards, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
    "        #_obs,\n",
    "        env_state.env_state.state,\n",
    "        infos,\n",
    "        #avail_actions,\n",
    "    )\n",
    "\n",
    "    runner_state = (policy_params, new_env_state, new_obs, dones, new_hstate, rng)\n",
    "    \n",
    "    return runner_state, (transition, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cf259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unroll(\n",
    "    runner_state,\n",
    "    episode_length: int,\n",
    "    play_step_fn: Callable[\n",
    "        [EnvState, Params, RNGKey],\n",
    "        Tuple[\n",
    "            EnvState,\n",
    "            Params,\n",
    "            RNGKey,\n",
    "            Transition,\n",
    "        ],\n",
    "    ],\n",
    ") -> Tuple[EnvState, Transition]:\n",
    "    \"\"\"Generates an episode according to the agent's policy, returns the final state of\n",
    "    the episode and the transitions of the episode.\n",
    "\n",
    "    Args:\n",
    "        init_state: first state of the rollout.\n",
    "        policy_params: params of the individual.\n",
    "        key: random key for stochasiticity handling.\n",
    "        episode_length: length of the rollout.\n",
    "        play_step_fn: function describing how a step need to be taken.\n",
    "\n",
    "    Returns:\n",
    "        A new state, the experienced transition.\n",
    "    \"\"\"\n",
    "\n",
    "    def _scan_play_step_fn(\n",
    "        carry, unused_arg: Any #: Tuple[EnvState, Params, RNGKey]\n",
    "    ) -> Tuple[Tuple[EnvState, Params, RNGKey], Transition]:\n",
    "        runner_state, (transitions, timestep) = play_step_fn(carry)\n",
    "        return runner_state, (transitions, timestep)\n",
    "\n",
    "    runner_state, (transitions, timestep) = jax.lax.scan(\n",
    "        _scan_play_step_fn,\n",
    "        runner_state,\n",
    "        (),\n",
    "        length=episode_length,\n",
    "    )\n",
    "    return runner_state, (transitions, timestep)\n",
    "\n",
    "\n",
    "def get_mask_from_transitions(\n",
    "    data: Transition,\n",
    ") -> jnp.ndarray:\n",
    "    is_done = jnp.clip(jnp.cumsum(data.global_done, axis=1), 0, 1)\n",
    "    mask = jnp.roll(is_done, 1, axis=1)\n",
    "    mask = mask.at[:, 0].set(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d817b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(\n",
    "    policy_params: Genotype,\n",
    "    key: RNGKey,\n",
    "    episode_length: int,\n",
    "    play_reset_fn: Callable[[RNGKey], EnvState],\n",
    "    play_step_fn: Callable[\n",
    "        [EnvState, Params, RNGKey], Tuple[EnvState, Params, RNGKey, QDTransition]\n",
    "    ],\n",
    "    descriptor_extractor: Callable[[QDTransition, jnp.ndarray], Descriptor],\n",
    ") -> Tuple[Fitness, Descriptor, ExtraScores]:\n",
    "    \"\"\"Evaluates policies contained in policies_params in parallel.\n",
    "    The play_reset_fn function allows for a more general scoring_function that can be\n",
    "    called with different batch-size and not only with a batch-size of the same\n",
    "    dimension as init_states.\n",
    "\n",
    "    To define purely stochastic environments, using the reset function from the\n",
    "    environment, use \"play_reset_fn = env.reset\".\n",
    "\n",
    "    To define purely deterministic environments, as in \"scoring_function\", generate\n",
    "    a single init_state using \"init_state = env.reset(key)\", then use\n",
    "    \"play_reset_fn = lambda key: init_state\".\n",
    "\n",
    "    Args:\n",
    "        policies_params: The parameters of closed-loop controllers/policies to evaluate.\n",
    "        key: A jax random key\n",
    "        episode_length: The maximal rollout length.\n",
    "        play_reset_fn: The function to reset the environment and obtain initial states.\n",
    "        play_step_fn: The function to play a step of the environment.\n",
    "        descriptor_extractor: The function to extract the descriptor.\n",
    "\n",
    "    Returns:\n",
    "        fitness: Array of fitnesses of all evaluated policies\n",
    "        descriptor: Behavioural descriptors of all evaluated policies\n",
    "        extra_scores: Additional information resulting from the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Reset environments\n",
    "    key, subkey = jax.random.split(key)\n",
    "    #keys = jax.random.split(subkey, jax.tree.leaves(policies_params)[0].shape[0])\n",
    "    #keys = jax.random.split(subkey, config[\"NUM_ENVS\"])\n",
    "    #init_obs, init_env_state = jax.vmap(play_reset_fn, in_axes=(0,))(keys)\n",
    "    init_obs, init_env_state = play_reset_fn(key)\n",
    "    #print(\"init_obs is a dict with keys:\", init_obs.keys())\n",
    "    #for k, v in init_obs.items():\n",
    "    #    print(f\"init_obs[{k}] shape:\", v.shape) \n",
    "    \n",
    "    keys = jax.random.split(subkey, batch_size)\n",
    "\n",
    "    #init_dones = {\n",
    "    #    agent: jnp.zeros((config[\"NUM_ENVS\"]), dtype=bool)\n",
    "    #    for agent in env.agents + [\"__all__\"]\n",
    "    #}\n",
    "    init_hstate = ScannedRNN.initialize_carry(\n",
    "        config[\"HIDDEN_SIZE\"], len(env.agents), config[\"NUM_ENVS\"]\n",
    "    )\n",
    "    \n",
    "    batched_env_state = jax.tree.map(lambda x: jnp.stack([x] * batch_size), init_env_state)\n",
    "    batched_obs = jax.tree.map(lambda x: jnp.stack([x] * batch_size), init_obs)\n",
    "    batched_dones = {\n",
    "        agent: jnp.stack([jnp.zeros(config[\"NUM_ENVS\"], dtype=bool)] * batch_size)\n",
    "        for agent in env.agents + [\"__all__\"]\n",
    "    }\n",
    "    batched_hstate = jnp.stack([init_hstate] * batch_size)\n",
    "\n",
    "    #print(\"batched_obs is a dict with keys:\", batched_obs.keys())\n",
    "    #for k, v in batched_obs.items():\n",
    "    #    print(f\"batched_obs[{k}] shape:\", v.shape) \n",
    "\n",
    "    init_runner_state = (policy_params, batched_env_state, batched_obs, batched_dones, batched_hstate, keys)\n",
    "    #print(\"init_runner_state:\")\n",
    "    #jax.tree.map(lambda x: print(x.shape), init_runner_state)\n",
    "    \n",
    "    # Step environments\n",
    "    unroll_fn = functools.partial(\n",
    "        generate_unroll,\n",
    "        episode_length=episode_length,\n",
    "        play_step_fn=play_step_fn,\n",
    "    )\n",
    "    #keys = jax.random.split(key, jax.tree.leaves(policies_params)[0].shape[0])\n",
    "    _, (data, timestep) = jax.vmap(unroll_fn)(init_runner_state) # data = Transistions data struc\n",
    "    #jax.debug.print(\"after vmap timestep shape: {}\", \n",
    "    #jax.tree.map(lambda x: x.shape, timestep))\n",
    "\n",
    "    # Create a mask to extract data properly\n",
    "    #mask = get_mask_from_transitions(data)\n",
    "    mask = data.infos[\"returned_episode\"]\n",
    "\n",
    "    # Evaluate\n",
    "    #print(\"data.reward shape:\", data.reward.shape)\n",
    "    #print(\"data.global_done shape:\", data.global_done.shape)\n",
    "    #print(\"mask shape:\", mask.shape)\n",
    "    \n",
    "    #print(type(data.infos[\"returned_episode_returns\"]))\n",
    "    #print(data.infos[\"returned_episode_returns\"].shape)\n",
    "\n",
    "    # Shape: (num_offspring, episode_len, num_envs, 1)\n",
    "    returns = data.infos[\"returned_episode_returns\"][..., 0]  # (batch_size, episode_length, num_envs)\n",
    "    #print(\"returns shape\", returns.shape)\n",
    "\n",
    "    # Take the max over time to extract the one non-zero final return per env\n",
    "    final_returns = jnp.max(returns, axis=1)  # (batch_size, num_envs)\n",
    "    #print(\"final returns shape\", final_returns.shape)\n",
    "\n",
    "    # Average over the environments per offspring\n",
    "    mean_return = jnp.mean(final_returns, axis=1, keepdims=True)  # shape: (batch_size, 1)\n",
    "    var_return = jnp.var(final_returns, axis=1, keepdims=True)\n",
    "\n",
    "    # === Ally survival reward ===\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)  # (B, T, E, A)\n",
    "    teams = data.env_state.unit_teams                      # (B, T, E, A)\n",
    "    is_ally = (teams == 0).astype(jnp.float32)              # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                            # (B, T, E, A)\n",
    "    #print(\"ally_alive shape:\", ally_alive.shape)\n",
    "\n",
    "    # Final timestep allies alive\n",
    "    final_ally_alive = ally_alive[:, -1, :, :]              # (B, E, A)\n",
    "    #print(\"final_ally_alive shape:\", final_ally_alive.shape)\n",
    "    total_alive_allies = jnp.sum(final_ally_alive, axis=(1, 2))  # (B,)\n",
    "    #print(\"total_alive_allies shape:\", total_alive_allies.shape)\n",
    "\n",
    "    # Total possible allies\n",
    "    total_possible_allies = jnp.sum(is_ally[:, 0, :, :], axis=(1, 2))  # (B,)\n",
    "    #print(\"total_possible_allies shape:\", total_possible_allies.shape)\n",
    "    ally_alive_reward = (total_alive_allies / total_possible_allies)[:, None]  # (B, 1)   \n",
    "    #print(\"ally_alive_reward shape:\", ally_alive_reward.shape)\n",
    "\n",
    "    # === Final fitness ===\n",
    "    fitnesses = (mean_return - var_return) + ally_alive_reward # (B, 1)\n",
    "\n",
    "    descriptors = descriptor_extractor(data, mask)\n",
    "\n",
    "    #print(\"fitness shape:\", fitnesses.shape)\n",
    "    #print(\"descriptors shape:\", descriptors.shape)\n",
    "\n",
    "    return fitnesses, descriptors, {\"transitions\": timestep}#data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b647f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_descriptors(data):\\n    \"\"\"\\n    Compute per-trajectory descriptors:\\n    - % of actions that were movement actions over the whole episode (per batch item)\\n    - % of actions that were attack actions over the whole episode (per batch item)\\n    - Avg ally-ally distance averaged over all steps (per batch item)\\n\\n    Output: shape (batch_size, 3)\\n    \"\"\"\\n    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\\n    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\\n    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\\n    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\\n    teams = data.env_state.unit_teams                                # (B, T, E, A)\\n\\n    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\\n    ally_alive = alive * is_ally                                     # (B, T, E, A)\\n\\n    # Movement mask: True where movement_actions != 0 on either coordinate\\n    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\\n    moved = moved * ally_alive                                       # only alive allies\\n\\n    # Attack mask: True where attack_actions > 0\\n    attacked = (attack_actions > 0).astype(jnp.float32)              # (B, T, E, A)\\n    attacked = attacked * ally_alive                                 # only alive allies\\n\\n    # Total number of movement and attack actions per batch\\n    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\\n    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\\n\\n    # Total actions = moves + attacks\\n    total_actions = num_move_actions + num_attack_actions + 1e-8\\n\\n    # Movement and attack percent over whole episode\\n    movement_pct = num_move_actions / total_actions\\n    attack_pct = num_attack_actions / total_actions\\n\\n    # Pairwise distance function (same as before)\\n    def avg_pairwise_distance(pos, mask):\\n        \"\"\"\\n        pos: (A, 2)\\n        mask: (A,)\\n        returns: scalar distance\\n        \"\"\"\\n        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\\n        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\\n        pair_mask = mask[:, None] * mask[None, :]      # (A, A)\\n        not_self = 1 - jnp.eye(mask.shape[0])\\n        valid_pairs = pair_mask * not_self\\n        total_dist = jnp.sum(dists * valid_pairs)\\n        num_pairs = jnp.sum(valid_pairs)\\n        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\\n\\n    # Compute avg distances over *all* time steps\\n    ally_mask_full = (teams == 0) * alive  # (B, T, E, A)\\n\\n    # vmap over batch, time, env\\n    # Output: (B, T, E)\\n    all_step_dists = jax.vmap(\\n        jax.vmap(\\n            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),  # over envs\\n            in_axes=(0, 0)  # over time\\n        ),\\n        in_axes=(0, 0)  # over batch\\n    )(positions, ally_mask_full)\\n\\n    # Average over envs, then over time steps → (B,)\\n    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\\n\\n    # Normalize and clip\\n    max_distance = 32\\n    quarter_max = 0.25 * max_distance \\n    norm_dist = avg_dists_over_time / quarter_max\\n    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\\n\\n    # Stack all descriptors → shape (B, 3)\\n    #return jnp.stack([movement_pct, attack_pct, norm_dist], axis=-1)\\n    return jnp.stack([movement_pct, norm_dist], axis=-1)\\n\\n\\ndef descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\\n    \"\"\"Compute final xy position.\\n\\n    This function suppose that state descriptor is the xy position, as it\\n    just select the final one of the state descriptors given.\\n    \"\"\"\\n    # reshape mask for descriptor extraction\\n    mask = jnp.expand_dims(mask, axis=-1)\\n\\n    # Get descriptor\\n    #last_index = jnp.int32(jnp.sum(1.0 - mask, axis=1)) - 1\\n    #descriptors = jax.vmap(lambda x, y: x[y])(data.state_desc, last_index)\\n    descriptors = compute_descriptors(data)\\n\\n    # remove the dim coming from the trajectory\\n    return descriptors#.squeeze(axis=1)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compute_descriptors(data):\n",
    "    \"\"\"\n",
    "    Compute per-trajectory descriptors:\n",
    "    - % of actions that were movement actions over the whole episode (per batch item)\n",
    "    - % of actions that were attack actions over the whole episode (per batch item)\n",
    "    - Avg ally-ally distance averaged over all steps (per batch item)\n",
    "    \n",
    "    Output: shape (batch_size, 3)\n",
    "    \"\"\"\n",
    "    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\n",
    "    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\n",
    "    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\n",
    "    teams = data.env_state.unit_teams                                # (B, T, E, A)\n",
    "\n",
    "    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                                     # (B, T, E, A)\n",
    "\n",
    "    # Movement mask: True where movement_actions != 0 on either coordinate\n",
    "    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\n",
    "    moved = moved * ally_alive                                       # only alive allies\n",
    "\n",
    "    # Attack mask: True where attack_actions > 0\n",
    "    attacked = (attack_actions > 0).astype(jnp.float32)              # (B, T, E, A)\n",
    "    attacked = attacked * ally_alive                                 # only alive allies\n",
    "\n",
    "    # Total number of movement and attack actions per batch\n",
    "    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\n",
    "    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\n",
    "\n",
    "    # Total actions = moves + attacks\n",
    "    total_actions = num_move_actions + num_attack_actions + 1e-8\n",
    "\n",
    "    # Movement and attack percent over whole episode\n",
    "    movement_pct = num_move_actions / total_actions\n",
    "    attack_pct = num_attack_actions / total_actions\n",
    "\n",
    "    # Pairwise distance function (same as before)\n",
    "    def avg_pairwise_distance(pos, mask):\n",
    "        \"\"\"\n",
    "        pos: (A, 2)\n",
    "        mask: (A,)\n",
    "        returns: scalar distance\n",
    "        \"\"\"\n",
    "        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\n",
    "        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\n",
    "        pair_mask = mask[:, None] * mask[None, :]      # (A, A)\n",
    "        not_self = 1 - jnp.eye(mask.shape[0])\n",
    "        valid_pairs = pair_mask * not_self\n",
    "        total_dist = jnp.sum(dists * valid_pairs)\n",
    "        num_pairs = jnp.sum(valid_pairs)\n",
    "        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\n",
    "\n",
    "    # Compute avg distances over *all* time steps\n",
    "    ally_mask_full = (teams == 0) * alive  # (B, T, E, A)\n",
    "\n",
    "    # vmap over batch, time, env\n",
    "    # Output: (B, T, E)\n",
    "    all_step_dists = jax.vmap(\n",
    "        jax.vmap(\n",
    "            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),  # over envs\n",
    "            in_axes=(0, 0)  # over time\n",
    "        ),\n",
    "        in_axes=(0, 0)  # over batch\n",
    "    )(positions, ally_mask_full)\n",
    "\n",
    "    # Average over envs, then over time steps → (B,)\n",
    "    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\n",
    "\n",
    "    # Normalize and clip\n",
    "    max_distance = 32\n",
    "    quarter_max = 0.25 * max_distance \n",
    "    norm_dist = avg_dists_over_time / quarter_max\n",
    "    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\n",
    "\n",
    "    # Stack all descriptors → shape (B, 3)\n",
    "    #return jnp.stack([movement_pct, attack_pct, norm_dist], axis=-1)\n",
    "    return jnp.stack([movement_pct, norm_dist], axis=-1)\n",
    "\n",
    "\n",
    "def descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\n",
    "    \"\"\"Compute final xy position.\n",
    "\n",
    "    This function suppose that state descriptor is the xy position, as it\n",
    "    just select the final one of the state descriptors given.\n",
    "    \"\"\"\n",
    "    # reshape mask for descriptor extraction\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Get descriptor\n",
    "    #last_index = jnp.int32(jnp.sum(1.0 - mask, axis=1)) - 1\n",
    "    #descriptors = jax.vmap(lambda x, y: x[y])(data.state_desc, last_index)\n",
    "    descriptors = compute_descriptors(data)\n",
    "\n",
    "    # remove the dim coming from the trajectory\n",
    "    return descriptors#.squeeze(axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa23523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptors(data, full_mask):\n",
    "    \"\"\"\n",
    "    Compute per-trajectory descriptors:\n",
    "    - % of actions that were movement actions over the whole episode (per batch item)\n",
    "    - Avg ally-ally distance averaged over all steps (per batch item)\n",
    "\n",
    "    Output: shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\n",
    "    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\n",
    "    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\n",
    "    teams = data.env_state.unit_teams                                # (B, T, E, A)\n",
    "\n",
    "    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                                     # (B, T, E, A)\n",
    "\n",
    "    # === Apply mask: ignore masked steps ===\n",
    "    full_mask = jnp.asarray(full_mask)\n",
    "    full_mask = 1.0 - full_mask  # Mask where 1 means usable data\n",
    "    ally_alive = ally_alive * full_mask\n",
    "\n",
    "    # Movement mask\n",
    "    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\n",
    "    moved = moved * ally_alive\n",
    "\n",
    "    # Attack mask\n",
    "    attacked = (attack_actions > 0).astype(jnp.float32)\n",
    "    attacked = attacked * ally_alive\n",
    "\n",
    "    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\n",
    "    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\n",
    "    total_actions = num_move_actions + num_attack_actions + 1e-8\n",
    "\n",
    "    movement_pct = num_move_actions / total_actions\n",
    "\n",
    "    # === Distance computation ===\n",
    "    def avg_pairwise_distance(pos, mask):\n",
    "        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\n",
    "        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\n",
    "        pair_mask = mask[:, None] * mask[None, :]\n",
    "        not_self = 1 - jnp.eye(mask.shape[0])\n",
    "        valid_pairs = pair_mask * not_self\n",
    "        total_dist = jnp.sum(dists * valid_pairs)\n",
    "        num_pairs = jnp.sum(valid_pairs)\n",
    "        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\n",
    "\n",
    "    ally_mask_full = is_ally * alive * full_mask       # shape (B, T, E, A)\n",
    "\n",
    "    # (B, T, E)\n",
    "    all_step_dists = jax.vmap(\n",
    "        jax.vmap(\n",
    "            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),\n",
    "            in_axes=(0, 0)\n",
    "        ),\n",
    "        in_axes=(0, 0)\n",
    "    )(positions, ally_mask_full)\n",
    "\n",
    "    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\n",
    "\n",
    "    max_distance = 32\n",
    "    quarter_max = 0.25 * max_distance\n",
    "    norm_dist = avg_dists_over_time / quarter_max\n",
    "    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\n",
    "\n",
    "    return jnp.stack([movement_pct, norm_dist], axis=-1)  # shape (B, 2)\n",
    "\n",
    "def descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\n",
    "    \"\"\"Compute trajectory descriptors, with mask expanded to match env_state agent dim.\"\"\"\n",
    "\n",
    "    B, T, E, A_total = data.env_state.unit_alive.shape\n",
    "    A_ally = mask.shape[-1]\n",
    "\n",
    "    # Expand to match shape of alive/env_state: assume allies are first\n",
    "    full_mask = jnp.zeros((B, T, E, A_total))\n",
    "    full_mask = full_mask.at[..., :A_ally].set(mask)\n",
    "\n",
    "    # Call descriptor computation with full mask\n",
    "    descriptors = compute_descriptors(data, full_mask)\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682e6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qmix_loss_fn(\n",
    "        policy_fn: Callable[[Params, Observation], jnp.ndarray],\n",
    "        reward_scaling: float,\n",
    "        discount: float,\n",
    ") -> Callable[[Params, Transition], jnp.ndarray]:\n",
    "    \"\"\"Creates the loss functions for IQL.\n",
    "\n",
    "    Args:\n",
    "        policy_fn: forward pass through the neural network defining the policy.\n",
    "        reward_scaling: value to multiply the reward given by the environment.\n",
    "        discount: discount factor.\n",
    "\n",
    "    Returns:\n",
    "        Return the loss functions used to train the policy.\n",
    "    \"\"\"\n",
    "    def _policy_loss_fn(\n",
    "        policy_params: Params,\n",
    "        target_policy_params: Params,\n",
    "        minibatch: Transition,\n",
    "        #emitter_state: CustomQualityPGEmitterState,\n",
    "    ) -> jnp.ndarray:\n",
    "        #minibatch = emitter_state.buffer.sample(emitter_state.buffer_state, emitter_state.key).experience\n",
    "\n",
    "        minibatch = jax.tree.map(\n",
    "            lambda x: jnp.swapaxes(\n",
    "                x[:, 0], 0, 1\n",
    "            ),  # remove the dummy sequence dim (1) and swap batch and temporal dims\n",
    "            minibatch,\n",
    "        )  # (max_time_steps, batch_size, ...)\n",
    "\n",
    "        # preprocess network input\n",
    "        init_hs = ScannedRNN.initialize_carry(\n",
    "            config[\"HIDDEN_SIZE\"],\n",
    "            len(env.agents),\n",
    "            config[\"BUFFER_BATCH_SIZE\"],\n",
    "        )\n",
    "        # num_agents, timesteps, batch_size, ...\n",
    "        _obs = batchify(minibatch.obs)\n",
    "        _dones = batchify(minibatch.dones)\n",
    "        _actions = batchify(minibatch.actions)\n",
    "        _rewards = batchify(minibatch.rewards)\n",
    "        _avail_actions = batchify(minibatch.avail_actions)\n",
    "        ###################################################################################################\n",
    "        #print(\"init_hs.shape\", init_hs.shape)\n",
    "        #print(\"_obs.shape\", _obs.shape)\n",
    "        #print(\"_does.shape\", _dones.shape)\n",
    "        #print(\"init_hs.shape\", init_hs.shape)\n",
    "        ###################################################################################################\n",
    "        _, q_next_target = jax.vmap(policy_fn, in_axes=(None, 0, 0, 0))(\n",
    "            target_policy_params['agent'], #train_state.target_network_params,\n",
    "            init_hs,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )  # (num_agents, timesteps, batch_size, num_actions)\n",
    "\n",
    "        _, q_vals = jax.vmap(policy_fn, in_axes=(None, 0, 0, 0))(\n",
    "            policy_params['agent'],\n",
    "            init_hs,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )  # (num_agents, timesteps, batch_size, num_actions)\n",
    "\n",
    "        # get logits of the chosen actions\n",
    "        chosen_action_q_vals = jnp.take_along_axis(\n",
    "            q_vals,\n",
    "            _actions[..., np.newaxis],\n",
    "            axis=-1,\n",
    "        ).squeeze(-1)  # (num_agents, timesteps, batch_size,)\n",
    "\n",
    "        unavailable_actions = 1 - _avail_actions\n",
    "        valid_q_vals = q_vals - (unavailable_actions * 1e10)\n",
    "\n",
    "        # get the q values of the next state\n",
    "        q_next = jnp.take_along_axis(\n",
    "            q_next_target,\n",
    "            jnp.argmax(valid_q_vals, axis=-1)[..., np.newaxis],\n",
    "            axis=-1,\n",
    "        ).squeeze(-1)  # (num_agents, timesteps, batch_size,)\n",
    "\n",
    "        qmix_next = mixer.apply(target_policy_params['mixer'], q_next, minibatch.obs[\"__all__\"])\n",
    "        qmix_target = (\n",
    "            minibatch.rewards[\"__all__\"][:-1]\n",
    "            + (\n",
    "                1 - minibatch.dones[\"__all__\"][:-1]\n",
    "            )  # use next done because last done was saved for rnn re-init\n",
    "            * config[\"GAMMA\"]\n",
    "            * qmix_next[1:]  # sum over agents\n",
    "        )\n",
    "\n",
    "        qmix = mixer.apply(policy_params['mixer'], chosen_action_q_vals, minibatch.obs[\"__all__\"])[:-1]\n",
    "        loss = jnp.mean(\n",
    "            (qmix - jax.lax.stop_gradient(qmix_target)) ** 2\n",
    "        )\n",
    "\n",
    "        #return loss, chosen_action_q_vals.mean()\n",
    "        return loss\n",
    "    \n",
    "    return _policy_loss_fn\n",
    "\n",
    "#class CustomQualityPGEmitterState(QualityPGEmitterState):\n",
    "    #target_network_params: Any\n",
    "#    buffer_state: Any\n",
    "\n",
    "@chex.dataclass(frozen=True)\n",
    "class CustomQualityPGEmitterState:\n",
    "    #target_network_params: Any\n",
    "    buffer_state: Any\n",
    "    #replay_buffer: Any = struct.field(pytree_node=False)  # Static Python object\n",
    "    key: RNGKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf22424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myQualityPGEmitter(Emitter):\n",
    "    \"\"\"\n",
    "    A policy gradient emitter used to implement the Policy Gradient Assisted MAP-Elites\n",
    "    (PGA-Map-Elites) algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: QualityPGConfig,\n",
    "        policy_network: nn.Module,\n",
    "        env: QDEnv,\n",
    "        selector: Optional[Selector] = None,\n",
    "    ) -> None:\n",
    "        self._config = config\n",
    "        self._env = env\n",
    "        self._selector = selector\n",
    "        self._actor_critic_iterations = int(\n",
    "            config.num_critic_training_steps / config.policy_delay\n",
    "        )  # actor and critic training are packed into a single function\n",
    "\n",
    "        # Init Critics\n",
    "        #critic_network = QModule(\n",
    "        #    n_critics=2, hidden_layer_sizes=self._config.critic_hidden_layer_size\n",
    "        #)\n",
    "        #critic_network = CriticRNN(action_dim=env.action_space(env.agents[0]).n, config=config, n_critics=2)\n",
    "        #target_q_network = RNNQNetwork(\n",
    "        #    action_dim=wrapped_env.max_action_space,\n",
    "        #    hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "        #)\n",
    "        \n",
    "        #self._critic_network = target_q_network #critic_network\n",
    "\n",
    "        # Set up the losses and optimizers - return the opt states\n",
    "        self._policy_loss_fn = make_qmix_loss_fn( #make_td3_loss_fn(\n",
    "            policy_fn=policy_network.apply,\n",
    "            #critic_fn=critic_network.apply,\n",
    "            reward_scaling=self._config.reward_scaling,\n",
    "            discount=self._config.discount,\n",
    "            #noise_clip=self._config.noise_clip,\n",
    "            #policy_noise=self._config.policy_noise,\n",
    "        )\n",
    "\n",
    "        # Init optimizers\n",
    "        #self._actor_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.actor_learning_rate\n",
    "        #)\n",
    "        #self._critic_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.critic_learning_rate\n",
    "        #)\n",
    "        #self._policies_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.policy_learning_rate\n",
    "        #)\n",
    "        \n",
    "        #lr_scheduler = optax.linear_schedule(\n",
    "        #    init_value=config[\"LR\"],\n",
    "        #    end_value=1e-10,\n",
    "        #    transition_steps=(config[\"NUM_EPOCHS\"]) * config[\"NUM_UPDATES\"],\n",
    "        #)\n",
    "        #lr = lr_scheduler if config.get(\"LR_LINEAR_DECAY\", False) else config[\"LR\"]\n",
    "        #tx = optax.chain(\n",
    "        #    optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "        #    optax.radam(learning_rate=lr),\n",
    "        #)\n",
    "        #self._policies_optimizer = tx\n",
    "\n",
    "        buffer = fbx.make_trajectory_buffer(\n",
    "            max_length_time_axis=self._config.replay_buffer_size // (self._config.num_envs * batch_size), #batch_size,\n",
    "            min_length_time_axis=self._config.batch_size,\n",
    "            sample_batch_size=self._config.batch_size,\n",
    "            add_batch_size=self._config.num_envs * batch_size, # batch_size different to self._config.batch_size and is accessed globally\n",
    "            sample_sequence_length=1,\n",
    "            period=1,\n",
    "        )\n",
    "        self._buffer = buffer\n",
    "\n",
    "        # Init optimizers\n",
    "        #self._policies_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.policy_learning_rate\n",
    "        #)\n",
    "        self._policies_optimizer = optax.chain(\n",
    "            optax.clip_by_global_norm(max_norm=10),\n",
    "            optax.radam(learning_rate=self._config.policy_learning_rate),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            the batch size emitted by the emitter.\n",
    "        \"\"\"\n",
    "        return self._config.env_batch_size\n",
    "\n",
    "    @property\n",
    "    def use_all_data(self) -> bool:\n",
    "        \"\"\"Whether to use all data or not when used along other emitters.\n",
    "\n",
    "        QualityPGEmitter uses the transitions from the genotypes that were generated\n",
    "        by other emitters.\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def init(\n",
    "        self,\n",
    "        key: RNGKey,\n",
    "        repertoire: Repertoire,\n",
    "        genotypes: Genotype,\n",
    "        fitnesses: Fitness,\n",
    "        descriptors: Descriptor,\n",
    "        extra_scores: ExtraScores,\n",
    "    ) -> CustomQualityPGEmitterState:\n",
    "        \"\"\"Initializes the emitter state.\n",
    "\n",
    "        Args:\n",
    "            genotypes: The initial population.\n",
    "            key: A random key.\n",
    "\n",
    "        Returns:\n",
    "            The initial state of the PGAMEEmitter.\n",
    "        \"\"\"\n",
    "        '''\n",
    "        #observation_size = self._env.observation_size\n",
    "        #action_size = self._env.action_size\n",
    "        #descriptor_size = self._env.state_descriptor_length\n",
    "\n",
    "        obs_space = self._env.observation_space(env.agents[0])#.shape[0]\n",
    "        action_space = self._env.action_space(env.agents[0])#.shape[0]\n",
    "\n",
    "        observation_size = int(np.prod(obs_space.shape))\n",
    "        action_size = int(np.prod(action_space.shape))\n",
    "        descriptor_size = 2 # hardcoded\n",
    "\n",
    "        # Initialise critic, greedy actor and population\n",
    "        #key, subkey = jax.random.split(key)\n",
    "        #fake_obs = jnp.zeros(shape=(observation_size,))\n",
    "        #fake_action = jnp.zeros(shape=(action_size,))\n",
    "        #critic_params = self._critic_network.init(\n",
    "        #    subkey, obs=fake_obs, actions=fake_action\n",
    "        #)\n",
    "\n",
    "        #init_hstate = ScannedRNN.initialize_carry(1, config[\"GRU_HIDDEN_DIM\"])\n",
    "        key, subkey = jax.random.split(key)\n",
    "        #fake_hstate = jnp.stack([init_hstate] * 1) \n",
    "        #fake_obs = tuple(jnp.stack([x] * batch_size) for x in init_x)\n",
    "        #fake_action = jnp.zeros(shape=(action_size,))\n",
    "        #critic_params = self._critic_network.init(subkey, fake_hstate, fake_obs, fake_action)\n",
    "\n",
    "        fake_x = (\n",
    "            jnp.zeros(\n",
    "                (1, config[\"NUM_ENVS\"], env.observation_space(env.agents[0]).shape[0])\n",
    "            ),\n",
    "            jnp.zeros((1, config[\"NUM_ENVS\"])),\n",
    "            jnp.zeros((1, config[\"NUM_ENVS\"], env.action_space(env.agents[0]).n)),\n",
    "        )\n",
    "        fake_hstate = ScannedRNN.initialize_carry(config[\"NUM_ENVS\"], config[\"GRU_HIDDEN_DIM\"])\n",
    "        fake_action = jnp.zeros(shape=(action_size,))\n",
    "        critic_params = self._critic_network.init(subkey, fake_hstate, fake_x, fake_action)\n",
    "\n",
    "        #target_critic_params = jax.tree.map(lambda x: x, critic_params)\n",
    "\n",
    "        #actor_params = jax.tree.map(lambda x: x[0], genotypes)\n",
    "        #target_actor_params = jax.tree.map(lambda x: x[0], genotypes)\n",
    "\n",
    "        # Prepare init optimizer states\n",
    "        #critic_optimizer_state = self._critic_optimizer.init(critic_params)\n",
    "        #actor_optimizer_state = self._actor_optimizer.init(actor_params)\n",
    "\n",
    "        # Initialize replay buffer\n",
    "        dummy_transition = QDTransition.init_dummy(\n",
    "            observation_dim=observation_size,\n",
    "            action_dim=action_size,\n",
    "            descriptor_dim=descriptor_size,\n",
    "        )\n",
    "\n",
    "        replay_buffer = ReplayBuffer.init(\n",
    "            buffer_size=self._config.replay_buffer_size, transition=dummy_transition\n",
    "        )\n",
    "\n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        #print(\"Transitions type:\", type(transitions))\n",
    "        #print(\"Transitions fields:\", transitions)\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        replay_buffer = replay_buffer.insert(transitions)\n",
    "\n",
    "        '''\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        '''\n",
    "        init_x = (\n",
    "            jnp.zeros(\n",
    "                (1, 1, wrapped_env.obs_size)\n",
    "            ),  # (time_step, batch_size, obs_size)\n",
    "            jnp.zeros((1, 1)),  # (time_step, batch size)\n",
    "        )\n",
    "        init_hs = ScannedRNN.initialize_carry(\n",
    "            config[\"HIDDEN_SIZE\"], 1\n",
    "        )  # (batch_size, hidden_dim)\n",
    "        network_params = policy_network.init(rng, init_hs, *init_x)\n",
    "\n",
    "        lr_scheduler = optax.linear_schedule(\n",
    "            init_value=config[\"LR\"],\n",
    "            end_value=1e-10,\n",
    "            transition_steps=(config[\"NUM_EPOCHS\"]) * config[\"NUM_UPDATES\"],\n",
    "        )\n",
    "\n",
    "        lr = lr_scheduler if config.get(\"LR_LINEAR_DECAY\", False) else config[\"LR\"]\n",
    "\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.radam(learning_rate=lr),\n",
    "        )\n",
    "\n",
    "        train_state = CustomTrainState.create(\n",
    "            apply_fn=policy_network.apply,\n",
    "            params=network_params,\n",
    "            target_network_params=network_params,\n",
    "            tx=tx,\n",
    "        )\n",
    "        '''\n",
    "        # INIT BUFFER\n",
    "        # to initalize the buffer is necessary to sample a trajectory to know its strucutre\n",
    "        def _env_sample_step(env_state, unused):\n",
    "            rng, key_a, key_s = jax.random.split(\n",
    "                jax.random.PRNGKey(0), 3\n",
    "            )  # use a dummy rng here\n",
    "            key_a = jax.random.split(key_a, env.num_agents)\n",
    "            actions = {\n",
    "                agent: self._env.batch_sample(key_a[i], agent)\n",
    "                for i, agent in enumerate(env.agents)\n",
    "            }\n",
    "            avail_actions = self._env.get_valid_actions(env_state.env_state)\n",
    "            obs, env_state, rewards, dones, infos = self._env.batch_step(\n",
    "                key_s, env_state, actions\n",
    "            )\n",
    "            timestep = Timestep(\n",
    "                obs=obs,\n",
    "                actions=actions,\n",
    "                rewards=rewards,\n",
    "                dones=dones,\n",
    "                avail_actions=avail_actions,\n",
    "            )\n",
    "            return env_state, timestep\n",
    "\n",
    "        _, _env_state = self._env.batch_reset(key)\n",
    "        _, sample_traj = jax.lax.scan(\n",
    "            _env_sample_step, _env_state, None, self._config.num_steps\n",
    "        )\n",
    "        sample_traj_unbatched = jax.tree.map(\n",
    "            lambda x: x[:, 0], sample_traj\n",
    "        )  # remove the NUM_ENV dim\n",
    "        \n",
    "        # Remove time dimension\n",
    "        sample_traj_unbatched = jax.tree.map(lambda x: x[:, 0], sample_traj)  # (16, …)\n",
    "        # Tile across parallel_policies(batch_size) to match real add_batch_size\n",
    "        #sample_traj_unbatched = jax.tree.map(\n",
    "        #    lambda x: jnp.repeat(x, batch_size, axis=0),\n",
    "        #    sample_traj_unbatched\n",
    "        #)  # now (128, …)\n",
    "        \n",
    "        #print(\"Init sample_traj shape:\", jax.tree.map(lambda x: x.shape, sample_traj_unbatched))\n",
    "        buffer_state = self._buffer.init(sample_traj_unbatched)\n",
    "        \n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        #replay_buffer = replay_buffer.insert(transitions)\n",
    "        # BUFFER UPDATE\n",
    "        #print(\"Transitions keys:\", transitions.keys())\n",
    "        #for k, v in transitions.items():\n",
    "        #    print(k, v.shape, v.dtype)\n",
    "        \n",
    "        #jax.tree.map(lambda x: print(x.shape), transitions)\n",
    "        #jax.tree.map(lambda x: print(\"Buffer expects:\", x.shape), buffer_state.experience)\n",
    "        \n",
    "        def prepare_for_buffer(x):\n",
    "            # x: (P, T, E, *feat_dims)\n",
    "            P, T, E, *feat_dims = x.shape\n",
    "\n",
    "            # First move to (P, E, T, *feat_dims)\n",
    "            x = x.transpose(0, 2, 1, *range(3, x.ndim))\n",
    "\n",
    "            # Merge P * E into batch\n",
    "            x = x.reshape(P * E, T, *feat_dims)\n",
    "\n",
    "            # Add dummy seq_len=1 in the middle -> (batch, 1, T, feat_dim...)\n",
    "            x = x[:, np.newaxis, ...]\n",
    "\n",
    "            return x\n",
    "        \n",
    "        buffer_traj_batch = jax.tree.map(\n",
    "            prepare_for_buffer,\n",
    "            transitions\n",
    "        )\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(x, 0, 1)[\n",
    "        #        :, np.newaxis\n",
    "        #    ],  # put the batch dim first and add a dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)  # (num_envs, 1, time_steps, ...)\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(\n",
    "        #        # Reorder from (num_policies, time_steps, num_envs, …)\n",
    "        #        # → (time_steps, num_policies, num_envs, …)\n",
    "        #        x.transpose(1, 0, 2, *range(3, x.ndim))\n",
    "        #        # Merge num_policies * num_envs into one dimension\n",
    "        #        .reshape(x.shape[1], -1, *x.shape[3:]),\n",
    "        #        0, 1  # swap (time_steps, merged_envs, …) → (merged_envs, time_steps, …)\n",
    "        #    )[:, np.newaxis],  # add dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)\n",
    "        #print(\"Runtime sample_traj shape:\", jax.tree.map(lambda x: x.shape, buffer_traj_batch))\n",
    "\n",
    "        buffer_state = self._buffer.add(buffer_state, buffer_traj_batch)\n",
    "\n",
    "\n",
    "        # Initial training state\n",
    "        #emitter_state = QualityPGEmitterState(\n",
    "        #    critic_params=critic_params,\n",
    "        #    critic_optimizer_state=critic_optimizer_state,\n",
    "        #    actor_params=actor_params,\n",
    "        #    actor_opt_state=actor_optimizer_state,\n",
    "        #    target_critic_params=target_critic_params,\n",
    "        #    target_actor_params=target_actor_params,\n",
    "        #    replay_buffer=replay_buffer,\n",
    "        #    key=key,\n",
    "        #)\n",
    "\n",
    "        # Initial training state\n",
    "        emitter_state = CustomQualityPGEmitterState(\n",
    "            #critic_params=None, #critic_params,\n",
    "            #critic_optimizer_state=None, #critic_optimizer_state,\n",
    "            #actor_params=None, #actor_params,\n",
    "            #actor_opt_state=None, #actor_optimizer_state,\n",
    "            #target_critic_params=None, #target_critic_params,\n",
    "            #target_actor_params=None, #target_actor_params,\n",
    "            #replay_buffer=buffer,\n",
    "            buffer_state=buffer_state,\n",
    "            key=key,\n",
    "        )\n",
    "\n",
    "        return emitter_state\n",
    "\n",
    "    def emit(  # type: ignore\n",
    "        self,\n",
    "        repertoire: GARepertoire,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        key: RNGKey,\n",
    "    ) -> Tuple[Genotype, ExtraScores]:\n",
    "        \"\"\"Do a step of PG emission.\n",
    "\n",
    "        Args:\n",
    "            repertoire: the current repertoire of genotypes\n",
    "            emitter_state: the state of the emitter used\n",
    "            key: a random key\n",
    "\n",
    "        Returns:\n",
    "            A batch of offspring, a empty dict for signature.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = self._config.env_batch_size\n",
    "\n",
    "        # sample parents\n",
    "        mutation_pg_batch_size = int(batch_size) #int(batch_size - 1)\n",
    "        parents = repertoire.select(\n",
    "            key, mutation_pg_batch_size, selector=self._selector\n",
    "        ).genotypes\n",
    "\n",
    "        # apply the pg mutation\n",
    "        offsprings_pg = self.emit_pg(emitter_state, parents)\n",
    "\n",
    "        # get the actor (greedy actor)\n",
    "        #offspring_actor = self.emit_actor(emitter_state)\n",
    "\n",
    "        # add dimension for concatenation\n",
    "        #offspring_actor = jax.tree.map(\n",
    "        #    lambda x: jnp.expand_dims(x, axis=0), offspring_actor\n",
    "        #)\n",
    "        # gather offspring\n",
    "        #genotypes = jax.tree.map(\n",
    "        #    lambda x, y: jnp.concatenate([x, y], axis=0),\n",
    "        #    offsprings_pg,\n",
    "        #    offspring_actor,\n",
    "        #)\n",
    "        genotypes = offsprings_pg\n",
    "\n",
    "        return genotypes, {}\n",
    "\n",
    "    def emit_pg(\n",
    "        self, emitter_state: CustomQualityPGEmitterState, parents: Genotype\n",
    "    ) -> Genotype:\n",
    "        \"\"\"Emit the offsprings generated through pg mutation.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: current emitter state, contains critic and\n",
    "                replay buffer.\n",
    "            parents: the parents selected to be applied gradients in order\n",
    "                to mutate towards better performance.\n",
    "\n",
    "        Returns:\n",
    "            A new set of offsprings.\n",
    "        \"\"\"\n",
    "\n",
    "        # create a batch of policy optimizer states\n",
    "        policy_opt_states = jax.vmap(self._policies_optimizer.init)(parents)\n",
    "\n",
    "        # prepare the batched policy update function with vmapping\n",
    "        batched_policy_update_fn = jax.vmap(\n",
    "            partial(self._update_policy, emitter_state=emitter_state), #critic_params=emitter_state.critic_params),\n",
    "            in_axes=(0, 0)#, None),\n",
    "        )\n",
    "\n",
    "        def scan_update_policies(\n",
    "            carry: Tuple[Params, optax.OptState, RNGKey],\n",
    "            _: None,\n",
    "        ) -> Tuple[Tuple[Params, optax.OptState, RNGKey], Any]:\n",
    "\n",
    "            # Unpack the carry\n",
    "            (policy_params, policy_opt_state, key) = carry\n",
    "            key, subkey = jax.random.split(key)\n",
    "\n",
    "            # sample a mini-batch of data from the replay-buffer\n",
    "            #transitions = emitter_state.replay_buffer.sample(\n",
    "            #    subkey, self._config.batch_size\n",
    "            #)\n",
    "\n",
    "            #transitions = emitter_state.replay_buffer.sample(emitter_state.buffer_state, key).experience\n",
    "            (\n",
    "                new_policy_params,\n",
    "                new_policy_opt_states,\n",
    "            ) = batched_policy_update_fn(policy_params, policy_opt_state)#transitions)\n",
    "            return (new_policy_params, new_policy_opt_states, key), ()\n",
    "\n",
    "        (\n",
    "            final_policy_params,\n",
    "            final_policy_opt_state,\n",
    "            final_key,\n",
    "        ), _ = jax.lax.scan(\n",
    "            scan_update_policies,\n",
    "            (parents, policy_opt_states, emitter_state.key),\n",
    "            length=self._config.num_pg_training_steps,\n",
    "        )\n",
    "\n",
    "        return final_policy_params\n",
    "\n",
    "    def emit_actor(self, emitter_state: CustomQualityPGEmitterState) -> Genotype:\n",
    "        \"\"\"Emit the greedy actor.\n",
    "\n",
    "        Simply needs to be retrieved from the emitter state.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: the current emitter state, it stores the\n",
    "                greedy actor.\n",
    "\n",
    "        Returns:\n",
    "            The parameters of the actor.\n",
    "        \"\"\"\n",
    "        return emitter_state.actor_params\n",
    "\n",
    "    def state_update(  # type: ignore\n",
    "        self,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        repertoire: Optional[Repertoire],\n",
    "        genotypes: Optional[Genotype],\n",
    "        fitnesses: Optional[Fitness],\n",
    "        descriptors: Optional[Descriptor],\n",
    "        extra_scores: ExtraScores,\n",
    "    ) -> CustomQualityPGEmitterState:\n",
    "        \"\"\"This function gives an opportunity to update the emitter state\n",
    "        after the genotypes have been scored.\n",
    "\n",
    "        Here it is used to fill the Replay Buffer with the transitions\n",
    "        from the scoring of the genotypes, and then the training of the\n",
    "        critic/actor happens. Hence the params of critic/actor are updated,\n",
    "        as well as their optimizer states.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: current emitter state.\n",
    "            repertoire: the current genotypes repertoire\n",
    "            genotypes: unused here - but compulsory in the signature.\n",
    "            fitnesses: unused here - but compulsory in the signature.\n",
    "            descriptors: unused here - but compulsory in the signature.\n",
    "            extra_scores: extra information coming from the scoring function,\n",
    "                this contains the transitions added to the replay buffer.\n",
    "\n",
    "        Returns:\n",
    "            New emitter state where the replay buffer has been filled with\n",
    "            the new experienced transitions.\n",
    "        \"\"\"\n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        def prepare_for_buffer(x):\n",
    "            # x: (P, T, E, *feat_dims)\n",
    "            P, T, E, *feat_dims = x.shape\n",
    "\n",
    "            # First move to (P, E, T, *feat_dims)\n",
    "            x = x.transpose(0, 2, 1, *range(3, x.ndim))\n",
    "\n",
    "            # Merge P * E into batch\n",
    "            x = x.reshape(P * E, T, *feat_dims)\n",
    "\n",
    "            # Add dummy seq_len=1 in the middle -> (batch, 1, T, feat_dim...)\n",
    "            x = x[:, np.newaxis, ...]\n",
    "\n",
    "            return x\n",
    "        \n",
    "        buffer_traj_batch = jax.tree.map(\n",
    "            prepare_for_buffer,\n",
    "            transitions\n",
    "        )\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(x, 0, 1)[\n",
    "        #        :, np.newaxis\n",
    "        #    ],  # put the batch dim first and add a dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)  # (num_envs, 1, time_steps, ...)\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(\n",
    "        #        # Reorder from (num_policies, time_steps, num_envs, …)\n",
    "        #        # → (time_steps, num_policies, num_envs, …)\n",
    "        #        x.transpose(1, 0, 2, *range(3, x.ndim))\n",
    "        #        # Merge num_policies * num_envs into one dimension\n",
    "        #        .reshape(x.shape[1], -1, *x.shape[3:]),\n",
    "        #        0, 1  # swap (time_steps, merged_envs, …) → (merged_envs, time_steps, …)\n",
    "        #    )[:, np.newaxis],  # add dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)\n",
    "        new_buffer_state = self._buffer.add(emitter_state.buffer_state, buffer_traj_batch)\n",
    "        final_emitter_state = emitter_state.replace(buffer_state=new_buffer_state)\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        #emitter_state = emitter_state.replace(\n",
    "        #    replay_buffer=emitter_state.replay_buffer.insert(transitions)\n",
    "        #)\n",
    "        \n",
    "        # Conduct Actor-Critic training\n",
    "        #final_emitter_state, _ = jax.lax.scan(\n",
    "        #    self._scan_actor_critic_training,\n",
    "        #    emitter_state,\n",
    "        #    length=self._actor_critic_iterations,\n",
    "        #)\n",
    "\n",
    "        return final_emitter_state  # type: ignore\n",
    "\n",
    "    def _update_policy(\n",
    "        self,\n",
    "        policy_params: Params,\n",
    "        policy_opt_state: optax.OptState,\n",
    "        #transitions: QDTransition,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        #critic_params: Params,\n",
    "    ) -> Tuple[optax.OptState, Params]:\n",
    "        \"\"\"\n",
    "        Perform one step of PG update on the off-spring policy.\n",
    "        This function is vmapped to mutate the entire batch of off-springs\n",
    "        in parallel.\n",
    "\n",
    "        Args:\n",
    "            policy_params: the parameters of the policy.\n",
    "            policy_opt_state: the optimiser state of the policy.\n",
    "            transitions: a mini-batch of transitions for gradient computation\n",
    "            critic_params: the parameters of the critic networks serving as\n",
    "                a differentiable target. This is fixed in each iteration.\n",
    "\n",
    "        Returns:\n",
    "            new_policy_params: new policy parameters\n",
    "            new_policy_opt_state: updated optimiser state\n",
    "        \"\"\"\n",
    "        new_target_params = policy_params\n",
    "\n",
    "        # SAMPLE minibatches for each grad update\n",
    "        key = emitter_state.key\n",
    "        minibatches_list = []\n",
    "\n",
    "        for _ in range(self._config.target_update_interval):\n",
    "            key, subkey = jax.random.split(key)\n",
    "            minibatch = self._buffer.sample(emitter_state.buffer_state, subkey).experience\n",
    "            minibatches_list.append(minibatch)\n",
    "\n",
    "        # Stack into [num_updates, ...] pytree\n",
    "        minibatches = jax.tree.map(lambda *xs: jnp.stack(xs), *minibatches_list)\n",
    "\n",
    "        # Update key back into emitter_state\n",
    "        emitter_state = emitter_state.replace(key=key)\n",
    "\n",
    "        def _apply_grad_update(carry, minibatch):\n",
    "            # Compute the policy gradient\n",
    "            policy_params, policy_opt_state = carry\n",
    "\n",
    "            policy_gradient = jax.grad(self._policy_loss_fn)(\n",
    "                policy_params,\n",
    "                #critic_params,\n",
    "                #transitions,\n",
    "                new_target_params,\n",
    "                #emitter_state\n",
    "                minibatch\n",
    "            )\n",
    "            # Apply the update on the policy\n",
    "            (\n",
    "                policy_updates,\n",
    "                new_policy_opt_state,\n",
    "            ) = self._policies_optimizer.update(policy_gradient, policy_opt_state)\n",
    "            new_policy_params = optax.apply_updates(policy_params, policy_updates)\n",
    "\n",
    "            return (new_policy_params, new_policy_opt_state), ()\n",
    "        \n",
    "        (new_policy_params, new_policy_opt_state), _ = jax.lax.scan(\n",
    "            _apply_grad_update, \n",
    "            (policy_params, policy_opt_state), \n",
    "            #length=config[\"TARGET_UPDATE_INTERVAL\"]\n",
    "            minibatches,\n",
    "            )\n",
    "        \n",
    "        new_target_params = optax.incremental_update(\n",
    "                        new_policy_params, #train_state.params,\n",
    "                        new_target_params, #train_state.target_network_params,\n",
    "                        self._config.tau,\n",
    "                    )\n",
    "\n",
    "        return new_target_params, new_policy_opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02557c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the scoring function\n",
    "# descriptor_extraction_fn = environments.descriptor_extractor[env_name] # Need to write my own function to extract descriptors\n",
    "scoring_fn = functools.partial(\n",
    "    scoring_function,\n",
    "    episode_length=episode_length,\n",
    "    play_reset_fn=reset_fn,\n",
    "    play_step_fn=play_step_fn,\n",
    "    descriptor_extractor=descriptor_extraction_fn,\n",
    ")\n",
    "\n",
    "# Get minimum reward value to make sure qd_score are positive\n",
    "#reward_offset = environments.reward_offset[env_name]\n",
    "\n",
    "# Define a metrics function\n",
    "metrics_function = functools.partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=1#reward_offset * episode_length, # Used to ensure QD score is positive could set to 1 if not needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb38e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myPGAMEEmitter(MultiEmitter):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: PGAMEConfig,\n",
    "        policy_network: nn.Module,\n",
    "        env: QDEnv,\n",
    "        variation_fn: Callable[[Params, Params, RNGKey], Tuple[Params, RNGKey]],\n",
    "        selector: Optional[Selector] = None,\n",
    "    ) -> None:\n",
    "\n",
    "        self._config = config\n",
    "        self._policy_network = policy_network\n",
    "        self._env = env\n",
    "        self._variation_fn = variation_fn\n",
    "\n",
    "        ga_batch_size = int(self._config.proportion_mutation_ga * config.env_batch_size)\n",
    "        qpg_batch_size = config.env_batch_size - ga_batch_size\n",
    "\n",
    "        @dataclass\n",
    "        class CustomQualityPGConfig(QualityPGConfig):\n",
    "            num_envs: Any = None\n",
    "            num_steps: Any = None\n",
    "            target_update_interval: Any = None\n",
    "            tau: Any = None\n",
    "                \n",
    "        qpg_config = CustomQualityPGConfig(\n",
    "            env_batch_size=qpg_batch_size,\n",
    "            num_critic_training_steps=config.num_critic_training_steps,\n",
    "            num_pg_training_steps=config.num_pg_training_steps,\n",
    "            replay_buffer_size=config.replay_buffer_size,\n",
    "            critic_hidden_layer_size=config.critic_hidden_layer_size,\n",
    "            critic_learning_rate=config.critic_learning_rate,\n",
    "            actor_learning_rate=config.greedy_learning_rate,\n",
    "            policy_learning_rate=config.policy_learning_rate,\n",
    "            noise_clip=config.noise_clip,\n",
    "            policy_noise=config.policy_noise,\n",
    "            discount=config.discount,\n",
    "            reward_scaling=config.reward_scaling,\n",
    "            batch_size=config.batch_size,\n",
    "            soft_tau_update=config.soft_tau_update,\n",
    "            policy_delay=config.policy_delay,\n",
    "\n",
    "            num_envs = config.num_envs,\n",
    "            num_steps = config.num_steps,\n",
    "            target_update_interval = config.target_update_interval,\n",
    "            tau = config.tau,\n",
    "        )\n",
    "\n",
    "        # define the quality emitter\n",
    "        q_emitter = myQualityPGEmitter(\n",
    "            config=qpg_config,\n",
    "            policy_network=policy_network,\n",
    "            env=env,\n",
    "            selector=selector,\n",
    "        )\n",
    "\n",
    "        # define the GA emitter\n",
    "        ga_emitter = MixingEmitter(\n",
    "            mutation_fn=lambda x, r: (x, r),\n",
    "            variation_fn=variation_fn,\n",
    "            variation_percentage=1.0,\n",
    "            batch_size=ga_batch_size,\n",
    "            selector=selector,\n",
    "        )\n",
    "\n",
    "        super().__init__(emitters=(q_emitter, ga_emitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd1bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define emitter\n",
    "variation_fn = functools.partial(\n",
    "    isoline_variation, iso_sigma=iso_sigma, line_sigma=line_sigma\n",
    ")\n",
    "\n",
    "mixing_emitter = MixingEmitter(\n",
    "    mutation_fn=None,\n",
    "    variation_fn=variation_fn,\n",
    "    variation_percentage=1.0,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "pg_emitter = myPGAMEEmitter(\n",
    "    config=pga_emitter_config,\n",
    "    policy_network=policy_network,\n",
    "    env=wrapped_env, #env,\n",
    "    variation_fn=variation_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598cdaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids: (100, 2)\n",
      "Descriptor dim: 2\n",
      "Network params size (MB): 9.1295\n",
      "Expected repertoire memory (MB): 912.95\n"
     ]
    }
   ],
   "source": [
    "# Instantiate MAP-Elites\n",
    "map_elites = MAPElites(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter=pg_emitter, #mixing_emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")\n",
    "\n",
    "# Compute the centroids\n",
    "key, subkey = jax.random.split(key)\n",
    "#centroids = compute_cvt_centroids(\n",
    "#    num_descriptors=number_of_descriptors,#env.descriptor_length, # Num of dimensions in the descriptor\n",
    "#    num_init_cvt_samples=num_init_cvt_samples,\n",
    "#    num_centroids=num_centroids,\n",
    "#    minval=min_descriptor,\n",
    "#    maxval=max_descriptor,\n",
    "#    key=subkey,\n",
    "#)\n",
    "grid_shape = (10, 10) # (500, 500)\n",
    "centroids = compute_euclidean_centroids(\n",
    "    grid_shape=grid_shape,\n",
    "    minval=min_descriptor,\n",
    "    maxval=max_descriptor,\n",
    ")\n",
    "\n",
    "print(\"Centroids:\", centroids.shape)   # how many?\n",
    "print(\"Descriptor dim:\", centroids.shape[-1])\n",
    "\n",
    "param_bytes = sum(x.size * x.dtype.itemsize for x in jax.tree.leaves(network_params))\n",
    "print(\"Network params size (MB):\", param_bytes / 1e6)\n",
    "\n",
    "total_repertoire_mem_mb = param_bytes/1e6 * centroids.shape[0]\n",
    "print(\"Expected repertoire memory (MB):\", total_repertoire_mem_mb)\n",
    "\n",
    "# Compute initial repertoire and emitter state\n",
    "key, subkey = jax.random.split(key)\n",
    "repertoire, emitter_state, init_metrics = map_elites.init(network_params, centroids, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c314a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_solution_near_descriptor(\n",
    "    repertoire: MapElitesRepertoire,\n",
    "    target_descriptor: jnp.ndarray,\n",
    "    initial_radius: float = 0.1,\n",
    "    max_radius: float = 2.0,\n",
    "    step: float = 0.05,\n",
    ") -> Tuple[Dict[str, jnp.ndarray], float, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Find the best solution near the target descriptor by expanding the radius until one is found.\n",
    "    \"\"\"\n",
    "\n",
    "    radius = initial_radius\n",
    "    found = False\n",
    "    best_params = None\n",
    "    best_fitness = -jnp.inf\n",
    "    best_descriptor = None\n",
    "\n",
    "    while radius <= max_radius and not found:\n",
    "        # Compute distances to centroids\n",
    "        distances = jnp.linalg.norm(repertoire.centroids - target_descriptor, axis=1)\n",
    "\n",
    "        # Find candidates within the radius\n",
    "        candidate_indices = jnp.where(distances < radius)[0]\n",
    "        candidate_fitnesses = repertoire.fitnesses[candidate_indices]\n",
    "        is_valid = candidate_fitnesses > -jnp.inf\n",
    "        #valid_indices = candidate_indices[is_valid]\n",
    "        valid_indices = candidate_indices[is_valid.ravel()]\n",
    "\n",
    "        if valid_indices.size > 0:\n",
    "            found = True\n",
    "            valid_fitnesses = repertoire.fitnesses[valid_indices]\n",
    "            best_idx_in_valid = jnp.argmax(valid_fitnesses)\n",
    "            best_index = valid_indices[best_idx_in_valid]\n",
    "\n",
    "            best_params = jax.tree.map(lambda x: x[best_index], repertoire.genotypes)\n",
    "            best_fitness = repertoire.fitnesses[best_index]\n",
    "            best_descriptor = repertoire.descriptors[best_index]\n",
    "        else:\n",
    "            radius += step\n",
    "\n",
    "    if not found:\n",
    "        # Fall back to dummy values if no solution found at all\n",
    "        best_params = jax.tree.map(lambda x: jnp.zeros_like(x[0]), repertoire.genotypes)\n",
    "        best_descriptor = jnp.zeros_like(repertoire.descriptors[0])\n",
    "        best_fitness = -jnp.inf\n",
    "\n",
    "    return best_params, best_fitness, best_descriptor\n",
    "\n",
    "def get_top_genotypes(repertoire, top_k):\n",
    "    \"\"\"Extract top_k genotypes from a repertoire, returning a clean stacked PyTree.\"\"\"\n",
    "    fitnesses = repertoire.fitnesses\n",
    "    valid_mask = fitnesses > -jnp.inf\n",
    "    valid_fitnesses = jnp.where(valid_mask, fitnesses, -jnp.inf)\n",
    "\n",
    "    # Sort indices by descending fitness\n",
    "    sorted_indices = jnp.argsort(valid_fitnesses)[::-1]\n",
    "    top_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Extract and squeeze each top genotype into a PyTree\n",
    "    top_genotypes_list = [\n",
    "        jax.tree_util.tree_map(lambda x: jnp.squeeze(x[i], axis=0), repertoire.genotypes)\n",
    "        for i in top_indices\n",
    "    ]\n",
    "\n",
    "    # Stack into batched PyTree\n",
    "    top_genotypes = jax.tree_util.tree_map(lambda *xs: jnp.stack(xs), *top_genotypes_list)\n",
    "\n",
    "    return top_genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1d79f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start main loop, num of loops  1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-22 11:05:08.736825: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 3.26GiB (3498332118 bytes) by rematerialization; only reduced to 4.56GiB (4902051199 bytes), down from 4.59GiB (4928533731 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 1/1250\n",
      "loop 2/1250\n",
      "loop 3/1250\n",
      "loop 4/1250\n",
      "loop 5/1250\n",
      "loop 6/1250\n",
      "loop 7/1250\n",
      "loop 8/1250\n",
      "loop 9/1250\n",
      "loop 10/1250\n",
      "loop 11/1250\n",
      "loop 12/1250\n",
      "loop 13/1250\n",
      "loop 14/1250\n",
      "loop 15/1250\n",
      "loop 16/1250\n",
      "loop 17/1250\n",
      "loop 18/1250\n",
      "loop 19/1250\n",
      "loop 20/1250\n",
      "loop 21/1250\n",
      "loop 22/1250\n",
      "loop 23/1250\n",
      "loop 24/1250\n",
      "loop 25/1250\n",
      "loop 26/1250\n",
      "loop 27/1250\n",
      "loop 28/1250\n",
      "loop 29/1250\n",
      "loop 30/1250\n",
      "loop 31/1250\n",
      "loop 32/1250\n",
      "loop 33/1250\n",
      "loop 34/1250\n",
      "loop 35/1250\n",
      "loop 36/1250\n",
      "loop 37/1250\n",
      "loop 38/1250\n",
      "loop 39/1250\n",
      "loop 40/1250\n",
      "loop 41/1250\n",
      "loop 42/1250\n",
      "loop 43/1250\n",
      "loop 44/1250\n",
      "loop 45/1250\n",
      "loop 46/1250\n",
      "loop 47/1250\n",
      "loop 48/1250\n",
      "loop 49/1250\n",
      "loop 50/1250\n",
      "loop 51/1250\n",
      "loop 52/1250\n",
      "loop 53/1250\n",
      "loop 54/1250\n",
      "loop 55/1250\n",
      "loop 56/1250\n",
      "loop 57/1250\n",
      "loop 58/1250\n",
      "loop 59/1250\n",
      "loop 60/1250\n",
      "loop 61/1250\n",
      "loop 62/1250\n",
      "loop 63/1250\n",
      "loop 64/1250\n",
      "loop 65/1250\n",
      "loop 66/1250\n",
      "loop 67/1250\n",
      "loop 68/1250\n",
      "loop 69/1250\n",
      "loop 70/1250\n",
      "loop 71/1250\n",
      "loop 72/1250\n",
      "loop 73/1250\n",
      "loop 74/1250\n",
      "loop 75/1250\n",
      "loop 76/1250\n",
      "loop 77/1250\n",
      "loop 78/1250\n",
      "loop 79/1250\n",
      "loop 80/1250\n",
      "loop 81/1250\n",
      "loop 82/1250\n",
      "loop 83/1250\n",
      "loop 84/1250\n",
      "loop 85/1250\n",
      "loop 86/1250\n",
      "loop 87/1250\n",
      "loop 88/1250\n",
      "loop 89/1250\n",
      "loop 90/1250\n",
      "loop 91/1250\n",
      "loop 92/1250\n",
      "loop 93/1250\n",
      "loop 94/1250\n",
      "loop 95/1250\n",
      "loop 96/1250\n",
      "loop 97/1250\n",
      "loop 98/1250\n",
      "loop 99/1250\n",
      "loop 100/1250\n",
      "loop 101/1250\n",
      "loop 102/1250\n",
      "loop 103/1250\n",
      "loop 104/1250\n",
      "loop 105/1250\n",
      "loop 106/1250\n",
      "loop 107/1250\n",
      "loop 108/1250\n",
      "loop 109/1250\n",
      "loop 110/1250\n",
      "loop 111/1250\n",
      "loop 112/1250\n",
      "loop 113/1250\n",
      "loop 114/1250\n",
      "loop 115/1250\n",
      "loop 116/1250\n",
      "loop 117/1250\n",
      "loop 118/1250\n",
      "loop 119/1250\n",
      "loop 120/1250\n",
      "loop 121/1250\n",
      "loop 122/1250\n",
      "loop 123/1250\n",
      "loop 124/1250\n",
      "loop 125/1250\n",
      "loop 126/1250\n",
      "loop 127/1250\n",
      "loop 128/1250\n",
      "loop 129/1250\n",
      "loop 130/1250\n",
      "loop 131/1250\n",
      "loop 132/1250\n",
      "loop 133/1250\n",
      "loop 134/1250\n",
      "loop 135/1250\n",
      "loop 136/1250\n",
      "loop 137/1250\n",
      "loop 138/1250\n",
      "loop 139/1250\n",
      "loop 140/1250\n",
      "loop 141/1250\n",
      "loop 142/1250\n",
      "loop 143/1250\n",
      "loop 144/1250\n",
      "loop 145/1250\n",
      "loop 146/1250\n",
      "loop 147/1250\n",
      "loop 148/1250\n",
      "loop 149/1250\n",
      "loop 150/1250\n",
      "loop 151/1250\n",
      "loop 152/1250\n",
      "loop 153/1250\n",
      "loop 154/1250\n",
      "loop 155/1250\n",
      "loop 156/1250\n",
      "loop 157/1250\n",
      "loop 158/1250\n",
      "loop 159/1250\n",
      "loop 160/1250\n",
      "loop 161/1250\n",
      "loop 162/1250\n",
      "loop 163/1250\n",
      "loop 164/1250\n",
      "loop 165/1250\n",
      "loop 166/1250\n",
      "loop 167/1250\n",
      "loop 168/1250\n",
      "loop 169/1250\n",
      "loop 170/1250\n",
      "loop 171/1250\n",
      "loop 172/1250\n",
      "loop 173/1250\n",
      "loop 174/1250\n",
      "loop 175/1250\n",
      "loop 176/1250\n",
      "loop 177/1250\n",
      "loop 178/1250\n",
      "loop 179/1250\n",
      "loop 180/1250\n",
      "loop 181/1250\n",
      "loop 182/1250\n",
      "loop 183/1250\n",
      "loop 184/1250\n",
      "loop 185/1250\n",
      "loop 186/1250\n",
      "loop 187/1250\n",
      "loop 188/1250\n",
      "loop 189/1250\n",
      "loop 190/1250\n",
      "loop 191/1250\n",
      "loop 192/1250\n",
      "loop 193/1250\n",
      "loop 194/1250\n",
      "loop 195/1250\n",
      "loop 196/1250\n",
      "loop 197/1250\n",
      "loop 198/1250\n",
      "loop 199/1250\n",
      "loop 200/1250\n",
      "loop 201/1250\n",
      "loop 202/1250\n",
      "loop 203/1250\n",
      "loop 204/1250\n",
      "loop 205/1250\n",
      "loop 206/1250\n",
      "loop 207/1250\n",
      "loop 208/1250\n",
      "loop 209/1250\n",
      "loop 210/1250\n",
      "loop 211/1250\n",
      "loop 212/1250\n",
      "loop 213/1250\n",
      "loop 214/1250\n",
      "loop 215/1250\n",
      "loop 216/1250\n",
      "loop 217/1250\n",
      "loop 218/1250\n",
      "loop 219/1250\n",
      "loop 220/1250\n",
      "loop 221/1250\n",
      "loop 222/1250\n",
      "loop 223/1250\n",
      "loop 224/1250\n",
      "loop 225/1250\n",
      "loop 226/1250\n",
      "loop 227/1250\n",
      "loop 228/1250\n",
      "loop 229/1250\n",
      "loop 230/1250\n",
      "loop 231/1250\n",
      "loop 232/1250\n",
      "loop 233/1250\n",
      "loop 234/1250\n",
      "loop 235/1250\n",
      "loop 236/1250\n",
      "loop 237/1250\n",
      "loop 238/1250\n",
      "loop 239/1250\n",
      "loop 240/1250\n",
      "loop 241/1250\n",
      "loop 242/1250\n",
      "loop 243/1250\n",
      "loop 244/1250\n",
      "loop 245/1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0822 12:39:10.249014 2621860 hlo_lexer.cc:443] Failed to parse int literal: 07258731385375554245137\n",
      "E0822 12:39:10.249071 2621860 hlo_lexer.cc:443] Failed to parse int literal: 07258731385375554245137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 246/1250\n",
      "loop 247/1250\n",
      "loop 248/1250\n",
      "loop 249/1250\n",
      "loop 250/1250\n",
      "loop 251/1250\n",
      "loop 252/1250\n",
      "loop 253/1250\n",
      "loop 254/1250\n",
      "loop 255/1250\n",
      "loop 256/1250\n",
      "loop 257/1250\n",
      "loop 258/1250\n",
      "loop 259/1250\n",
      "loop 260/1250\n",
      "loop 261/1250\n",
      "loop 262/1250\n",
      "loop 263/1250\n",
      "loop 264/1250\n",
      "loop 265/1250\n",
      "loop 266/1250\n",
      "loop 267/1250\n",
      "loop 268/1250\n",
      "loop 269/1250\n",
      "loop 270/1250\n",
      "loop 271/1250\n",
      "loop 272/1250\n",
      "loop 273/1250\n",
      "loop 274/1250\n",
      "loop 275/1250\n",
      "loop 276/1250\n",
      "loop 277/1250\n",
      "loop 278/1250\n",
      "loop 279/1250\n",
      "loop 280/1250\n",
      "loop 281/1250\n",
      "loop 282/1250\n",
      "loop 283/1250\n",
      "loop 284/1250\n",
      "loop 285/1250\n",
      "loop 286/1250\n",
      "loop 287/1250\n",
      "loop 288/1250\n",
      "loop 289/1250\n",
      "loop 290/1250\n",
      "loop 291/1250\n",
      "loop 292/1250\n",
      "loop 293/1250\n",
      "loop 294/1250\n",
      "loop 295/1250\n",
      "loop 296/1250\n",
      "loop 297/1250\n",
      "loop 298/1250\n",
      "loop 299/1250\n",
      "loop 300/1250\n",
      "loop 301/1250\n",
      "loop 302/1250\n",
      "loop 303/1250\n",
      "loop 304/1250\n",
      "loop 305/1250\n",
      "loop 306/1250\n",
      "loop 307/1250\n",
      "loop 308/1250\n",
      "loop 309/1250\n",
      "loop 310/1250\n",
      "loop 311/1250\n",
      "loop 312/1250\n",
      "loop 313/1250\n",
      "loop 314/1250\n",
      "loop 315/1250\n",
      "loop 316/1250\n",
      "loop 317/1250\n",
      "loop 318/1250\n",
      "loop 319/1250\n",
      "loop 320/1250\n",
      "loop 321/1250\n",
      "loop 322/1250\n",
      "loop 323/1250\n",
      "loop 324/1250\n",
      "loop 325/1250\n",
      "loop 326/1250\n",
      "loop 327/1250\n",
      "loop 328/1250\n",
      "loop 329/1250\n",
      "loop 330/1250\n",
      "loop 331/1250\n",
      "loop 332/1250\n",
      "loop 333/1250\n",
      "loop 334/1250\n",
      "loop 335/1250\n",
      "loop 336/1250\n",
      "loop 337/1250\n",
      "loop 338/1250\n",
      "loop 339/1250\n",
      "loop 340/1250\n",
      "loop 341/1250\n",
      "loop 342/1250\n",
      "loop 343/1250\n",
      "loop 344/1250\n",
      "loop 345/1250\n",
      "loop 346/1250\n",
      "loop 347/1250\n",
      "loop 348/1250\n",
      "loop 349/1250\n",
      "loop 350/1250\n",
      "loop 351/1250\n",
      "loop 352/1250\n",
      "loop 353/1250\n",
      "loop 354/1250\n",
      "loop 355/1250\n",
      "loop 356/1250\n",
      "loop 357/1250\n",
      "loop 358/1250\n",
      "loop 359/1250\n",
      "loop 360/1250\n",
      "loop 361/1250\n",
      "loop 362/1250\n",
      "loop 363/1250\n",
      "loop 364/1250\n",
      "loop 365/1250\n",
      "loop 366/1250\n",
      "loop 367/1250\n",
      "loop 368/1250\n",
      "loop 369/1250\n",
      "loop 370/1250\n",
      "loop 371/1250\n",
      "loop 372/1250\n",
      "loop 373/1250\n",
      "loop 374/1250\n",
      "loop 375/1250\n",
      "loop 376/1250\n",
      "loop 377/1250\n",
      "loop 378/1250\n",
      "loop 379/1250\n",
      "loop 380/1250\n",
      "loop 381/1250\n",
      "loop 382/1250\n",
      "loop 383/1250\n",
      "loop 384/1250\n",
      "loop 385/1250\n",
      "loop 386/1250\n",
      "loop 387/1250\n",
      "loop 388/1250\n",
      "loop 389/1250\n",
      "loop 390/1250\n",
      "loop 391/1250\n",
      "loop 392/1250\n",
      "loop 393/1250\n",
      "loop 394/1250\n",
      "loop 395/1250\n",
      "loop 396/1250\n",
      "loop 397/1250\n",
      "loop 398/1250\n",
      "loop 399/1250\n",
      "loop 400/1250\n",
      "loop 401/1250\n",
      "loop 402/1250\n",
      "loop 403/1250\n",
      "loop 404/1250\n",
      "loop 405/1250\n",
      "loop 406/1250\n",
      "loop 407/1250\n",
      "loop 408/1250\n",
      "loop 409/1250\n",
      "loop 410/1250\n",
      "loop 411/1250\n",
      "loop 412/1250\n",
      "loop 413/1250\n",
      "loop 414/1250\n",
      "loop 415/1250\n",
      "loop 416/1250\n",
      "loop 417/1250\n",
      "loop 418/1250\n",
      "loop 419/1250\n",
      "loop 420/1250\n",
      "loop 421/1250\n",
      "loop 422/1250\n",
      "loop 423/1250\n",
      "loop 424/1250\n",
      "loop 425/1250\n",
      "loop 426/1250\n",
      "loop 427/1250\n",
      "loop 428/1250\n",
      "loop 429/1250\n",
      "loop 430/1250\n",
      "loop 431/1250\n",
      "loop 432/1250\n",
      "loop 433/1250\n",
      "loop 434/1250\n",
      "loop 435/1250\n",
      "loop 436/1250\n",
      "loop 437/1250\n",
      "loop 438/1250\n",
      "loop 439/1250\n",
      "loop 440/1250\n",
      "loop 441/1250\n",
      "loop 442/1250\n",
      "loop 443/1250\n",
      "loop 444/1250\n",
      "loop 445/1250\n",
      "loop 446/1250\n",
      "loop 447/1250\n",
      "loop 448/1250\n",
      "loop 449/1250\n",
      "loop 450/1250\n",
      "loop 451/1250\n",
      "loop 452/1250\n",
      "loop 453/1250\n",
      "loop 454/1250\n",
      "loop 455/1250\n",
      "loop 456/1250\n",
      "loop 457/1250\n",
      "loop 458/1250\n",
      "loop 459/1250\n",
      "loop 460/1250\n",
      "loop 461/1250\n",
      "loop 462/1250\n",
      "loop 463/1250\n",
      "loop 464/1250\n",
      "loop 465/1250\n",
      "loop 466/1250\n",
      "loop 467/1250\n",
      "loop 468/1250\n",
      "loop 469/1250\n",
      "loop 470/1250\n",
      "loop 471/1250\n",
      "loop 472/1250\n",
      "loop 473/1250\n",
      "loop 474/1250\n",
      "loop 475/1250\n",
      "loop 476/1250\n",
      "loop 477/1250\n",
      "loop 478/1250\n",
      "loop 479/1250\n",
      "loop 480/1250\n",
      "loop 481/1250\n",
      "loop 482/1250\n",
      "loop 483/1250\n",
      "loop 484/1250\n",
      "loop 485/1250\n",
      "loop 486/1250\n",
      "loop 487/1250\n",
      "loop 488/1250\n",
      "loop 489/1250\n",
      "loop 490/1250\n",
      "loop 491/1250\n",
      "loop 492/1250\n",
      "loop 493/1250\n",
      "loop 494/1250\n",
      "loop 495/1250\n",
      "loop 496/1250\n",
      "loop 497/1250\n",
      "loop 498/1250\n",
      "loop 499/1250\n",
      "loop 500/1250\n",
      "loop 501/1250\n",
      "loop 502/1250\n",
      "loop 503/1250\n",
      "loop 504/1250\n",
      "loop 505/1250\n",
      "loop 506/1250\n",
      "loop 507/1250\n",
      "loop 508/1250\n",
      "loop 509/1250\n",
      "loop 510/1250\n",
      "loop 511/1250\n",
      "loop 512/1250\n",
      "loop 513/1250\n",
      "loop 514/1250\n",
      "loop 515/1250\n",
      "loop 516/1250\n",
      "loop 517/1250\n",
      "loop 518/1250\n",
      "loop 519/1250\n",
      "loop 520/1250\n",
      "loop 521/1250\n",
      "loop 522/1250\n",
      "loop 523/1250\n",
      "loop 524/1250\n",
      "loop 525/1250\n",
      "loop 526/1250\n",
      "loop 527/1250\n",
      "loop 528/1250\n",
      "loop 529/1250\n",
      "loop 530/1250\n",
      "loop 531/1250\n",
      "loop 532/1250\n",
      "loop 533/1250\n",
      "loop 534/1250\n",
      "loop 535/1250\n",
      "loop 536/1250\n",
      "loop 537/1250\n",
      "loop 538/1250\n",
      "loop 539/1250\n",
      "loop 540/1250\n",
      "loop 541/1250\n",
      "loop 542/1250\n",
      "loop 543/1250\n",
      "loop 544/1250\n",
      "loop 545/1250\n",
      "loop 546/1250\n",
      "loop 547/1250\n",
      "loop 548/1250\n",
      "loop 549/1250\n",
      "loop 550/1250\n",
      "loop 551/1250\n",
      "loop 552/1250\n",
      "loop 553/1250\n",
      "loop 554/1250\n",
      "loop 555/1250\n",
      "loop 556/1250\n",
      "loop 557/1250\n",
      "loop 558/1250\n",
      "loop 559/1250\n",
      "loop 560/1250\n",
      "loop 561/1250\n",
      "loop 562/1250\n",
      "loop 563/1250\n",
      "loop 564/1250\n",
      "loop 565/1250\n",
      "loop 566/1250\n",
      "loop 567/1250\n",
      "loop 568/1250\n",
      "loop 569/1250\n",
      "loop 570/1250\n",
      "loop 571/1250\n",
      "loop 572/1250\n",
      "loop 573/1250\n",
      "loop 574/1250\n",
      "loop 575/1250\n",
      "loop 576/1250\n",
      "loop 577/1250\n",
      "loop 578/1250\n",
      "loop 579/1250\n",
      "loop 580/1250\n",
      "loop 581/1250\n",
      "loop 582/1250\n",
      "loop 583/1250\n",
      "loop 584/1250\n",
      "loop 585/1250\n",
      "loop 586/1250\n",
      "loop 587/1250\n",
      "loop 588/1250\n",
      "loop 589/1250\n",
      "loop 590/1250\n",
      "loop 591/1250\n",
      "loop 592/1250\n",
      "loop 593/1250\n",
      "loop 594/1250\n",
      "loop 595/1250\n",
      "loop 596/1250\n",
      "loop 597/1250\n",
      "loop 598/1250\n",
      "loop 599/1250\n",
      "loop 600/1250\n",
      "loop 601/1250\n",
      "loop 602/1250\n",
      "loop 603/1250\n",
      "loop 604/1250\n",
      "loop 605/1250\n",
      "loop 606/1250\n",
      "loop 607/1250\n",
      "loop 608/1250\n",
      "loop 609/1250\n",
      "loop 610/1250\n",
      "loop 611/1250\n",
      "loop 612/1250\n",
      "loop 613/1250\n",
      "loop 614/1250\n",
      "loop 615/1250\n",
      "loop 616/1250\n",
      "loop 617/1250\n",
      "loop 618/1250\n",
      "loop 619/1250\n",
      "loop 620/1250\n",
      "loop 621/1250\n",
      "loop 622/1250\n",
      "loop 623/1250\n",
      "loop 624/1250\n",
      "loop 625/1250\n",
      "loop 626/1250\n",
      "loop 627/1250\n",
      "loop 628/1250\n",
      "loop 629/1250\n",
      "loop 630/1250\n",
      "loop 631/1250\n",
      "loop 632/1250\n",
      "loop 633/1250\n",
      "loop 634/1250\n",
      "loop 635/1250\n",
      "loop 636/1250\n",
      "loop 637/1250\n",
      "loop 638/1250\n",
      "loop 639/1250\n",
      "loop 640/1250\n",
      "loop 641/1250\n",
      "loop 642/1250\n",
      "loop 643/1250\n",
      "loop 644/1250\n",
      "loop 645/1250\n",
      "loop 646/1250\n",
      "loop 647/1250\n",
      "loop 648/1250\n",
      "loop 649/1250\n",
      "loop 650/1250\n",
      "loop 651/1250\n",
      "loop 652/1250\n",
      "loop 653/1250\n",
      "loop 654/1250\n",
      "loop 655/1250\n",
      "loop 656/1250\n",
      "loop 657/1250\n",
      "loop 658/1250\n",
      "loop 659/1250\n",
      "loop 660/1250\n",
      "loop 661/1250\n",
      "loop 662/1250\n",
      "loop 663/1250\n",
      "loop 664/1250\n",
      "loop 665/1250\n",
      "loop 666/1250\n",
      "loop 667/1250\n",
      "loop 668/1250\n",
      "loop 669/1250\n",
      "loop 670/1250\n",
      "loop 671/1250\n",
      "loop 672/1250\n",
      "loop 673/1250\n",
      "loop 674/1250\n",
      "loop 675/1250\n",
      "loop 676/1250\n",
      "loop 677/1250\n",
      "loop 678/1250\n",
      "loop 679/1250\n",
      "loop 680/1250\n",
      "loop 681/1250\n",
      "loop 682/1250\n",
      "loop 683/1250\n",
      "loop 684/1250\n",
      "loop 685/1250\n",
      "loop 686/1250\n",
      "loop 687/1250\n",
      "loop 688/1250\n",
      "loop 689/1250\n",
      "loop 690/1250\n",
      "loop 691/1250\n",
      "loop 692/1250\n",
      "loop 693/1250\n",
      "loop 694/1250\n",
      "loop 695/1250\n",
      "loop 696/1250\n",
      "loop 697/1250\n",
      "loop 698/1250\n",
      "loop 699/1250\n",
      "loop 700/1250\n",
      "loop 701/1250\n",
      "loop 702/1250\n",
      "loop 703/1250\n",
      "loop 704/1250\n",
      "loop 705/1250\n",
      "loop 706/1250\n",
      "loop 707/1250\n",
      "loop 708/1250\n",
      "loop 709/1250\n",
      "loop 710/1250\n",
      "loop 711/1250\n",
      "loop 712/1250\n",
      "loop 713/1250\n",
      "loop 714/1250\n",
      "loop 715/1250\n",
      "loop 716/1250\n",
      "loop 717/1250\n",
      "loop 718/1250\n",
      "loop 719/1250\n",
      "loop 720/1250\n",
      "loop 721/1250\n",
      "loop 722/1250\n",
      "loop 723/1250\n",
      "loop 724/1250\n",
      "loop 725/1250\n",
      "loop 726/1250\n",
      "loop 727/1250\n",
      "loop 728/1250\n",
      "loop 729/1250\n",
      "loop 730/1250\n",
      "loop 731/1250\n",
      "loop 732/1250\n",
      "loop 733/1250\n",
      "loop 734/1250\n",
      "loop 735/1250\n",
      "loop 736/1250\n",
      "loop 737/1250\n",
      "loop 738/1250\n",
      "loop 739/1250\n",
      "loop 740/1250\n",
      "loop 741/1250\n",
      "loop 742/1250\n",
      "loop 743/1250\n",
      "loop 744/1250\n",
      "loop 745/1250\n",
      "loop 746/1250\n",
      "loop 747/1250\n",
      "loop 748/1250\n",
      "loop 749/1250\n",
      "loop 750/1250\n",
      "loop 751/1250\n",
      "loop 752/1250\n",
      "loop 753/1250\n",
      "loop 754/1250\n",
      "loop 755/1250\n",
      "loop 756/1250\n",
      "loop 757/1250\n",
      "loop 758/1250\n",
      "loop 759/1250\n",
      "loop 760/1250\n",
      "loop 761/1250\n",
      "loop 762/1250\n",
      "loop 763/1250\n",
      "loop 764/1250\n",
      "loop 765/1250\n",
      "loop 766/1250\n",
      "loop 767/1250\n",
      "loop 768/1250\n",
      "loop 769/1250\n",
      "loop 770/1250\n",
      "loop 771/1250\n",
      "loop 772/1250\n",
      "loop 773/1250\n",
      "loop 774/1250\n",
      "loop 775/1250\n",
      "loop 776/1250\n",
      "loop 777/1250\n",
      "loop 778/1250\n",
      "loop 779/1250\n",
      "loop 780/1250\n",
      "loop 781/1250\n",
      "loop 782/1250\n",
      "loop 783/1250\n",
      "loop 784/1250\n",
      "loop 785/1250\n",
      "loop 786/1250\n",
      "loop 787/1250\n",
      "loop 788/1250\n",
      "loop 789/1250\n",
      "loop 790/1250\n",
      "loop 791/1250\n",
      "loop 792/1250\n",
      "loop 793/1250\n",
      "loop 794/1250\n",
      "loop 795/1250\n",
      "loop 796/1250\n",
      "loop 797/1250\n",
      "loop 798/1250\n",
      "loop 799/1250\n",
      "loop 800/1250\n",
      "loop 801/1250\n",
      "loop 802/1250\n",
      "loop 803/1250\n",
      "loop 804/1250\n",
      "loop 805/1250\n",
      "loop 806/1250\n",
      "loop 807/1250\n",
      "loop 808/1250\n",
      "loop 809/1250\n",
      "loop 810/1250\n",
      "loop 811/1250\n",
      "loop 812/1250\n",
      "loop 813/1250\n",
      "loop 814/1250\n",
      "loop 815/1250\n",
      "loop 816/1250\n",
      "loop 817/1250\n",
      "loop 818/1250\n",
      "loop 819/1250\n",
      "loop 820/1250\n",
      "loop 821/1250\n",
      "loop 822/1250\n",
      "loop 823/1250\n",
      "loop 824/1250\n",
      "loop 825/1250\n",
      "loop 826/1250\n",
      "loop 827/1250\n",
      "loop 828/1250\n",
      "loop 829/1250\n",
      "loop 830/1250\n",
      "loop 831/1250\n",
      "loop 832/1250\n",
      "loop 833/1250\n",
      "loop 834/1250\n",
      "loop 835/1250\n",
      "loop 836/1250\n",
      "loop 837/1250\n",
      "loop 838/1250\n",
      "loop 839/1250\n",
      "loop 840/1250\n",
      "loop 841/1250\n",
      "loop 842/1250\n",
      "loop 843/1250\n",
      "loop 844/1250\n",
      "loop 845/1250\n",
      "loop 846/1250\n",
      "loop 847/1250\n",
      "loop 848/1250\n",
      "loop 849/1250\n",
      "loop 850/1250\n",
      "loop 851/1250\n",
      "loop 852/1250\n",
      "loop 853/1250\n",
      "loop 854/1250\n",
      "loop 855/1250\n",
      "loop 856/1250\n",
      "loop 857/1250\n",
      "loop 858/1250\n",
      "loop 859/1250\n",
      "loop 860/1250\n",
      "loop 861/1250\n",
      "loop 862/1250\n",
      "loop 863/1250\n",
      "loop 864/1250\n",
      "loop 865/1250\n",
      "loop 866/1250\n",
      "loop 867/1250\n",
      "loop 868/1250\n",
      "loop 869/1250\n",
      "loop 870/1250\n",
      "loop 871/1250\n",
      "loop 872/1250\n",
      "loop 873/1250\n",
      "loop 874/1250\n",
      "loop 875/1250\n",
      "loop 876/1250\n",
      "loop 877/1250\n",
      "loop 878/1250\n",
      "loop 879/1250\n",
      "loop 880/1250\n",
      "loop 881/1250\n",
      "loop 882/1250\n",
      "loop 883/1250\n",
      "loop 884/1250\n",
      "loop 885/1250\n",
      "loop 886/1250\n",
      "loop 887/1250\n",
      "loop 888/1250\n",
      "loop 889/1250\n",
      "loop 890/1250\n",
      "loop 891/1250\n",
      "loop 892/1250\n",
      "loop 893/1250\n",
      "loop 894/1250\n",
      "loop 895/1250\n",
      "loop 896/1250\n",
      "loop 897/1250\n",
      "loop 898/1250\n",
      "loop 899/1250\n",
      "loop 900/1250\n",
      "loop 901/1250\n",
      "loop 902/1250\n",
      "loop 903/1250\n",
      "loop 904/1250\n",
      "loop 905/1250\n",
      "loop 906/1250\n",
      "loop 907/1250\n",
      "loop 908/1250\n",
      "loop 909/1250\n",
      "loop 910/1250\n",
      "loop 911/1250\n",
      "loop 912/1250\n",
      "loop 913/1250\n",
      "loop 914/1250\n",
      "loop 915/1250\n",
      "loop 916/1250\n",
      "loop 917/1250\n",
      "loop 918/1250\n",
      "loop 919/1250\n",
      "loop 920/1250\n",
      "loop 921/1250\n",
      "loop 922/1250\n",
      "loop 923/1250\n",
      "loop 924/1250\n",
      "loop 925/1250\n",
      "loop 926/1250\n",
      "loop 927/1250\n",
      "loop 928/1250\n",
      "loop 929/1250\n",
      "loop 930/1250\n",
      "loop 931/1250\n",
      "loop 932/1250\n",
      "loop 933/1250\n",
      "loop 934/1250\n",
      "loop 935/1250\n",
      "loop 936/1250\n",
      "loop 937/1250\n",
      "loop 938/1250\n",
      "loop 939/1250\n",
      "loop 940/1250\n",
      "loop 941/1250\n",
      "loop 942/1250\n",
      "loop 943/1250\n",
      "loop 944/1250\n",
      "loop 945/1250\n",
      "loop 946/1250\n",
      "loop 947/1250\n",
      "loop 948/1250\n",
      "loop 949/1250\n",
      "loop 950/1250\n",
      "loop 951/1250\n",
      "loop 952/1250\n",
      "loop 953/1250\n",
      "loop 954/1250\n",
      "loop 955/1250\n",
      "loop 956/1250\n",
      "loop 957/1250\n",
      "loop 958/1250\n",
      "loop 959/1250\n",
      "loop 960/1250\n",
      "loop 961/1250\n",
      "loop 962/1250\n",
      "loop 963/1250\n",
      "loop 964/1250\n",
      "loop 965/1250\n",
      "loop 966/1250\n",
      "loop 967/1250\n",
      "loop 968/1250\n",
      "loop 969/1250\n",
      "loop 970/1250\n",
      "loop 971/1250\n",
      "loop 972/1250\n",
      "loop 973/1250\n",
      "loop 974/1250\n",
      "loop 975/1250\n",
      "loop 976/1250\n",
      "loop 977/1250\n",
      "loop 978/1250\n",
      "loop 979/1250\n",
      "loop 980/1250\n",
      "loop 981/1250\n",
      "loop 982/1250\n",
      "loop 983/1250\n",
      "loop 984/1250\n",
      "loop 985/1250\n",
      "loop 986/1250\n",
      "loop 987/1250\n",
      "loop 988/1250\n",
      "loop 989/1250\n",
      "loop 990/1250\n",
      "loop 991/1250\n",
      "loop 992/1250\n",
      "loop 993/1250\n",
      "loop 994/1250\n",
      "loop 995/1250\n",
      "loop 996/1250\n",
      "loop 997/1250\n",
      "loop 998/1250\n",
      "loop 999/1250\n",
      "loop 1000/1250\n",
      "loop 1001/1250\n",
      "loop 1002/1250\n",
      "loop 1003/1250\n",
      "loop 1004/1250\n",
      "loop 1005/1250\n",
      "loop 1006/1250\n",
      "loop 1007/1250\n",
      "loop 1008/1250\n",
      "loop 1009/1250\n",
      "loop 1010/1250\n",
      "loop 1011/1250\n",
      "loop 1012/1250\n",
      "loop 1013/1250\n",
      "loop 1014/1250\n",
      "loop 1015/1250\n",
      "loop 1016/1250\n",
      "loop 1017/1250\n",
      "loop 1018/1250\n",
      "loop 1019/1250\n",
      "loop 1020/1250\n",
      "loop 1021/1250\n",
      "loop 1022/1250\n",
      "loop 1023/1250\n",
      "loop 1024/1250\n",
      "loop 1025/1250\n",
      "loop 1026/1250\n",
      "loop 1027/1250\n",
      "loop 1028/1250\n",
      "loop 1029/1250\n",
      "loop 1030/1250\n",
      "loop 1031/1250\n",
      "loop 1032/1250\n",
      "loop 1033/1250\n",
      "loop 1034/1250\n",
      "loop 1035/1250\n",
      "loop 1036/1250\n",
      "loop 1037/1250\n",
      "loop 1038/1250\n",
      "loop 1039/1250\n",
      "loop 1040/1250\n",
      "loop 1041/1250\n",
      "loop 1042/1250\n",
      "loop 1043/1250\n",
      "loop 1044/1250\n",
      "loop 1045/1250\n",
      "loop 1046/1250\n",
      "loop 1047/1250\n",
      "loop 1048/1250\n",
      "loop 1049/1250\n",
      "loop 1050/1250\n",
      "loop 1051/1250\n",
      "loop 1052/1250\n",
      "loop 1053/1250\n",
      "loop 1054/1250\n",
      "loop 1055/1250\n",
      "loop 1056/1250\n",
      "loop 1057/1250\n",
      "loop 1058/1250\n",
      "loop 1059/1250\n",
      "loop 1060/1250\n",
      "loop 1061/1250\n",
      "loop 1062/1250\n",
      "loop 1063/1250\n",
      "loop 1064/1250\n",
      "loop 1065/1250\n",
      "loop 1066/1250\n",
      "loop 1067/1250\n",
      "loop 1068/1250\n",
      "loop 1069/1250\n",
      "loop 1070/1250\n",
      "loop 1071/1250\n",
      "loop 1072/1250\n",
      "loop 1073/1250\n",
      "loop 1074/1250\n",
      "loop 1075/1250\n",
      "loop 1076/1250\n",
      "loop 1077/1250\n",
      "loop 1078/1250\n",
      "loop 1079/1250\n",
      "loop 1080/1250\n",
      "loop 1081/1250\n",
      "loop 1082/1250\n",
      "loop 1083/1250\n",
      "loop 1084/1250\n",
      "loop 1085/1250\n",
      "loop 1086/1250\n",
      "loop 1087/1250\n",
      "loop 1088/1250\n",
      "loop 1089/1250\n",
      "loop 1090/1250\n",
      "loop 1091/1250\n",
      "loop 1092/1250\n",
      "loop 1093/1250\n",
      "loop 1094/1250\n",
      "loop 1095/1250\n",
      "loop 1096/1250\n",
      "loop 1097/1250\n",
      "loop 1098/1250\n",
      "loop 1099/1250\n",
      "loop 1100/1250\n",
      "loop 1101/1250\n",
      "loop 1102/1250\n",
      "loop 1103/1250\n",
      "loop 1104/1250\n",
      "loop 1105/1250\n",
      "loop 1106/1250\n",
      "loop 1107/1250\n",
      "loop 1108/1250\n",
      "loop 1109/1250\n",
      "loop 1110/1250\n",
      "loop 1111/1250\n",
      "loop 1112/1250\n",
      "loop 1113/1250\n",
      "loop 1114/1250\n",
      "loop 1115/1250\n",
      "loop 1116/1250\n",
      "loop 1117/1250\n",
      "loop 1118/1250\n",
      "loop 1119/1250\n",
      "loop 1120/1250\n",
      "loop 1121/1250\n",
      "loop 1122/1250\n",
      "loop 1123/1250\n",
      "loop 1124/1250\n",
      "loop 1125/1250\n",
      "loop 1126/1250\n",
      "loop 1127/1250\n",
      "loop 1128/1250\n",
      "loop 1129/1250\n",
      "loop 1130/1250\n",
      "loop 1131/1250\n",
      "loop 1132/1250\n",
      "loop 1133/1250\n",
      "loop 1134/1250\n",
      "loop 1135/1250\n",
      "loop 1136/1250\n",
      "loop 1137/1250\n",
      "loop 1138/1250\n",
      "loop 1139/1250\n",
      "loop 1140/1250\n",
      "loop 1141/1250\n",
      "loop 1142/1250\n",
      "loop 1143/1250\n",
      "loop 1144/1250\n",
      "loop 1145/1250\n",
      "loop 1146/1250\n",
      "loop 1147/1250\n",
      "loop 1148/1250\n",
      "loop 1149/1250\n",
      "loop 1150/1250\n",
      "loop 1151/1250\n",
      "loop 1152/1250\n",
      "loop 1153/1250\n",
      "loop 1154/1250\n",
      "loop 1155/1250\n",
      "loop 1156/1250\n",
      "loop 1157/1250\n",
      "loop 1158/1250\n",
      "loop 1159/1250\n",
      "loop 1160/1250\n",
      "loop 1161/1250\n",
      "loop 1162/1250\n",
      "loop 1163/1250\n",
      "loop 1164/1250\n",
      "loop 1165/1250\n",
      "loop 1166/1250\n",
      "loop 1167/1250\n",
      "loop 1168/1250\n",
      "loop 1169/1250\n",
      "loop 1170/1250\n",
      "loop 1171/1250\n",
      "loop 1172/1250\n",
      "loop 1173/1250\n",
      "loop 1174/1250\n",
      "loop 1175/1250\n",
      "loop 1176/1250\n",
      "loop 1177/1250\n",
      "loop 1178/1250\n",
      "loop 1179/1250\n",
      "loop 1180/1250\n",
      "loop 1181/1250\n",
      "loop 1182/1250\n",
      "loop 1183/1250\n",
      "loop 1184/1250\n",
      "loop 1185/1250\n",
      "loop 1186/1250\n",
      "loop 1187/1250\n",
      "loop 1188/1250\n",
      "loop 1189/1250\n",
      "loop 1190/1250\n",
      "loop 1191/1250\n",
      "loop 1192/1250\n",
      "loop 1193/1250\n",
      "loop 1194/1250\n",
      "loop 1195/1250\n",
      "loop 1196/1250\n",
      "loop 1197/1250\n",
      "loop 1198/1250\n",
      "loop 1199/1250\n",
      "loop 1200/1250\n",
      "loop 1201/1250\n",
      "loop 1202/1250\n",
      "loop 1203/1250\n",
      "loop 1204/1250\n",
      "loop 1205/1250\n",
      "loop 1206/1250\n",
      "loop 1207/1250\n",
      "loop 1208/1250\n",
      "loop 1209/1250\n",
      "loop 1210/1250\n",
      "loop 1211/1250\n",
      "loop 1212/1250\n",
      "loop 1213/1250\n",
      "loop 1214/1250\n",
      "loop 1215/1250\n",
      "loop 1216/1250\n",
      "loop 1217/1250\n",
      "loop 1218/1250\n",
      "loop 1219/1250\n",
      "loop 1220/1250\n",
      "loop 1221/1250\n",
      "loop 1222/1250\n",
      "loop 1223/1250\n",
      "loop 1224/1250\n",
      "loop 1225/1250\n",
      "loop 1226/1250\n",
      "loop 1227/1250\n",
      "loop 1228/1250\n",
      "loop 1229/1250\n",
      "loop 1230/1250\n",
      "loop 1231/1250\n",
      "loop 1232/1250\n",
      "loop 1233/1250\n",
      "loop 1234/1250\n",
      "loop 1235/1250\n",
      "loop 1236/1250\n",
      "loop 1237/1250\n",
      "loop 1238/1250\n",
      "loop 1239/1250\n",
      "loop 1240/1250\n",
      "loop 1241/1250\n",
      "loop 1242/1250\n",
      "loop 1243/1250\n",
      "loop 1244/1250\n",
      "loop 1245/1250\n",
      "loop 1246/1250\n",
      "loop 1247/1250\n",
      "loop 1248/1250\n",
      "loop 1249/1250\n",
      "loop 1250/1250\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "log_period = 10\n",
    "num_loops = num_iterations // log_period\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = {key: jnp.array([]) for key in [\"iteration\", \"qd_score\", \"coverage\", \"max_fitness\", \"time\"]}\n",
    "\n",
    "# Set up init metrics\n",
    "init_metrics = jax.tree.map(lambda x: jnp.array([x]) if x.shape == () else x, init_metrics)\n",
    "init_metrics[\"iteration\"] = jnp.array([0], dtype=jnp.int32)\n",
    "init_metrics[\"time\"] = jnp.array([0.0])  # No time recorded for initialization\n",
    "\n",
    "# Convert init_metrics to match the metrics dictionary structure\n",
    "metrics = jax.tree.map(lambda metric, init_metric: jnp.concatenate([metric, init_metric], axis=0), metrics, init_metrics)\n",
    "\n",
    "# Initialize CSV logger\n",
    "csv_logger = CSVLogger(\n",
    "    \"PGA_ME_QMIX-logs.csv\",\n",
    "    header=list(metrics.keys())\n",
    ")\n",
    "\n",
    "# Log initial metrics\n",
    "csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "\n",
    "# Main loop\n",
    "map_elites_scan_update = map_elites.scan_update\n",
    "#print(jax.tree_util.tree_structure((repertoire, emitter_state, key)))\n",
    "print(\"Start main loop, num of loops \", num_loops)\n",
    "for i in range(num_loops):\n",
    "    start_time = time.time()\n",
    "    (\n",
    "        repertoire,\n",
    "        emitter_state,\n",
    "        key,\n",
    "    ), current_metrics = jax.lax.scan(\n",
    "        map_elites_scan_update,\n",
    "        (repertoire, emitter_state, key),\n",
    "        (),\n",
    "        length=log_period,\n",
    "    )\n",
    "    timelapse = time.time() - start_time\n",
    "    print(f\"loop {i+1}/{num_loops}\")\n",
    "\n",
    "    # Metrics\n",
    "    current_metrics[\"iteration\"] = jnp.arange(1+log_period*i, 1+log_period*(i+1), dtype=jnp.int32)\n",
    "    current_metrics[\"time\"] = jnp.repeat(timelapse, log_period)\n",
    "    metrics = jax.tree.map(lambda metric, current_metric: jnp.concatenate([metric, current_metric], axis=0), metrics, current_metrics)\n",
    "\n",
    "    # Log\n",
    "    csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "\n",
    "    '''\n",
    "    # Create a new env replacing the old wrapped env that uses an updated policy from the reportoire depending on descriptor\n",
    "    if ((i + 1) % 10 == 0) and ((i + 1) > 50):\n",
    "        \n",
    "        # Choose best policy within range of target descriptor\n",
    "        #target_descriptor = jnp.array([[0.3, 0.3]])  # example target\n",
    "        #best_params, best_fitness, best_descriptor = get_best_solution_near_descriptor(\n",
    "        #    repertoire, target_descriptor, initial_radius=0.5\n",
    "        #)\n",
    "        \n",
    "        # Choose best overall policy\n",
    "        best_idx = jnp.argmax(repertoire.fitnesses)\n",
    "        best_params = jax.tree.map(lambda x: x[best_idx], repertoire.genotypes)\n",
    "\n",
    "        env = LearnedPolicyEnemySMAX(policy = policy_network, params=best_params[\"agent\"], config=config, scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "        env = SMAXLogWrapper(env)\n",
    "        wrapped_env = CTRolloutManager(env, batch_size=config[\"NUM_ENVS\"])\n",
    "\n",
    "        reset_fn = jax.jit(wrapped_env.batch_reset)\n",
    "\n",
    "        new_scoring_fn = functools.partial(\n",
    "            scoring_function,\n",
    "            episode_length=episode_length,\n",
    "            play_reset_fn=reset_fn,\n",
    "            play_step_fn=play_step_fn,\n",
    "            descriptor_extractor=descriptor_extraction_fn,\n",
    "        )\n",
    "\n",
    "        new_pg_emitter = myPGAMEEmitter(\n",
    "            config=pga_emitter_config,\n",
    "            policy_network=policy_network,\n",
    "            env=wrapped_env,\n",
    "            variation_fn=variation_fn,\n",
    "        )\n",
    "\n",
    "        # Reinstantiate MAP-Elites\n",
    "        new_map_elites = MAPElites(\n",
    "            scoring_function=new_scoring_fn,\n",
    "            emitter=new_pg_emitter, #mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # the best performing policies\n",
    "        top_genotypes = get_top_genotypes(repertoire, batch_size)\n",
    "\n",
    "        # Debug shape\n",
    "        #jax.tree_util.tree_map(lambda x: print(\"GENOTYPE SHAPE:\", x.shape), top_genotypes)\n",
    "        #jax.tree.map(lambda x: print(\"GENOTYPE SHAPE:\", x.shape), top_genotypes)\n",
    "\n",
    "        # Manually delete old objects\n",
    "        del repertoire\n",
    "        del emitter_state\n",
    "        del map_elites_scan_update\n",
    "\n",
    "        # Trigger Python garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create new reportoire and emitter state to use\n",
    "        key, subkey = jax.random.split(key)\n",
    "        repertoire, emitter_state, _ = new_map_elites.init(top_genotypes, centroids, subkey)\n",
    "        \n",
    "\n",
    "        # Update scan function with new_map_elites\n",
    "        map_elites_scan_update = new_map_elites.scan_update\n",
    "        \n",
    "        print(f\"loop updated at end of {i+1}/{num_loops}\")\n",
    "        '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b2269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the x-axis array\n",
    "#env_steps = metrics[\"iteration\"]\n",
    "env_steps = metrics[\"iteration\"] * batch_size * episode_length * config[\"NUM_ENVS\"]\n",
    "#print(jnp.max(env_steps))\n",
    "#print(jnp.max(metrics[\"iteration\"]))\n",
    "\n",
    "%matplotlib inline\n",
    "# Create the plots and the grid\n",
    "fig, axes = plot_map_elites_results(env_steps=env_steps, metrics=metrics, repertoire=repertoire, min_descriptor=min_descriptor, max_descriptor=max_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f36477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitness in the repertoire: 2.88\n",
      " Descriptor of the best individual in the repertoire: [0.22399251 0.31921452]\n",
      " Index in the repertoire of this individual: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_idx = jnp.argmax(repertoire.fitnesses)\n",
    "best_fitness = jnp.max(repertoire.fitnesses)\n",
    "best_descriptor = repertoire.descriptors[best_idx]\n",
    "print(\n",
    "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
    "    f\"Descriptor of the best individual in the repertoire: {best_descriptor}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba84343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the parameters of the best individual\n",
    "my_params = jax.tree.map(\n",
    "    lambda x: x[best_idx],\n",
    "    repertoire.genotypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ca1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "class Visualizer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: MultiAgentEnv,\n",
    "        state_seq,\n",
    "        reward_seq=None,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.interval = 64\n",
    "\n",
    "        # Preload data to CPU to avoid GPU-to-CPU transfers during animation\n",
    "        self.state_seq = jax.device_get(state_seq)\n",
    "        self.reward_seq = jax.device_get(reward_seq) if reward_seq is not None else None\n",
    "\n",
    "        self.fig, self.ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    def animate(\n",
    "        self,\n",
    "        save_fname: Optional[str] = None,\n",
    "        view: bool = True,\n",
    "    ):\n",
    "        ani = animation.FuncAnimation(\n",
    "            self.fig,\n",
    "            self.update,\n",
    "            frames=len(self.state_seq),\n",
    "            init_func=self.init,\n",
    "            blit=True,  # Enables fast rendering\n",
    "            interval=self.interval,\n",
    "        )\n",
    "\n",
    "        if save_fname is not None:\n",
    "            ani.save(save_fname)\n",
    "\n",
    "        if view:\n",
    "            plt.show(block=True)\n",
    "\n",
    "    def init(self):\n",
    "        self.im = self.env.init_render(self.ax, self.state_seq[0])\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.im = self.env.update_render(self.im, self.state_seq[frame])\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "\n",
    "class SMAXVisualizer(Visualizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: MultiAgentEnv,\n",
    "        state_seq,\n",
    "        reward_seq=None,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.raw_state_seq = state_seq  # GPU array until expanded\n",
    "        self.reward_seq = reward_seq\n",
    "        self.interval = 64\n",
    "        self.have_expanded = False\n",
    "        self.heuristic_enemy = isinstance(env, EnemySMAX)\n",
    "        self.fig, self.ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    def expand_state_seq(self):\n",
    "        \"\"\"Expands the state sequence for higher frame resolution.\"\"\"\n",
    "        expanded = self.env.expand_state_seq(self.raw_state_seq)\n",
    "        self.state_seq = jax.device_get(expanded)  # Preload to CPU\n",
    "        self.have_expanded = True\n",
    "\n",
    "    def animate(self, save_fname: Optional[str] = None, view: bool = True):\n",
    "        if not self.have_expanded:\n",
    "            self.expand_state_seq()\n",
    "        return super().animate(save_fname, view)\n",
    "\n",
    "    def init(self):\n",
    "        self.im = self.env.init_render(self.ax, self.state_seq[0], 0, 0)\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.im = self.env.update_render(\n",
    "            self.im,\n",
    "            self.state_seq[frame],\n",
    "            frame % self.env.world_steps_per_env_step,\n",
    "            frame // self.env.world_steps_per_env_step,\n",
    "        )\n",
    "        return [self.im]  # Required for blitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "424061d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_obs_with_id(obs_dict, env):\n",
    "    \"\"\"Simulate CTRolloutManager's preprocessing by adding one-hot agent IDs.\"\"\"\n",
    "    new_obs_dict = {}\n",
    "    num_agents = len(env.agents)\n",
    "    for i, agent in enumerate(env.agents):\n",
    "        obs = obs_dict[agent].flatten()\n",
    "        one_hot = jax.nn.one_hot(i, num_classes=num_agents)\n",
    "        new_obs_dict[agent] = jnp.concatenate([obs, one_hot])\n",
    "    return new_obs_dict\n",
    "\n",
    "\n",
    "def visualize_recurrent_policy(trained_params, env, config):\n",
    "    rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "    rng, rng = jax.random.split(rng)\n",
    "    #wrapped_env = CTRolloutManager(env, batch_size=1)\n",
    "\n",
    "    # Create policy network\n",
    "    #network = RNNQNetwork(\n",
    "    #    action_dim=wrapped_env.max_action_space,\n",
    "    #    hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "    #)\n",
    "    network = RNNQNetwork(\n",
    "        action_dim=env.action_space(env.agents[0]).n,\n",
    "        hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "    )\n",
    "    \n",
    "    # Reset environment\n",
    "    #obs, env_state = wrapped_env.batch_reset(reset_rng)\n",
    "    obs, env_state = env.reset(rng)\n",
    "    #dones = {\n",
    "    #    agent: jnp.zeros((1), dtype=bool)\n",
    "    #    for agent in env.agents + [\"__all__\"]\n",
    "    #}\n",
    "    dones = {agent: jnp.array(False) for agent in env.agents}\n",
    "    hstate = ScannedRNN.initialize_carry(\n",
    "        config[\"HIDDEN_SIZE\"], len(env.agents), 1\n",
    "    )\n",
    "    \n",
    "    # Collect all environment states\n",
    "    returns = {agent: 0.0 for agent in env.agents}\n",
    "    state_seq = []\n",
    "    max_steps = config[\"NUM_STEPS\"]\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Compute Q-values\n",
    "        # Prepare inputs for network\n",
    "        obs = preprocess_obs_with_id(obs, env)\n",
    "        _obs = batchify(obs)         # (num_agents, obs_dim)\n",
    "        _obs = _obs[:, None, :]                      # (num_agents, 1, obs_dim)\n",
    "\n",
    "        #_dones = batchify(dones)    # (num_agents,)\n",
    "        #_dones = _dones[:, None]                     # (num_agents, 1)\n",
    "        _dones = jnp.stack([jnp.array([dones[agent]]) for agent in env.agents])  # shape (num_agents, 1)\n",
    "        _dones = jnp.expand_dims(_dones, axis=-1)  # from (3, 1) to (3, 1, 1)\n",
    "\n",
    "        #print(\"_obs.shape:\", _obs.shape)\n",
    "        #print(\"_dones.shape:\", _dones.shape)\n",
    "        #print(\"hstate.shape:\", hstate.shape)\n",
    "\n",
    "        def apply_fn(h, o, d):\n",
    "            return network.apply(trained_params, h, o, d)\n",
    "\n",
    "        hstate, q_vals = jax.vmap(apply_fn, in_axes=(0, 0, 0))(\n",
    "            hstate,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )\n",
    "        #print(\"hstate.shape:\", hstate.shape)\n",
    "\n",
    "        #hstate = hstate[:, None, :]  # Already in (num_agents, hidden_dim)\n",
    "        q_vals = q_vals.squeeze(axis=1)  # (num_agents, num_envs, num_actions) remove the time dim\n",
    "        #print(\"q_vals.shape\", q_vals.shape)\n",
    "        \n",
    "        actions = {}\n",
    "        #avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "        avail_actions = env.get_avail_actions(env_state.env_state)\n",
    "\n",
    "        for i, agent in enumerate(env.agents):\n",
    "            avail_agent = avail_actions[agent][None, None, :]  # shape (1, 1, n_actions)\n",
    "            #print(\"avail_agent.shape\", avail_agent.shape)\n",
    "            \n",
    "            unavail_actions = 1 - avail_agent  # shape (1, 1, n_actions)\n",
    "            \n",
    "            # Select Q-values for this agent only\n",
    "            q_agent = q_vals[i][None, None, :]  # shape (1, 1, n_actions)\n",
    "            q_masked = q_agent - (unavail_actions * 1e10)\n",
    "\n",
    "            action = jnp.argmax(q_masked, axis=-1)  # shape (1, 1)\n",
    "            action = action.squeeze()               # scalar\n",
    "            #print(\"action.shape\", action.shape)\n",
    "\n",
    "            # Wrap in array with batch dim\n",
    "            actions[agent] = int(action)    # shape (1,)\n",
    "        \n",
    "        #rng, rng_s = jax.random.split(rng)\n",
    "        state_seq.append((rng, env_state.env_state, actions))\n",
    "\n",
    "        # Step environment\n",
    "\n",
    "        # Batch the actions dict\n",
    "        # Original actions: {'ally_0': 4, 'ally_1': 4, 'ally_2': 4}\n",
    "        #actions = {k: jnp.array([v]) for k, v in actions.items()}\n",
    "\n",
    "        #obs, env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        #    rng_s, env_state, actions\n",
    "        #)\n",
    "        obs, env_state, rewards, dones, infos = env.step(rng, env_state, actions)\n",
    "        returns = {a: returns[a] + rewards[a] for a in env.agents}\n",
    "        \n",
    "        if dones[\"__all__\"]:\n",
    "            break\n",
    "\n",
    "    # Visualization\n",
    "    print(\"Returns:\", returns)\n",
    "\n",
    "    viz = SMAXVisualizer(env, state_seq)\n",
    "    viz.animate(view=False, save_fname=\"trained_qmix_rnn.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed47f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns: {'ally_0': Array(2., dtype=float32), 'ally_1': Array(2., dtype=float32), 'ally_2': Array(2., dtype=float32), 'ally_3': Array(2., dtype=float32), 'ally_4': Array(2., dtype=float32)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = map_name_to_scenario(config[\"MAP_NAME\"])\n",
    "#env = HeuristicEnemySMAX(scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "#env = SMAXLogWrapper(env)\n",
    "env = wrapped_env\n",
    "\n",
    "visualize_recurrent_policy(my_params['agent'], env, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4a09329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from flax.serialization import to_state_dict\n",
    "from flax.serialization import from_state_dict\n",
    "\n",
    "\n",
    "def save_repertoire(repertoire: MapElitesRepertoire, filepath: str):\n",
    "    # Convert the object to a savable dictionary\n",
    "    state_dict = {\n",
    "        \"genotypes\": to_state_dict(repertoire.genotypes),\n",
    "        \"fitnesses\": repertoire.fitnesses,\n",
    "        \"descriptors\": repertoire.descriptors,\n",
    "        \"centroids\": repertoire.centroids,\n",
    "        \"extra_scores\": to_state_dict(repertoire.extra_scores),\n",
    "        \"keys_extra_scores\": repertoire.keys_extra_scores,\n",
    "    }\n",
    "    \n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(state_dict, f)\n",
    "\n",
    "def load_repertoire(filepath: str) -> MapElitesRepertoire:\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        state_dict = pickle.load(f)\n",
    "\n",
    "    # Rebuild the object using the saved state\n",
    "    genotypes = from_state_dict(state_dict[\"genotypes\"], state_dict[\"genotypes\"])\n",
    "    extra_scores = from_state_dict(state_dict[\"extra_scores\"], state_dict[\"extra_scores\"])\n",
    "\n",
    "    return MapElitesRepertoire(\n",
    "        genotypes=genotypes,\n",
    "        fitnesses=state_dict[\"fitnesses\"],\n",
    "        descriptors=state_dict[\"descriptors\"],\n",
    "        centroids=state_dict[\"centroids\"],\n",
    "        extra_scores=extra_scores,\n",
    "        keys_extra_scores=state_dict[\"keys_extra_scores\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb2c9771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved reportoire\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "\n",
    "#os.makedirs(\"/vol/bitbucket/eww24/Masters_project/repertoire\", exist_ok=True)\n",
    "\n",
    "filepath = \"/vol/bitbucket/eww24/Masters_project/repertoire/qmix_transfer_repertoire_2s3z_v2.pkl\"\n",
    "save_repertoire(repertoire, filepath)\n",
    "print(\"saved reportoire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "895bf9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repertoire loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "loaded_repertoire = load_repertoire(filepath)\n",
    "print(\"Repertoire loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2adae51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitness in the repertoire: 2.88\n",
      " Descriptor of the best individual in the repertoire: [0.22399251 0.31921452]\n",
      " Index in the repertoire of this individual: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_idx = jnp.argmax(loaded_repertoire.fitnesses)\n",
    "best_fitness = jnp.max(loaded_repertoire.fitnesses)\n",
    "best_descriptor = loaded_repertoire.descriptors[best_idx]\n",
    "print(\n",
    "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
    "    f\"Descriptor of the best individual in the repertoire: {best_descriptor}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
