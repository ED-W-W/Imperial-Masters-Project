{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5945f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import numpy as np\n",
    "import chex\n",
    "import optax\n",
    "from flax.linen.initializers import constant, orthogonal\n",
    "from typing import Sequence, NamedTuple, Any, Dict\n",
    "from flax.training.train_state import TrainState\n",
    "import distrax\n",
    "\n",
    "from jaxmarl import make\n",
    "from jaxmarl.wrappers.baselines import (\n",
    "    SMAXLogWrapper,\n",
    "    MPELogWrapper,\n",
    "    LogWrapper,\n",
    "    CTRolloutManager,\n",
    ")\n",
    "from jaxmarl.environments.smax import map_name_to_scenario, HeuristicEnemySMAX, LearnedPolicyEnemySMAX\n",
    "from jaxmarl.environments.smax.heuristic_enemy_smax_env import EnemySMAX\n",
    "from jaxmarl.viz.visualizer import Visualizer, SMAXVisualizer\n",
    "\n",
    "import functools\n",
    "from functools import partial\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from qdax.core.map_elites import MAPElites\n",
    "from qdax.core.containers.mapelites_repertoire import compute_cvt_centroids, compute_euclidean_centroids, MapElitesRepertoire\n",
    "#import qdax.tasks.brax.v1 as environments\n",
    "#from qdax.tasks.brax.v1.env_creators import scoring_function_brax_envs as scoring_function\n",
    "from qdax.core.neuroevolution.buffers.buffer import QDTransition\n",
    "from qdax.core.neuroevolution.networks.networks import MLP\n",
    "from qdax.core.emitters.mutation_operators import isoline_variation\n",
    "from qdax.core.emitters.standard_emitters import MixingEmitter\n",
    "from qdax.utils.plotting import plot_map_elites_results\n",
    "from qdax.utils.metrics import CSVLogger, default_qd_metrics\n",
    "\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from qdax.core.emitters.repertoire_selectors.selector import Selector\n",
    "from qdax.core.emitters.qpg_emitter import QualityPGConfig, QualityPGEmitterState\n",
    "from qdax.tasks.brax.v1.envs.base_env import QDEnv\n",
    "\n",
    "from qdax.core.emitters.multi_emitter import MultiEmitter\n",
    "from qdax.core.containers.ga_repertoire import GARepertoire\n",
    "from qdax.core.containers.repertoire import Repertoire\n",
    "#from qdax.core.neuroevolution.losses.td3_loss import make_td3_loss_fn\n",
    "from qdax.core.emitters.emitter import Emitter\n",
    "#from qdax.core.neuroevolution.networks.networks import QModule\n",
    "#from qdax.core.neuroevolution.buffers.buffer import ReplayBuffer\n",
    "\n",
    "from qdax.core.emitters.pga_me_emitter import PGAMEConfig, PGAMEEmitter\n",
    "\n",
    "import flashbax as fbx\n",
    "## Brax version conflict with JaxMARL(0.10.3) and QDax(0.10.4 / 0.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ff85aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Optional, Tuple\n",
    "from qdax.custom_types import (\n",
    "    Descriptor,\n",
    "    EnvState,\n",
    "    ExtraScores,\n",
    "    Fitness,\n",
    "    Genotype,\n",
    "    Observation,\n",
    "    Params,\n",
    "    RNGKey,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac7fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # valid for iql, vdn, qmix\n",
    "    \"TOTAL_TIMESTEPS\": 10e7, #1e7,\n",
    "    \"NUM_ENVS\": 16, #16,\n",
    "    \"NUM_STEPS\": 128,\n",
    "    \"BUFFER_SIZE\": 12000, #5000,\n",
    "    \"BUFFER_BATCH_SIZE\": 32,\n",
    "    \"HIDDEN_SIZE\": 256, #64, #512,\n",
    "    \"MIXER_EMBEDDING_DIM\": 16, #64,\n",
    "    \"MIXER_HYPERNET_HIDDEN_DIM\": 64, #256,\n",
    "    \"MIXER_INIT_SCALE\": 0.001,\n",
    "    \"EPS_START\": 1.0,\n",
    "    \"EPS_FINISH\": 0.05,\n",
    "    \"EPS_DECAY\": 0.1, # percentage of updates\n",
    "    \"MAX_GRAD_NORM\": 10,\n",
    "    \"TARGET_UPDATE_INTERVAL\": 1, #10,\n",
    "    \"TAU\": 0.1, #1.,\n",
    "    \"NUM_EPOCHS\": 8,\n",
    "    \"LR\": 0.00005,\n",
    "    \"LEARNING_STARTS\": 10000, # timesteps\n",
    "    \"LR_LINEAR_DECAY\": False,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"REW_SCALE\": 10., # scale the reward to the original scale of SMAC\n",
    "\n",
    "    # ENV\n",
    "    \"ENV_NAME\": \"HeuristicEnemySMAX\",\n",
    "    #\"MAP_NAME\": \"3s_vs_5z\",\n",
    "    #\"MAP_NAME\":\"smacv2_5_units\", # 5 random units for each size\n",
    "    \"MAP_NAME\": \"2s3z\",\n",
    "    #\"MAP_NAME\": \"5m_vs_6m\",\n",
    "    \"ENV_KWARGS\": {\n",
    "        \"see_enemy_actions\": True,\n",
    "        \"walls_cause_death\": True,\n",
    "        \"attack_mode\": \"closest\", # uncomment when using heuristic policy\n",
    "        #\"won_battle_bonus\": 10.0, # To test if increasing winning reward gets solution to beat enemy\n",
    "    },\n",
    "\n",
    "    \"NUM_SEEDS\": 1, # number of vmapped seeds (not used)\n",
    "    \"SEED\": 88,\n",
    "\n",
    "    \"HYP_TUNE\": False, # perform hyp tune\n",
    "\n",
    "    # evaluate\n",
    "    \"TEST_DURING_TRAINING\": False, #True,\n",
    "    \"TEST_INTERVAL\": 0.05, # as a fraction of updates, i.e. log every 5% of training process\n",
    "    \"TEST_NUM_STEPS\": 128,\n",
    "    \"TEST_NUM_ENVS\": 512, # number of episodes to average over, can affect performance\n",
    "}\n",
    "batch_size = 5# 128 # Num of offsprings \n",
    "#env_name = 'walker2d_uni'\n",
    "episode_length = config[\"NUM_STEPS\"] #128  # NUM_STEPS\n",
    "num_iterations = int(config[\"TOTAL_TIMESTEPS\"] / (batch_size * config[\"NUM_ENVS\"] * config[\"NUM_STEPS\"]))\n",
    "seed = 88 \n",
    "policy_hidden_layer_sizes = (128, 128, 128) #(64, 64)\n",
    "iso_sigma = 0.005 #0.005 \n",
    "line_sigma = 0.05 #0.05 \n",
    "num_init_cvt_samples = 20000 #50000 \n",
    "num_centroids = 1024 #1024 \n",
    "min_descriptor = 0. \n",
    "max_descriptor = 1.0 \n",
    "number_of_descriptors=2\n",
    "\n",
    "\n",
    "proportion_mutation_ga = 0.5 \n",
    "\n",
    "# IQL params\n",
    "env_batch_size = batch_size #100 \n",
    "replay_buffer_size = config[\"BUFFER_SIZE\"] #1000000 \n",
    "critic_hidden_layer_size = (256, 256) \n",
    "critic_learning_rate = 3e-4 \n",
    "greedy_learning_rate = 3e-4 \n",
    "policy_learning_rate = 0.00005 #1e-3 \n",
    "noise_clip = 0.5\n",
    "policy_noise = 0.2 \n",
    "discount = config[\"GAMMA\"] #0.99 \n",
    "reward_scaling = 1.0 \n",
    "transitions_batch_size = config[\"BUFFER_BATCH_SIZE\"] #256 \n",
    "soft_tau_update = 0.005\n",
    "num_critic_training_steps = 300 \n",
    "num_pg_training_steps = 10 #100 \n",
    "policy_delay = 2\n",
    "\n",
    "# Define the PG-emitter config\n",
    "@dataclass\n",
    "class CustomPGAMEConfig(PGAMEConfig):\n",
    "    num_envs: Any = None\n",
    "    num_steps: Any = None\n",
    "    target_update_interval: Any = None\n",
    "    tau: Any = None\n",
    "\n",
    "pga_emitter_config = CustomPGAMEConfig(\n",
    "    env_batch_size=env_batch_size,\n",
    "    batch_size=transitions_batch_size,\n",
    "    proportion_mutation_ga=proportion_mutation_ga,\n",
    "    critic_hidden_layer_size=critic_hidden_layer_size,\n",
    "    critic_learning_rate=critic_learning_rate,\n",
    "    greedy_learning_rate=greedy_learning_rate,\n",
    "    policy_learning_rate=policy_learning_rate,\n",
    "    noise_clip=noise_clip,\n",
    "    policy_noise=policy_noise,\n",
    "    discount=discount,\n",
    "    reward_scaling=reward_scaling,\n",
    "    replay_buffer_size=replay_buffer_size,\n",
    "    soft_tau_update=soft_tau_update,\n",
    "    num_critic_training_steps=num_critic_training_steps,\n",
    "    num_pg_training_steps=num_pg_training_steps,\n",
    "    policy_delay=policy_delay,\n",
    "\n",
    "    num_envs = config[\"NUM_ENVS\"],\n",
    "    num_steps = config[\"NUM_STEPS\"],\n",
    "    target_update_interval = config[\"TARGET_UPDATE_INTERVAL\"],\n",
    "    tau = config[\"TAU\"],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07479b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScannedRNN(nn.Module):\n",
    "\n",
    "    @partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"params\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"Applies the module.\"\"\"\n",
    "        rnn_state = carry\n",
    "        ins, resets = x\n",
    "        hidden_size = ins.shape[-1]\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, np.newaxis],\n",
    "            self.initialize_carry(hidden_size, *ins.shape[:-1]),\n",
    "            rnn_state,\n",
    "        )\n",
    "        new_rnn_state, y = nn.GRUCell(hidden_size)(rnn_state, ins)\n",
    "        return new_rnn_state, y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(hidden_size, *batch_size):\n",
    "        # Use a dummy key since the default state init fn is just zeros.\n",
    "        return nn.GRUCell(hidden_size, parent=None).initialize_carry(\n",
    "            jax.random.PRNGKey(0), (*batch_size, hidden_size)\n",
    "        )\n",
    "\n",
    "\n",
    "class RNNQNetwork(nn.Module):\n",
    "    # homogenous agent for parameters sharing, assumes all agents have same obs and action dim\n",
    "    action_dim: int\n",
    "    hidden_dim: int\n",
    "    init_scale: float = 1.0\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden, obs, dones):\n",
    "        embedding = nn.Dense(\n",
    "            self.hidden_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(obs)\n",
    "        embedding = nn.relu(embedding)\n",
    "\n",
    "        rnn_in = (embedding, dones)\n",
    "        hidden, embedding = ScannedRNN()(hidden, rnn_in)\n",
    "\n",
    "        q_vals = nn.Dense(\n",
    "            self.action_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(embedding)\n",
    "\n",
    "        return hidden, q_vals\n",
    "    \n",
    "\n",
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"HyperNetwork for generating weights of QMix' mixing network.\"\"\"\n",
    "\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(\n",
    "            self.hidden_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(\n",
    "            self.output_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        return x\n",
    "'''   \n",
    "# 1 layer hypernetwork\n",
    "class HyperNetwork(nn.Module):\n",
    "    \"\"\"HyperNetwork for generating weights of QMix' mixing network.\"\"\"\n",
    "\n",
    "    hidden_dim: int\n",
    "    output_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(\n",
    "            self.output_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(x)\n",
    "        return x\n",
    "'''\n",
    "\n",
    "class MixingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixing network for projecting individual agent Q-values into Q_tot. Follows the original QMix implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    embedding_dim: int\n",
    "    hypernet_hidden_dim: int\n",
    "    init_scale: float\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, q_vals, states):\n",
    "\n",
    "        n_agents, time_steps, batch_size = q_vals.shape\n",
    "        q_vals = jnp.transpose(q_vals, (1, 2, 0))  # (time_steps, batch_size, n_agents)\n",
    "\n",
    "        # hypernetwork\n",
    "        w_1 = HyperNetwork(\n",
    "            hidden_dim=self.hypernet_hidden_dim,\n",
    "            output_dim=self.embedding_dim * n_agents,\n",
    "            init_scale=self.init_scale,\n",
    "        )(states)\n",
    "        b_1 = nn.Dense(\n",
    "            self.embedding_dim,\n",
    "            kernel_init=orthogonal(self.init_scale),\n",
    "            bias_init=constant(0.0),\n",
    "        )(states)\n",
    "        w_2 = HyperNetwork(\n",
    "            hidden_dim=self.hypernet_hidden_dim,\n",
    "            output_dim=self.embedding_dim,\n",
    "            init_scale=self.init_scale,\n",
    "        )(states)\n",
    "        b_2 = HyperNetwork(\n",
    "            hidden_dim=self.embedding_dim, output_dim=1, init_scale=self.init_scale\n",
    "        )(states)\n",
    "\n",
    "        # monotonicity and reshaping\n",
    "        w_1 = jnp.abs(w_1.reshape(time_steps, batch_size, n_agents, self.embedding_dim))\n",
    "        b_1 = b_1.reshape(time_steps, batch_size, 1, self.embedding_dim)\n",
    "        w_2 = jnp.abs(w_2.reshape(time_steps, batch_size, self.embedding_dim, 1))\n",
    "        b_2 = b_2.reshape(time_steps, batch_size, 1, 1)\n",
    "\n",
    "        # mix\n",
    "        hidden = nn.elu(jnp.matmul(q_vals[:, :, None, :], w_1) + b_1)\n",
    "        q_tot = jnp.matmul(hidden, w_2) + b_2\n",
    "\n",
    "        return q_tot.squeeze()  # (time_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec87de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Transition(NamedTuple):\n",
    "#    global_done: jnp.ndarray\n",
    "#    done: jnp.ndarray\n",
    "#    action: jnp.ndarray\n",
    "#    reward: jnp.ndarray\n",
    "#    obs: jnp.ndarray\n",
    "#    env_state: jnp.ndarray\n",
    "#    info: jnp.ndarray\n",
    "#    avail_actions: jnp.ndarray\n",
    "\n",
    "class Transition(NamedTuple):\n",
    "    #global_done: jnp.ndarray\n",
    "    #reward: jnp.ndarray\n",
    "    env_state: jnp.ndarray\n",
    "    infos: jnp.ndarray\n",
    "\n",
    "@chex.dataclass(frozen=True)\n",
    "class Timestep:\n",
    "    obs: dict\n",
    "    actions: dict\n",
    "    rewards: dict\n",
    "    dones: dict\n",
    "    avail_actions: dict\n",
    "\n",
    "\n",
    "class CustomTrainState(TrainState):\n",
    "    target_network_params: Any\n",
    "    timesteps: int = 0\n",
    "    n_updates: int = 0\n",
    "    grad_steps: int = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "051ce603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom flax.serialization import from_bytes\\n\\nclass ScannedRNNIPPO(nn.Module):\\n    @functools.partial(\\n        nn.scan,\\n        variable_broadcast=\"params\",\\n        in_axes=0,\\n        out_axes=0,\\n        split_rngs={\"params\": False},\\n    )\\n    @nn.compact\\n    def __call__(self, carry, x):\\n        \"\"\"Applies the module.\"\"\"\\n        rnn_state = carry\\n        ins, resets = x\\n        resets = jnp.atleast_1d(resets)\\n        rnn_state = jnp.where(\\n            resets[:, np.newaxis],\\n            self.initialize_carry(*rnn_state.shape),\\n            rnn_state,\\n        )\\n        new_rnn_state, y = nn.GRUCell(features=ins.shape[1])(rnn_state, ins)\\n        return new_rnn_state, y\\n\\n    @staticmethod\\n    def initialize_carry(batch_size, hidden_size):\\n        # Use a dummy key since the default state init fn is just zeros.\\n        cell = nn.GRUCell(features=hidden_size)\\n        return cell.initialize_carry(jax.random.PRNGKey(0), (batch_size, hidden_size))\\n\\n\\nclass ActorCriticRNN(nn.Module):\\n    action_dim: Sequence[int]\\n    config: Dict\\n\\n    @nn.compact\\n    def __call__(self, hidden, x):\\n        obs, dones, avail_actions = x\\n        embedding = nn.Dense(\\n            self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\\n        )(obs)\\n        embedding = nn.relu(embedding)\\n\\n        rnn_in = (embedding, dones)\\n        hidden, embedding = ScannedRNNIPPO(name=\"ScannedRNN_0\")(hidden, rnn_in)\\n\\n        actor_mean = nn.Dense(self.config[\"GRU_HIDDEN_DIM\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\\n            embedding\\n        )\\n        actor_mean = nn.relu(actor_mean)\\n        actor_mean = nn.Dense(\\n            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\\n        )(actor_mean)\\n        unavail_actions = 1 - avail_actions\\n        action_logits = actor_mean - (unavail_actions * 1e10)\\n\\n        pi = distrax.Categorical(logits=action_logits)\\n\\n        critic = nn.Dense(self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\\n            embedding\\n        )\\n        critic = nn.relu(critic)\\n        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\\n            critic\\n        )\\n\\n        return hidden, pi, jnp.squeeze(critic, axis=-1)\\n\\nippo_config = {\\n    \"LR\": 0.004,\\n    \"NUM_ENVS\": 128,\\n    \"NUM_STEPS\": 128,\\n    \"GRU_HIDDEN_DIM\": 128,\\n    \"FC_DIM_SIZE\": 128,\\n    \"TOTAL_TIMESTEPS\": 1e7,\\n    \"UPDATE_EPOCHS\": 4,\\n    \"NUM_MINIBATCHES\": 4,\\n    \"GAMMA\": 0.99,\\n    \"GAE_LAMBDA\": 0.95,\\n    \"CLIP_EPS\": 0.05,\\n    \"SCALE_CLIP_EPS\": False,\\n    \"ENT_COEF\": 0.01,\\n    \"VF_COEF\": 0.5,\\n    \"MAX_GRAD_NORM\": 0.25,\\n    \"ACTIVATION\": \"relu\",\\n    \"ENV_NAME\": \"HeuristicEnemySMAX\",\\n    \"MAP_NAME\": \"2s3z\",\\n    \"SEED\": 88,\\n    \"ENV_KWARGS\": {\\n        \"see_enemy_actions\": True,\\n        \"walls_cause_death\": True,\\n        \"attack_mode\": \"closest\"\\n    },\\n    \"ANNEAL_LR\": True,\\n}\\n\\n# Create dummy env\\nscenario = map_name_to_scenario(ippo_config[\"MAP_NAME\"])\\ndummy_env = HeuristicEnemySMAX(scenario=scenario, **ippo_config[\"ENV_KWARGS\"])\\ndummy_env = SMAXLogWrapper(dummy_env)\\n\\n# Create dummy model instance\\ndummy_network = ActorCriticRNN(dummy_env.action_space(dummy_env.agents[0]).n, config=ippo_config)\\n\\n# Prepare dummy input for param loading\\ndummy_hstate = ScannedRNNIPPO.initialize_carry(ippo_config[\"NUM_ENVS\"], ippo_config[\"GRU_HIDDEN_DIM\"])\\ndummy_obs = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.observation_space(dummy_env.agents[0]).shape[0]))\\ndummy_dones = jnp.zeros((1, ippo_config[\"NUM_ENVS\"]))\\ndummy_avail = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.action_space(dummy_env.agents[0]).n))\\ndummy_input = (dummy_obs, dummy_dones, dummy_avail)\\n\\n# Create dummy params to use as template\\nrng = jax.random.PRNGKey(0)\\ndummy_params = dummy_network.init(rng, dummy_hstate, dummy_input)\\n#trained_ippo_params = dummy_params\\n\\n# Load trained parameters\\nwith open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_ippo_params.msgpack\", \"rb\") as f:\\n    trained_ippo_params = from_bytes(dummy_params, f.read())\\nprint(\"Params loaded\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load trained IPPO policy\n",
    "'''\n",
    "from flax.serialization import from_bytes\n",
    "\n",
    "class ScannedRNNIPPO(nn.Module):\n",
    "    @functools.partial(\n",
    "        nn.scan,\n",
    "        variable_broadcast=\"params\",\n",
    "        in_axes=0,\n",
    "        out_axes=0,\n",
    "        split_rngs={\"params\": False},\n",
    "    )\n",
    "    @nn.compact\n",
    "    def __call__(self, carry, x):\n",
    "        \"\"\"Applies the module.\"\"\"\n",
    "        rnn_state = carry\n",
    "        ins, resets = x\n",
    "        resets = jnp.atleast_1d(resets)\n",
    "        rnn_state = jnp.where(\n",
    "            resets[:, np.newaxis],\n",
    "            self.initialize_carry(*rnn_state.shape),\n",
    "            rnn_state,\n",
    "        )\n",
    "        new_rnn_state, y = nn.GRUCell(features=ins.shape[1])(rnn_state, ins)\n",
    "        return new_rnn_state, y\n",
    "\n",
    "    @staticmethod\n",
    "    def initialize_carry(batch_size, hidden_size):\n",
    "        # Use a dummy key since the default state init fn is just zeros.\n",
    "        cell = nn.GRUCell(features=hidden_size)\n",
    "        return cell.initialize_carry(jax.random.PRNGKey(0), (batch_size, hidden_size))\n",
    "\n",
    "\n",
    "class ActorCriticRNN(nn.Module):\n",
    "    action_dim: Sequence[int]\n",
    "    config: Dict\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, hidden, x):\n",
    "        obs, dones, avail_actions = x\n",
    "        embedding = nn.Dense(\n",
    "            self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(np.sqrt(2)), bias_init=constant(0.0)\n",
    "        )(obs)\n",
    "        embedding = nn.relu(embedding)\n",
    "\n",
    "        rnn_in = (embedding, dones)\n",
    "        hidden, embedding = ScannedRNNIPPO(name=\"ScannedRNN_0\")(hidden, rnn_in)\n",
    "\n",
    "        actor_mean = nn.Dense(self.config[\"GRU_HIDDEN_DIM\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\n",
    "            embedding\n",
    "        )\n",
    "        actor_mean = nn.relu(actor_mean)\n",
    "        actor_mean = nn.Dense(\n",
    "            self.action_dim, kernel_init=orthogonal(0.01), bias_init=constant(0.0)\n",
    "        )(actor_mean)\n",
    "        unavail_actions = 1 - avail_actions\n",
    "        action_logits = actor_mean - (unavail_actions * 1e10)\n",
    "\n",
    "        pi = distrax.Categorical(logits=action_logits)\n",
    "\n",
    "        critic = nn.Dense(self.config[\"FC_DIM_SIZE\"], kernel_init=orthogonal(2), bias_init=constant(0.0))(\n",
    "            embedding\n",
    "        )\n",
    "        critic = nn.relu(critic)\n",
    "        critic = nn.Dense(1, kernel_init=orthogonal(1.0), bias_init=constant(0.0))(\n",
    "            critic\n",
    "        )\n",
    "\n",
    "        return hidden, pi, jnp.squeeze(critic, axis=-1)\n",
    "    \n",
    "ippo_config = {\n",
    "    \"LR\": 0.004,\n",
    "    \"NUM_ENVS\": 128,\n",
    "    \"NUM_STEPS\": 128,\n",
    "    \"GRU_HIDDEN_DIM\": 128,\n",
    "    \"FC_DIM_SIZE\": 128,\n",
    "    \"TOTAL_TIMESTEPS\": 1e7,\n",
    "    \"UPDATE_EPOCHS\": 4,\n",
    "    \"NUM_MINIBATCHES\": 4,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"GAE_LAMBDA\": 0.95,\n",
    "    \"CLIP_EPS\": 0.05,\n",
    "    \"SCALE_CLIP_EPS\": False,\n",
    "    \"ENT_COEF\": 0.01,\n",
    "    \"VF_COEF\": 0.5,\n",
    "    \"MAX_GRAD_NORM\": 0.25,\n",
    "    \"ACTIVATION\": \"relu\",\n",
    "    \"ENV_NAME\": \"HeuristicEnemySMAX\",\n",
    "    \"MAP_NAME\": \"2s3z\",\n",
    "    \"SEED\": 88,\n",
    "    \"ENV_KWARGS\": {\n",
    "        \"see_enemy_actions\": True,\n",
    "        \"walls_cause_death\": True,\n",
    "        \"attack_mode\": \"closest\"\n",
    "    },\n",
    "    \"ANNEAL_LR\": True,\n",
    "}\n",
    "\n",
    "# Create dummy env\n",
    "scenario = map_name_to_scenario(ippo_config[\"MAP_NAME\"])\n",
    "dummy_env = HeuristicEnemySMAX(scenario=scenario, **ippo_config[\"ENV_KWARGS\"])\n",
    "dummy_env = SMAXLogWrapper(dummy_env)\n",
    "\n",
    "# Create dummy model instance\n",
    "dummy_network = ActorCriticRNN(dummy_env.action_space(dummy_env.agents[0]).n, config=ippo_config)\n",
    "\n",
    "# Prepare dummy input for param loading\n",
    "dummy_hstate = ScannedRNNIPPO.initialize_carry(ippo_config[\"NUM_ENVS\"], ippo_config[\"GRU_HIDDEN_DIM\"])\n",
    "dummy_obs = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.observation_space(dummy_env.agents[0]).shape[0]))\n",
    "dummy_dones = jnp.zeros((1, ippo_config[\"NUM_ENVS\"]))\n",
    "dummy_avail = jnp.zeros((1, ippo_config[\"NUM_ENVS\"], dummy_env.action_space(dummy_env.agents[0]).n))\n",
    "dummy_input = (dummy_obs, dummy_dones, dummy_avail)\n",
    "\n",
    "# Create dummy params to use as template\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dummy_params = dummy_network.init(rng, dummy_hstate, dummy_input)\n",
    "#trained_ippo_params = dummy_params\n",
    "\n",
    "# Load trained parameters\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_ippo_params.msgpack\", \"rb\") as f:\n",
    "    trained_ippo_params = from_bytes(dummy_params, f.read())\n",
    "print(\"Params loaded\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853d4116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dataclasses\\nfrom jaxmarl.environments.smax.smax_env import SMAX\\nfrom jaxmarl.environments.smax.smax_env import State as SMAXState\\nfrom jaxmarl.environments.multi_agent_env import MultiAgentEnv\\n\\nfrom flax import struct\\n\\n@struct.dataclass\\nclass State:\\n    # underlying jaxmarl env state\\n    state: ...\\n    # the enemy policy state. Needed for recurrent policies or\\n    # remembering details about previous observations for heuristics.\\n    enemy_policy_state: ...\\n\\nclass EnemySMAX(MultiAgentEnv):\\n    \"\"\"Class that presents the SMAX environment as a single-player\\n    (but still multi-agent) environment. Functions like a wrapper, but\\n    not linked with any of the wrapper code because that is used differently.\"\"\"\\n\\n\\n\\n    def __init__(self, **env_kwargs):\\n        self._env = SMAX(**env_kwargs)\\n        # only one team\\n        self.num_agents = self._env.num_allies\\n        self.num_enemies = self._env.num_enemies\\n        # want to provide a consistent API between this and SMAX\\n        self.num_allies = self._env.num_allies\\n        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\\n        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\\n        self.all_agents = self.agents + self.enemy_agents\\n        self.observation_spaces = {\\n            i: self._env.observation_spaces[i] for i in self.agents\\n        }\\n        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\\n\\n    def __getattr__(self, name: str):\\n        return getattr(self._env, name)\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\\n        key, reset_key = jax.random.split(key)\\n        obs, state = self._env.reset(reset_key)\\n        enemy_policy_state = self.get_enemy_policy_initial_state(key)\\n        new_obs = {agent: obs[agent] for agent in self.agents}\\n        new_obs[\"world_state\"] = obs[\"world_state\"]\\n        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\\n\\n    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\\n        raise NotImplementedError\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        raise NotImplementedError\\n\\n    @partial(jax.jit, static_argnums=(0, 4))\\n    def step_env(\\n        self,\\n        key: chex.PRNGKey,\\n        state: State,\\n        actions: Dict[str, chex.Array],\\n        get_state_sequence=False,\\n    ):\\n        jaxmarl_state = state.state\\n        obs = self._env.get_obs(jaxmarl_state)\\n        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\\n        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\\n\\n        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\\n        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\\n\\n        enemy_dones = {\\n            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\\n        }\\n        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\\n\\n        #enemy_x = (    \\n        #    enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\\n        #    enemy_dones[jnp.newaxis, :],    # [1, num_agents]\\n        #    enemy_avail_actions              # [1, num_agents, num_actions]\\n        #)\\n\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        key, action_key = jax.random.split(key)\\n        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n        #    action_key, state.enemy_policy_state, enemy_obs\\n        #)\\n        enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n            action_key, state.enemy_policy_state, enemy_obs, enemy_dones, enemy_avail_actions #enemy_x\\n        )\\n\\n        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \\n        actions = jnp.array([actions[i] for i in self.agents])\\n        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        #print(\"enemy_actions:\", enemy_actions)\\n        #print(\"actions shape:\", actions.shape)\\n        enemy_movement_actions, enemy_attack_actions = (\\n            self._env._decode_discrete_actions(enemy_actions)\\n        )\\n        if self._env.action_type == \"continuous\":\\n            cont_actions = jnp.zeros((len(self.all_agents), 4))\\n            cont_actions = cont_actions.at[: self.num_allies].set(actions)\\n            key, action_key = jax.random.split(key)\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_continuous_actions(\\n                    action_key, jaxmarl_state, cont_actions\\n                )\\n            )\\n            ally_movement_actions = ally_movement_actions[: self.num_allies]\\n            ally_attack_actions = ally_attack_actions[: self.num_allies]\\n        else:\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_discrete_actions(actions)\\n            )\\n\\n        movement_actions = jnp.concatenate(\\n            [ally_movement_actions, enemy_movement_actions], axis=0\\n        )\\n        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\\n\\n        if not get_state_sequence:\\n            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            new_obs = {agent: obs[agent] for agent in self.agents}\\n            new_obs[\"world_state\"] = obs[\"world_state\"]\\n            rewards = {agent: rewards[agent] for agent in self.agents}\\n            all_done = dones[\"__all__\"]\\n            dones = {agent: dones[agent] for agent in self.agents}\\n            dones[\"__all__\"] = all_done\\n\\n            state = state.replace(\\n                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\\n            )\\n            return new_obs, state, rewards, dones, infos\\n        else:\\n            states = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            return states\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def get_avail_actions(self, state: State):\\n        avail_actions = self._env.get_avail_actions(state.state)\\n        return {agent: avail_actions[agent] for agent in self.agents}\\n\\n    def get_all_unit_obs(self, state: State):\\n        return self._env.get_obs(state.state)\\n\\n    def get_obs(self, state: State) -> Dict[str, chex.Array]:\\n        obs = self.get_all_unit_obs(state)\\n        return {agent: obs[agent] for agent in self.agents}\\n\\n    def get_world_state(self, state: State):\\n        return self._env.get_world_state(state.state)\\n\\n    def is_terminal(self, state: State):\\n        return self._env.is_terminal(state.state)\\n\\n    def expand_state_seq(self, state_seq):\\n        # TODO jit/scan this\\n        expanded_state_seq = []\\n\\n        # TODO this actually can\\'t take a key because recording this key is really hard\\n        # it\\'s not exposed to the user so we can\\'t ask them to store it. Not a problem\\n        # for now but will have to get creative in the future potentially.\\n        for key, state, actions in state_seq:\\n            # There is a split in the step function of MultiAgentEnv\\n            # We call split here so that the action key is the same.\\n            key, _ = jax.random.split(key)\\n            states = self.step_env(key, state, actions, get_state_sequence=True)\\n            states = list(map(SMAXState, *dataclasses.astuple(states)))\\n            viz_actions = {\\n                agent: states[-1].prev_attack_actions[i]\\n                for i, agent in enumerate(self.all_agents)\\n            }\\n\\n            expanded_state_seq.append((key, state.state, viz_actions))\\n            expanded_state_seq.extend(\\n                zip([key] * len(states), states, [viz_actions] * len(states))\\n            )\\n            state = state.replace(\\n                state=state.state.replace(terminal=self.is_terminal(state))\\n            )\\n        return expanded_state_seq\\n\\n\\n# wrapper for creation of env playing against user specified policy\\nclass LearnedPolicyEnemySMAX(EnemySMAX):\\n    def __init__(self, policy, params, config, **env_kwargs):\\n        super().__init__(**env_kwargs)\\n        self.policy = policy\\n        self.params = params\\n        #self.hstate = hstate\\n        self.config = config\\n\\n\\n    def preprocess_obs_with_id(self, enemy_obs):\\n        \"\"\"Add one-hot agent ID encoding to enemy obs.\"\"\"\\n        num_enemies = self._env.num_enemies\\n        new_obs = []\\n        for i, obs in enumerate(enemy_obs):\\n            one_hot = jax.nn.one_hot(i, num_classes=num_enemies)\\n            new_obs.append(jnp.concatenate([obs, one_hot]))\\n        return jnp.stack(new_obs)  # shape: [num_enemies, obs_dim + num_enemies]\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        #self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\\n        self.hstate = ScannedRNN.initialize_carry(config[\"HIDDEN_SIZE\"], self._env.num_enemies) # use num envs from config instead of ippo_config\\n        return (self.params, self.hstate)\\n\\n    def mirror_obs_unit_list(self, obs_array):\\n        \"\"\"Mirror enemy obs to ally POV.\"\"\"\\n        obs_dim = obs_array.shape[-1]\\n        num_units_other = (self.num_enemies - 1) + self.num_allies\\n        unit_feat_len = len(self._env.unit_features)\\n        own_feat_len = len(self._env.own_features)\\n\\n        # Split into \"other units\" block and \"own\" block\\n        other_units_flat = obs_array[..., :num_units_other * unit_feat_len]\\n        own_block = obs_array[..., num_units_other * unit_feat_len:]\\n\\n        # Reshape to [num_units_other, unit_feat_len]\\n        other_units = other_units_flat.reshape(obs_array.shape[0], num_units_other, unit_feat_len)\\n\\n        # Flip X-related features\\n        x_idx = self._env.unit_features.index(\"position_x\")\\n        last_x_idx = self._env.unit_features.index(\"last_movement_x\")\\n        other_units = other_units.at[..., x_idx].set(1.0 - other_units[..., x_idx])\\n        other_units = other_units.at[..., last_x_idx].set(-other_units[..., last_x_idx])\\n\\n        # Reverse order to swap ally/enemy view\\n        other_units = other_units[..., ::-1, :]\\n\\n        # Mirror own features\\n        own_feats = own_block\\n        ox_idx = self._env.own_features.index(\"position_x\")\\n        own_feats = own_feats.at[..., ox_idx].set(1.0 - own_feats[..., ox_idx])\\n\\n        # Recombine\\n        mirrored = jnp.concatenate([other_units.reshape(obs_array.shape[0], -1), own_feats], axis=-1)\\n        return mirrored\\n\\n    def mirror_policy_to_env_actions_no_attack_mirror(self, policy_actions):\\n        \"\"\"\\n        Mirror movement only. Keep attack indices as-is.\\n        \"\"\"\\n        num_move = self._env.num_movement_actions  # 5\\n        # Movement mapping for 0:N, 1:E, 2:S, 3:W, 4:Stop\\n        move_map = jnp.array([0, 3, 2, 1, num_move - 1], dtype=jnp.int32)\\n\\n        is_move = policy_actions < num_move\\n        mapped_moves = move_map[policy_actions]\\n\\n        # Attacks are unchanged\\n        mapped_attacks = policy_actions\\n\\n        env_actions = jnp.where(is_move, mapped_moves, mapped_attacks)\\n        return env_actions.astype(jnp.int32)\\n\\n    def get_enemy_actions(self, key, policy_state, enemy_obs, enemy_dones, enemy_avail_actions): #enemy_x):\\n        params, hstate = policy_state\\n\\n        # mirror the obs\\n        enemy_obs = self.mirror_obs_unit_list(enemy_obs)\\n        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\\n        enemy_obs = self.preprocess_obs_with_id(enemy_obs)\\n        #enemy_obs = jnp.array(enemy_obs)  # ensure JAX array\\n        enemy_obs = enemy_obs[jnp.newaxis, :]  # shape [1, num_enemies, obs_dim + num_enemies]\\n\\n        #enemy_dones = jnp.array(enemy_dones)  # ensure JAX array\\n        enemy_dones = enemy_dones[jnp.newaxis, :]  # [1, num_enemies]\\n        #enemy_avail_actions = jnp.array(enemy_avail_actions)  # ensure JAX array\\n        enemy_avail_actions = enemy_avail_actions[jnp.newaxis, :]  # [1, num_enemies, num_actions]\\n\\n        #print(\"hstate shape:\", hstate.shape)\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        #pi, _ = self.policy.apply(policy_state, enemy_obs)\\n        hstate, q_vals = self.policy.apply(params, hstate, enemy_obs, enemy_dones) #enemy_x)\\n        #print(\"q_val shape:\", q_vals.shape)\\n\\n        unavail_actions = 1 - enemy_avail_actions\\n        q_vals = q_vals - (unavail_actions * 1e10)\\n        enemy_actions = jnp.argmax(q_vals, axis=-1).squeeze(0)\\n\\n        # Mirror the actions\\n        enemy_actions = self.mirror_policy_to_env_actions_no_attack_mirror(enemy_actions)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        enemy_actions = {\\n            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\\n            for agent in self.enemy_agents\\n        }\\n        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\\n        policy_state = (params, hstate)\\n        return enemy_actions, policy_state\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for the RNNActor policy network\n",
    "'''\n",
    "import dataclasses\n",
    "from jaxmarl.environments.smax.smax_env import SMAX\n",
    "from jaxmarl.environments.smax.smax_env import State as SMAXState\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "from flax import struct\n",
    "\n",
    "@struct.dataclass\n",
    "class State:\n",
    "    # underlying jaxmarl env state\n",
    "    state: ...\n",
    "    # the enemy policy state. Needed for recurrent policies or\n",
    "    # remembering details about previous observations for heuristics.\n",
    "    enemy_policy_state: ...\n",
    "\n",
    "class EnemySMAX(MultiAgentEnv):\n",
    "    \"\"\"Class that presents the SMAX environment as a single-player\n",
    "    (but still multi-agent) environment. Functions like a wrapper, but\n",
    "    not linked with any of the wrapper code because that is used differently.\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, **env_kwargs):\n",
    "        self._env = SMAX(**env_kwargs)\n",
    "        # only one team\n",
    "        self.num_agents = self._env.num_allies\n",
    "        self.num_enemies = self._env.num_enemies\n",
    "        # want to provide a consistent API between this and SMAX\n",
    "        self.num_allies = self._env.num_allies\n",
    "        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\n",
    "        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\n",
    "        self.all_agents = self.agents + self.enemy_agents\n",
    "        self.observation_spaces = {\n",
    "            i: self._env.observation_spaces[i] for i in self.agents\n",
    "        }\n",
    "        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\n",
    "        key, reset_key = jax.random.split(key)\n",
    "        obs, state = self._env.reset(reset_key)\n",
    "        enemy_policy_state = self.get_enemy_policy_initial_state(key)\n",
    "        new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "        new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\n",
    "\n",
    "    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0, 4))\n",
    "    def step_env(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: State,\n",
    "        actions: Dict[str, chex.Array],\n",
    "        get_state_sequence=False,\n",
    "    ):\n",
    "        jaxmarl_state = state.state\n",
    "        obs = self._env.get_obs(jaxmarl_state)\n",
    "        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\n",
    "        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\n",
    "        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_dones = {\n",
    "            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\n",
    "        \n",
    "        #enemy_x = (    \n",
    "        #    enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\n",
    "        #    enemy_dones[jnp.newaxis, :],    # [1, num_agents]\n",
    "        #    enemy_avail_actions              # [1, num_agents, num_actions]\n",
    "        #)\n",
    "\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "\n",
    "        key, action_key = jax.random.split(key)\n",
    "        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "        #    action_key, state.enemy_policy_state, enemy_obs\n",
    "        #)\n",
    "        enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "            action_key, state.enemy_policy_state, enemy_obs, enemy_dones, enemy_avail_actions #enemy_x\n",
    "        )\n",
    "        \n",
    "        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \n",
    "        actions = jnp.array([actions[i] for i in self.agents])\n",
    "        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        #print(\"enemy_actions:\", enemy_actions)\n",
    "        #print(\"actions shape:\", actions.shape)\n",
    "        enemy_movement_actions, enemy_attack_actions = (\n",
    "            self._env._decode_discrete_actions(enemy_actions)\n",
    "        )\n",
    "        if self._env.action_type == \"continuous\":\n",
    "            cont_actions = jnp.zeros((len(self.all_agents), 4))\n",
    "            cont_actions = cont_actions.at[: self.num_allies].set(actions)\n",
    "            key, action_key = jax.random.split(key)\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_continuous_actions(\n",
    "                    action_key, jaxmarl_state, cont_actions\n",
    "                )\n",
    "            )\n",
    "            ally_movement_actions = ally_movement_actions[: self.num_allies]\n",
    "            ally_attack_actions = ally_attack_actions[: self.num_allies]\n",
    "        else:\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_discrete_actions(actions)\n",
    "            )\n",
    "\n",
    "        movement_actions = jnp.concatenate(\n",
    "            [ally_movement_actions, enemy_movement_actions], axis=0\n",
    "        )\n",
    "        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\n",
    "\n",
    "        if not get_state_sequence:\n",
    "            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "            new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "            rewards = {agent: rewards[agent] for agent in self.agents}\n",
    "            all_done = dones[\"__all__\"]\n",
    "            dones = {agent: dones[agent] for agent in self.agents}\n",
    "            dones[\"__all__\"] = all_done\n",
    "\n",
    "            state = state.replace(\n",
    "                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\n",
    "            )\n",
    "            return new_obs, state, rewards, dones, infos\n",
    "        else:\n",
    "            states = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            return states\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def get_avail_actions(self, state: State):\n",
    "        avail_actions = self._env.get_avail_actions(state.state)\n",
    "        return {agent: avail_actions[agent] for agent in self.agents}\n",
    "\n",
    "    def get_all_unit_obs(self, state: State):\n",
    "        return self._env.get_obs(state.state)\n",
    "\n",
    "    def get_obs(self, state: State) -> Dict[str, chex.Array]:\n",
    "        obs = self.get_all_unit_obs(state)\n",
    "        return {agent: obs[agent] for agent in self.agents}\n",
    "\n",
    "    def get_world_state(self, state: State):\n",
    "        return self._env.get_world_state(state.state)\n",
    "\n",
    "    def is_terminal(self, state: State):\n",
    "        return self._env.is_terminal(state.state)\n",
    "\n",
    "    def expand_state_seq(self, state_seq):\n",
    "        # TODO jit/scan this\n",
    "        expanded_state_seq = []\n",
    "\n",
    "        # TODO this actually can't take a key because recording this key is really hard\n",
    "        # it's not exposed to the user so we can't ask them to store it. Not a problem\n",
    "        # for now but will have to get creative in the future potentially.\n",
    "        for key, state, actions in state_seq:\n",
    "            # There is a split in the step function of MultiAgentEnv\n",
    "            # We call split here so that the action key is the same.\n",
    "            key, _ = jax.random.split(key)\n",
    "            states = self.step_env(key, state, actions, get_state_sequence=True)\n",
    "            states = list(map(SMAXState, *dataclasses.astuple(states)))\n",
    "            viz_actions = {\n",
    "                agent: states[-1].prev_attack_actions[i]\n",
    "                for i, agent in enumerate(self.all_agents)\n",
    "            }\n",
    "\n",
    "            expanded_state_seq.append((key, state.state, viz_actions))\n",
    "            expanded_state_seq.extend(\n",
    "                zip([key] * len(states), states, [viz_actions] * len(states))\n",
    "            )\n",
    "            state = state.replace(\n",
    "                state=state.state.replace(terminal=self.is_terminal(state))\n",
    "            )\n",
    "        return expanded_state_seq\n",
    "\n",
    "\n",
    "# wrapper for creation of env playing against user specified policy\n",
    "class LearnedPolicyEnemySMAX(EnemySMAX):\n",
    "    def __init__(self, policy, params, config, **env_kwargs):\n",
    "        super().__init__(**env_kwargs)\n",
    "        self.policy = policy\n",
    "        self.params = params\n",
    "        #self.hstate = hstate\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    def preprocess_obs_with_id(self, enemy_obs):\n",
    "        \"\"\"Add one-hot agent ID encoding to enemy obs.\"\"\"\n",
    "        num_enemies = self._env.num_enemies\n",
    "        new_obs = []\n",
    "        for i, obs in enumerate(enemy_obs):\n",
    "            one_hot = jax.nn.one_hot(i, num_classes=num_enemies)\n",
    "            new_obs.append(jnp.concatenate([obs, one_hot]))\n",
    "        return jnp.stack(new_obs)  # shape: [num_enemies, obs_dim + num_enemies]\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        #self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "        self.hstate = ScannedRNN.initialize_carry(config[\"HIDDEN_SIZE\"], self._env.num_enemies) # use num envs from config instead of ippo_config\n",
    "        return (self.params, self.hstate)\n",
    "    \n",
    "    def mirror_obs_unit_list(self, obs_array):\n",
    "        \"\"\"Mirror enemy obs to ally POV.\"\"\"\n",
    "        obs_dim = obs_array.shape[-1]\n",
    "        num_units_other = (self.num_enemies - 1) + self.num_allies\n",
    "        unit_feat_len = len(self._env.unit_features)\n",
    "        own_feat_len = len(self._env.own_features)\n",
    "\n",
    "        # Split into \"other units\" block and \"own\" block\n",
    "        other_units_flat = obs_array[..., :num_units_other * unit_feat_len]\n",
    "        own_block = obs_array[..., num_units_other * unit_feat_len:]\n",
    "\n",
    "        # Reshape to [num_units_other, unit_feat_len]\n",
    "        other_units = other_units_flat.reshape(obs_array.shape[0], num_units_other, unit_feat_len)\n",
    "\n",
    "        # Flip X-related features\n",
    "        x_idx = self._env.unit_features.index(\"position_x\")\n",
    "        last_x_idx = self._env.unit_features.index(\"last_movement_x\")\n",
    "        other_units = other_units.at[..., x_idx].set(1.0 - other_units[..., x_idx])\n",
    "        other_units = other_units.at[..., last_x_idx].set(-other_units[..., last_x_idx])\n",
    "\n",
    "        # Reverse order to swap ally/enemy view\n",
    "        other_units = other_units[..., ::-1, :]\n",
    "\n",
    "        # Mirror own features\n",
    "        own_feats = own_block\n",
    "        ox_idx = self._env.own_features.index(\"position_x\")\n",
    "        own_feats = own_feats.at[..., ox_idx].set(1.0 - own_feats[..., ox_idx])\n",
    "\n",
    "        # Recombine\n",
    "        mirrored = jnp.concatenate([other_units.reshape(obs_array.shape[0], -1), own_feats], axis=-1)\n",
    "        return mirrored\n",
    "    \n",
    "    def mirror_policy_to_env_actions_no_attack_mirror(self, policy_actions):\n",
    "        \"\"\"\n",
    "        Mirror movement only. Keep attack indices as-is.\n",
    "        \"\"\"\n",
    "        num_move = self._env.num_movement_actions  # 5\n",
    "        # Movement mapping for 0:N, 1:E, 2:S, 3:W, 4:Stop\n",
    "        move_map = jnp.array([0, 3, 2, 1, num_move - 1], dtype=jnp.int32)\n",
    "\n",
    "        is_move = policy_actions < num_move\n",
    "        mapped_moves = move_map[policy_actions]\n",
    "\n",
    "        # Attacks are unchanged\n",
    "        mapped_attacks = policy_actions\n",
    "\n",
    "        env_actions = jnp.where(is_move, mapped_moves, mapped_attacks)\n",
    "        return env_actions.astype(jnp.int32)\n",
    "\n",
    "    def get_enemy_actions(self, key, policy_state, enemy_obs, enemy_dones, enemy_avail_actions): #enemy_x):\n",
    "        params, hstate = policy_state\n",
    "\n",
    "        # mirror the obs\n",
    "        enemy_obs = self.mirror_obs_unit_list(enemy_obs)\n",
    "        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\n",
    "        enemy_obs = self.preprocess_obs_with_id(enemy_obs)\n",
    "        #enemy_obs = jnp.array(enemy_obs)  # ensure JAX array\n",
    "        enemy_obs = enemy_obs[jnp.newaxis, :]  # shape [1, num_enemies, obs_dim + num_enemies]\n",
    "\n",
    "        #enemy_dones = jnp.array(enemy_dones)  # ensure JAX array\n",
    "        enemy_dones = enemy_dones[jnp.newaxis, :]  # [1, num_enemies]\n",
    "        #enemy_avail_actions = jnp.array(enemy_avail_actions)  # ensure JAX array\n",
    "        enemy_avail_actions = enemy_avail_actions[jnp.newaxis, :]  # [1, num_enemies, num_actions]\n",
    "\n",
    "        #print(\"hstate shape:\", hstate.shape)\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        #pi, _ = self.policy.apply(policy_state, enemy_obs)\n",
    "        hstate, q_vals = self.policy.apply(params, hstate, enemy_obs, enemy_dones) #enemy_x)\n",
    "        #print(\"q_val shape:\", q_vals.shape)\n",
    "\n",
    "        unavail_actions = 1 - enemy_avail_actions\n",
    "        q_vals = q_vals - (unavail_actions * 1e10)\n",
    "        enemy_actions = jnp.argmax(q_vals, axis=-1).squeeze(0)\n",
    "        \n",
    "        # Mirror the actions\n",
    "        enemy_actions = self.mirror_policy_to_env_actions_no_attack_mirror(enemy_actions)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        enemy_actions = {\n",
    "            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\n",
    "            for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\n",
    "        policy_state = (params, hstate)\n",
    "        return enemy_actions, policy_state\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bdd397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dataclasses\\nfrom jaxmarl.environments.smax.smax_env import SMAX\\nfrom jaxmarl.environments.smax.smax_env import State as SMAXState\\nfrom jaxmarl.environments.multi_agent_env import MultiAgentEnv\\n\\nfrom flax import struct\\n\\n@struct.dataclass\\nclass State:\\n    # underlying jaxmarl env state\\n    state: ...\\n    # the enemy policy state. Needed for recurrent policies or\\n    # remembering details about previous observations for heuristics.\\n    enemy_policy_state: ...\\n\\nclass EnemySMAX(MultiAgentEnv):\\n    \"\"\"Class that presents the SMAX environment as a single-player\\n    (but still multi-agent) environment. Functions like a wrapper, but\\n    not linked with any of the wrapper code because that is used differently.\"\"\"\\n\\n\\n\\n    def __init__(self, **env_kwargs):\\n        self._env = SMAX(**env_kwargs)\\n        # only one team\\n        self.num_agents = self._env.num_allies\\n        self.num_enemies = self._env.num_enemies\\n        # want to provide a consistent API between this and SMAX\\n        self.num_allies = self._env.num_allies\\n        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\\n        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\\n        self.all_agents = self.agents + self.enemy_agents\\n        self.observation_spaces = {\\n            i: self._env.observation_spaces[i] for i in self.agents\\n        }\\n        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\\n\\n    def __getattr__(self, name: str):\\n        return getattr(self._env, name)\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\\n        key, reset_key = jax.random.split(key)\\n        obs, state = self._env.reset(reset_key)\\n        enemy_policy_state = self.get_enemy_policy_initial_state(key)\\n        new_obs = {agent: obs[agent] for agent in self.agents}\\n        new_obs[\"world_state\"] = obs[\"world_state\"]\\n        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\\n\\n    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\\n        raise NotImplementedError\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        raise NotImplementedError\\n\\n    @partial(jax.jit, static_argnums=(0, 4))\\n    def step_env(\\n        self,\\n        key: chex.PRNGKey,\\n        state: State,\\n        actions: Dict[str, chex.Array],\\n        get_state_sequence=False,\\n    ):\\n        jaxmarl_state = state.state\\n        obs = self._env.get_obs(jaxmarl_state)\\n        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\\n        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\\n\\n        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\\n        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\\n\\n        enemy_dones = {\\n            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\\n        }\\n        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\\n\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        enemy_x = (    \\n            enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\\n            enemy_dones[jnp.newaxis, :],    # [1, num_agents]\\n            enemy_avail_actions              # [1, num_agents, num_actions]\\n        )\\n\\n        key, action_key = jax.random.split(key)\\n        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n        #    action_key, state.enemy_policy_state, enemy_obs\\n        #)\\n        enemy_actions, enemy_policy_state = self.get_enemy_actions(\\n            action_key, state.enemy_policy_state, enemy_x\\n        )\\n\\n        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \\n        actions = jnp.array([actions[i] for i in self.agents])\\n        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        #print(\"enemy_actions:\", enemy_actions)\\n        #print(\"actions shape:\", actions.shape)\\n        enemy_movement_actions, enemy_attack_actions = (\\n            self._env._decode_discrete_actions(enemy_actions)\\n        )\\n        if self._env.action_type == \"continuous\":\\n            cont_actions = jnp.zeros((len(self.all_agents), 4))\\n            cont_actions = cont_actions.at[: self.num_allies].set(actions)\\n            key, action_key = jax.random.split(key)\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_continuous_actions(\\n                    action_key, jaxmarl_state, cont_actions\\n                )\\n            )\\n            ally_movement_actions = ally_movement_actions[: self.num_allies]\\n            ally_attack_actions = ally_attack_actions[: self.num_allies]\\n        else:\\n            ally_movement_actions, ally_attack_actions = (\\n                self._env._decode_discrete_actions(actions)\\n            )\\n\\n        movement_actions = jnp.concatenate(\\n            [ally_movement_actions, enemy_movement_actions], axis=0\\n        )\\n        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\\n\\n        if not get_state_sequence:\\n            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            new_obs = {agent: obs[agent] for agent in self.agents}\\n            new_obs[\"world_state\"] = obs[\"world_state\"]\\n            rewards = {agent: rewards[agent] for agent in self.agents}\\n            all_done = dones[\"__all__\"]\\n            dones = {agent: dones[agent] for agent in self.agents}\\n            dones[\"__all__\"] = all_done\\n\\n            state = state.replace(\\n                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\\n            )\\n            return new_obs, state, rewards, dones, infos\\n        else:\\n            states = self._env.step_env_no_decode(\\n                key,\\n                jaxmarl_state,\\n                (movement_actions, attack_actions),\\n                get_state_sequence=get_state_sequence,\\n            )\\n            return states\\n\\n    @partial(jax.jit, static_argnums=(0,))\\n    def get_avail_actions(self, state: State):\\n        avail_actions = self._env.get_avail_actions(state.state)\\n        return {agent: avail_actions[agent] for agent in self.agents}\\n\\n    def get_all_unit_obs(self, state: State):\\n        return self._env.get_obs(state.state)\\n\\n    def get_obs(self, state: State) -> Dict[str, chex.Array]:\\n        obs = self.get_all_unit_obs(state)\\n        return {agent: obs[agent] for agent in self.agents}\\n\\n    def get_world_state(self, state: State):\\n        return self._env.get_world_state(state.state)\\n\\n    def is_terminal(self, state: State):\\n        return self._env.is_terminal(state.state)\\n\\n    def expand_state_seq(self, state_seq):\\n        # TODO jit/scan this\\n        expanded_state_seq = []\\n\\n        # TODO this actually can\\'t take a key because recording this key is really hard\\n        # it\\'s not exposed to the user so we can\\'t ask them to store it. Not a problem\\n        # for now but will have to get creative in the future potentially.\\n        for key, state, actions in state_seq:\\n            # There is a split in the step function of MultiAgentEnv\\n            # We call split here so that the action key is the same.\\n            key, _ = jax.random.split(key)\\n            states = self.step_env(key, state, actions, get_state_sequence=True)\\n            states = list(map(SMAXState, *dataclasses.astuple(states)))\\n            viz_actions = {\\n                agent: states[-1].prev_attack_actions[i]\\n                for i, agent in enumerate(self.all_agents)\\n            }\\n\\n            expanded_state_seq.append((key, state.state, viz_actions))\\n            expanded_state_seq.extend(\\n                zip([key] * len(states), states, [viz_actions] * len(states))\\n            )\\n            state = state.replace(\\n                state=state.state.replace(terminal=self.is_terminal(state))\\n            )\\n        return expanded_state_seq\\n\\n\\n\\n# wrapper for creation of env playing against user specified policy\\nclass LearnedPolicyEnemySMAX(EnemySMAX):\\n    def __init__(self, policy, params, config, **env_kwargs):\\n        super().__init__(**env_kwargs)\\n        self.policy = policy\\n        self.params = params\\n        #self.hstate = hstate\\n        self.config = config\\n\\n    def get_enemy_policy_initial_state(self, key):\\n        self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\\n        return (self.params, self.hstate)\\n\\n    def get_enemy_actions(self, key, policy_state, enemy_x):\\n        params, hstate = policy_state\\n        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\\n\\n        #print(\"hstate shape:\", hstate.shape)\\n        #print(\"enemy_obs shape:\", enemy_obs.shape)\\n        #print(\"enemy_dones shape:\", enemy_dones.shape)\\n        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\\n\\n        #pi, _ = self.policy.apply(policy_state, enemy_obs)\\n        hstate, pi, _ = self.policy.apply(params, hstate, enemy_x)\\n        enemy_actions = pi.sample(seed=key) \\n        enemy_actions = jnp.squeeze(enemy_actions, axis=0)\\n        #print(\"enemy_actions shape:\", enemy_actions.shape)\\n        enemy_actions = {\\n            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\\n            for agent in self.enemy_agents\\n        }\\n        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\\n        policy_state = (params, hstate)\\n        return enemy_actions, policy_state\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used for the IPPO ActorCriticRNN policy network\n",
    "'''\n",
    "import dataclasses\n",
    "from jaxmarl.environments.smax.smax_env import SMAX\n",
    "from jaxmarl.environments.smax.smax_env import State as SMAXState\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "from flax import struct\n",
    "\n",
    "@struct.dataclass\n",
    "class State:\n",
    "    # underlying jaxmarl env state\n",
    "    state: ...\n",
    "    # the enemy policy state. Needed for recurrent policies or\n",
    "    # remembering details about previous observations for heuristics.\n",
    "    enemy_policy_state: ...\n",
    "\n",
    "class EnemySMAX(MultiAgentEnv):\n",
    "    \"\"\"Class that presents the SMAX environment as a single-player\n",
    "    (but still multi-agent) environment. Functions like a wrapper, but\n",
    "    not linked with any of the wrapper code because that is used differently.\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, **env_kwargs):\n",
    "        self._env = SMAX(**env_kwargs)\n",
    "        # only one team\n",
    "        self.num_agents = self._env.num_allies\n",
    "        self.num_enemies = self._env.num_enemies\n",
    "        # want to provide a consistent API between this and SMAX\n",
    "        self.num_allies = self._env.num_allies\n",
    "        self.agents = [f\"ally_{i}\" for i in range(self.num_agents)]\n",
    "        self.enemy_agents = [f\"enemy_{i}\" for i in range(self.num_enemies)]\n",
    "        self.all_agents = self.agents + self.enemy_agents\n",
    "        self.observation_spaces = {\n",
    "            i: self._env.observation_spaces[i] for i in self.agents\n",
    "        }\n",
    "        self.action_spaces = {i: self._env.action_spaces[i] for i in self.agents}\n",
    "\n",
    "    def __getattr__(self, name: str):\n",
    "        return getattr(self._env, name)\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(self, key: chex.PRNGKey) -> Tuple[Dict[str, chex.Array], State]:\n",
    "        key, reset_key = jax.random.split(key)\n",
    "        obs, state = self._env.reset(reset_key)\n",
    "        enemy_policy_state = self.get_enemy_policy_initial_state(key)\n",
    "        new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "        new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "        return new_obs, State(state=state, enemy_policy_state=enemy_policy_state)\n",
    "\n",
    "    def get_enemy_actions(self, key, enemy_policy_state, enemy_obs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0, 4))\n",
    "    def step_env(\n",
    "        self,\n",
    "        key: chex.PRNGKey,\n",
    "        state: State,\n",
    "        actions: Dict[str, chex.Array],\n",
    "        get_state_sequence=False,\n",
    "    ):\n",
    "        jaxmarl_state = state.state\n",
    "        obs = self._env.get_obs(jaxmarl_state)\n",
    "        enemy_obs = self._env.get_obs_unit_list(jaxmarl_state)\n",
    "        enemy_obs = jnp.array([enemy_obs[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_avail_actions = self._env.get_avail_actions(jaxmarl_state)\n",
    "        enemy_avail_actions = jnp.array([enemy_avail_actions[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        enemy_dones = {\n",
    "            agent: ~state.state.unit_alive[self.agent_ids[agent]] for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_dones = jnp.array([enemy_dones[agent] for agent in self.enemy_agents])\n",
    "\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        enemy_x = (    \n",
    "            enemy_obs[jnp.newaxis, :],     # [1, num_agents, ...]\n",
    "            enemy_dones[jnp.newaxis, :],    # [1, num_agents]\n",
    "            enemy_avail_actions              # [1, num_agents, num_actions]\n",
    "        )\n",
    "\n",
    "        key, action_key = jax.random.split(key)\n",
    "        #enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "        #    action_key, state.enemy_policy_state, enemy_obs\n",
    "        #)\n",
    "        enemy_actions, enemy_policy_state = self.get_enemy_actions(\n",
    "            action_key, state.enemy_policy_state, enemy_x\n",
    "        )\n",
    "        \n",
    "        enemy_actions = jnp.array([enemy_actions[i] for i in self.enemy_agents]) \n",
    "        actions = jnp.array([actions[i] for i in self.agents])\n",
    "        #print(\"enemy_actions dtype:\", enemy_actions.dtype)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        #print(\"enemy_actions:\", enemy_actions)\n",
    "        #print(\"actions shape:\", actions.shape)\n",
    "        enemy_movement_actions, enemy_attack_actions = (\n",
    "            self._env._decode_discrete_actions(enemy_actions)\n",
    "        )\n",
    "        if self._env.action_type == \"continuous\":\n",
    "            cont_actions = jnp.zeros((len(self.all_agents), 4))\n",
    "            cont_actions = cont_actions.at[: self.num_allies].set(actions)\n",
    "            key, action_key = jax.random.split(key)\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_continuous_actions(\n",
    "                    action_key, jaxmarl_state, cont_actions\n",
    "                )\n",
    "            )\n",
    "            ally_movement_actions = ally_movement_actions[: self.num_allies]\n",
    "            ally_attack_actions = ally_attack_actions[: self.num_allies]\n",
    "        else:\n",
    "            ally_movement_actions, ally_attack_actions = (\n",
    "                self._env._decode_discrete_actions(actions)\n",
    "            )\n",
    "\n",
    "        movement_actions = jnp.concatenate(\n",
    "            [ally_movement_actions, enemy_movement_actions], axis=0\n",
    "        )\n",
    "        attack_actions = jnp.concatenate([ally_attack_actions, enemy_attack_actions], axis=0)\n",
    "\n",
    "        if not get_state_sequence:\n",
    "            obs, jaxmarl_state, rewards, dones, infos = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            new_obs = {agent: obs[agent] for agent in self.agents}\n",
    "            new_obs[\"world_state\"] = obs[\"world_state\"]\n",
    "            rewards = {agent: rewards[agent] for agent in self.agents}\n",
    "            all_done = dones[\"__all__\"]\n",
    "            dones = {agent: dones[agent] for agent in self.agents}\n",
    "            dones[\"__all__\"] = all_done\n",
    "\n",
    "            state = state.replace(\n",
    "                enemy_policy_state=enemy_policy_state, state=jaxmarl_state\n",
    "            )\n",
    "            return new_obs, state, rewards, dones, infos\n",
    "        else:\n",
    "            states = self._env.step_env_no_decode(\n",
    "                key,\n",
    "                jaxmarl_state,\n",
    "                (movement_actions, attack_actions),\n",
    "                get_state_sequence=get_state_sequence,\n",
    "            )\n",
    "            return states\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def get_avail_actions(self, state: State):\n",
    "        avail_actions = self._env.get_avail_actions(state.state)\n",
    "        return {agent: avail_actions[agent] for agent in self.agents}\n",
    "\n",
    "    def get_all_unit_obs(self, state: State):\n",
    "        return self._env.get_obs(state.state)\n",
    "\n",
    "    def get_obs(self, state: State) -> Dict[str, chex.Array]:\n",
    "        obs = self.get_all_unit_obs(state)\n",
    "        return {agent: obs[agent] for agent in self.agents}\n",
    "\n",
    "    def get_world_state(self, state: State):\n",
    "        return self._env.get_world_state(state.state)\n",
    "\n",
    "    def is_terminal(self, state: State):\n",
    "        return self._env.is_terminal(state.state)\n",
    "\n",
    "    def expand_state_seq(self, state_seq):\n",
    "        # TODO jit/scan this\n",
    "        expanded_state_seq = []\n",
    "\n",
    "        # TODO this actually can't take a key because recording this key is really hard\n",
    "        # it's not exposed to the user so we can't ask them to store it. Not a problem\n",
    "        # for now but will have to get creative in the future potentially.\n",
    "        for key, state, actions in state_seq:\n",
    "            # There is a split in the step function of MultiAgentEnv\n",
    "            # We call split here so that the action key is the same.\n",
    "            key, _ = jax.random.split(key)\n",
    "            states = self.step_env(key, state, actions, get_state_sequence=True)\n",
    "            states = list(map(SMAXState, *dataclasses.astuple(states)))\n",
    "            viz_actions = {\n",
    "                agent: states[-1].prev_attack_actions[i]\n",
    "                for i, agent in enumerate(self.all_agents)\n",
    "            }\n",
    "\n",
    "            expanded_state_seq.append((key, state.state, viz_actions))\n",
    "            expanded_state_seq.extend(\n",
    "                zip([key] * len(states), states, [viz_actions] * len(states))\n",
    "            )\n",
    "            state = state.replace(\n",
    "                state=state.state.replace(terminal=self.is_terminal(state))\n",
    "            )\n",
    "        return expanded_state_seq\n",
    "\n",
    "\n",
    "\n",
    "# wrapper for creation of env playing against user specified policy\n",
    "class LearnedPolicyEnemySMAX(EnemySMAX):\n",
    "    def __init__(self, policy, params, config, **env_kwargs):\n",
    "        super().__init__(**env_kwargs)\n",
    "        self.policy = policy\n",
    "        self.params = params\n",
    "        #self.hstate = hstate\n",
    "        self.config = config\n",
    "\n",
    "    def get_enemy_policy_initial_state(self, key):\n",
    "        self.hstate = ScannedRNNIPPO.initialize_carry(self._env.num_enemies, ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "        return (self.params, self.hstate)\n",
    "\n",
    "    def get_enemy_actions(self, key, policy_state, enemy_x):\n",
    "        params, hstate = policy_state\n",
    "        #enemy_obs, enemy_dones, enemy_avail_actions = enemy_x\n",
    "\n",
    "        #print(\"hstate shape:\", hstate.shape)\n",
    "        #print(\"enemy_obs shape:\", enemy_obs.shape)\n",
    "        #print(\"enemy_dones shape:\", enemy_dones.shape)\n",
    "        #print(\"enemy_avail_actions shape:\", enemy_avail_actions.shape)\n",
    "        \n",
    "        #pi, _ = self.policy.apply(policy_state, enemy_obs)\n",
    "        hstate, pi, _ = self.policy.apply(params, hstate, enemy_x)\n",
    "        enemy_actions = pi.sample(seed=key) \n",
    "        enemy_actions = jnp.squeeze(enemy_actions, axis=0)\n",
    "        #print(\"enemy_actions shape:\", enemy_actions.shape)\n",
    "        enemy_actions = {\n",
    "            agent: enemy_actions[self._env.agent_ids[agent] - self.num_agents]\n",
    "            for agent in self.enemy_agents\n",
    "        }\n",
    "        enemy_actions = {k: v.squeeze() for k, v in enemy_actions.items()}\n",
    "        policy_state = (params, hstate)\n",
    "        return enemy_actions, policy_state\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03c27f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded agent params\n",
      "Loaded mixer params\n"
     ]
    }
   ],
   "source": [
    "# Init environment\n",
    "from flax.serialization import from_bytes # For loading pretrained params\n",
    "\n",
    "#env = environments.create(env_name, episode_length=episode_length)\n",
    "scenario = map_name_to_scenario(config[\"MAP_NAME\"])\n",
    "env = HeuristicEnemySMAX(scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "#ippo_hstate = ScannedRNNIPPO.initialize_carry(config[\"NUM_ACTORS\"], ippo_config[\"GRU_HIDDEN_DIM\"]) # use num envs from config instead of ippo_config\n",
    "#env = LearnedPolicyEnemySMAX(policy = dummy_network, params=trained_ippo_params, config=config, scenario=scenario, **config[\"ENV_KWARGS\"]) # env against trained IPPO policy\n",
    "env = SMAXLogWrapper(env)\n",
    "wrapped_env = CTRolloutManager(env, batch_size=config[\"NUM_ENVS\"])\n",
    "\n",
    "rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "reset_fn = jax.jit(wrapped_env.batch_reset)\n",
    "#reset_fn = jax.jit(env.reset)\n",
    "\n",
    "config[\"NUM_ACTORS\"] = env.num_agents * config[\"NUM_ENVS\"]\n",
    "config[\"NUM_UPDATES\"] = (\n",
    "    config[\"TOTAL_TIMESTEPS\"] // config[\"NUM_STEPS\"] // config[\"NUM_ENVS\"]\n",
    ")\n",
    "\n",
    "\n",
    "# Init a random key\n",
    "key = jax.random.key(seed)\n",
    "\n",
    "# Init policy network\n",
    "policy_layer_sizes = policy_hidden_layer_sizes + (env.action_space(env.agents[0]).n,) # Not actually used\n",
    "#policy_network = ActorRNN(env.action_space(env.agents[0]).n, config=config)\n",
    "policy_network = RNNQNetwork(\n",
    "            action_dim=wrapped_env.max_action_space,\n",
    "            hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "        )\n",
    "\n",
    "# Init mixer used in qmix\n",
    "mixer = MixingNetwork(\n",
    "    config[\"MIXER_EMBEDDING_DIM\"],\n",
    "    config[\"MIXER_HYPERNET_HIDDEN_DIM\"],\n",
    "    config[\"MIXER_INIT_SCALE\"],\n",
    ")\n",
    "\n",
    "# Init population of controllers\n",
    "key, subkey = jax.random.split(key)\n",
    "#keys = jax.random.split(subkey, num=batch_size)\n",
    "# fake_batch = jnp.zeros(shape=(batch_size, env.observation_size)) # Not needed as on-policy is used for no batches?\n",
    "# init_variables = jax.vmap(policy_network.init)(keys, fake_batch)\n",
    "init_x = (\n",
    "    jnp.zeros(\n",
    "        (1, 1, wrapped_env.obs_size)\n",
    "    ),  # (time_step, batch_size, obs_size)\n",
    "    jnp.zeros((1, 1)),  # (time_step, batch size)\n",
    ")\n",
    "init_hstate = ScannedRNN.initialize_carry(\n",
    "    config[\"HIDDEN_SIZE\"], 1\n",
    ")  # (batch_size, hidden_dim)\n",
    "\n",
    "keys = jax.random.split(subkey, batch_size-1) # subtract 1 from batch size for loaded params added later\n",
    "\n",
    "# Assume init_hstate: [H], init_x: [X]\n",
    "#fake_hstate = jnp.stack([init_hstate] * batch_size)  # [N, H]\n",
    "#fake_x = tuple(jnp.stack([x] * batch_size) for x in init_x)\n",
    "\n",
    "# Add leading batch dim and broadcast fake hidden state\n",
    "fake_hstate = jnp.broadcast_to(jnp.expand_dims(init_hstate, 0), (batch_size-1, *init_hstate.shape))  # [batch_size, H]\n",
    "# Same for each element in init_x tuple (assuming init_x is a tuple of arrays)\n",
    "fake_x = tuple(\n",
    "    jnp.broadcast_to(jnp.expand_dims(x, 0), (batch_size-1, *x.shape)) for x in init_x\n",
    ")\n",
    "\n",
    "# Load trained parameters\n",
    "dummy_params = policy_network.init(key, init_hstate, *init_x)\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_qmix_params.msgpack\", \"rb\") as f:\n",
    "    loaded_agent_params = from_bytes(dummy_params, f.read())\n",
    "print(\"Loaded agent params\")\n",
    "\n",
    "#network_params = policy_network.init(subkey, init_hstate, init_x)\n",
    "agent_params = jax.vmap(\n",
    "    policy_network.init\n",
    ")(keys, fake_hstate, *fake_x)\n",
    "\n",
    "# init mixer\n",
    "def _env_sample_step(env_state, unused):\n",
    "    rng, key_a, key_s = jax.random.split(\n",
    "        jax.random.PRNGKey(0), 3\n",
    "    )  # use a dummy rng here\n",
    "    key_a = jax.random.split(key_a, env.num_agents)\n",
    "    actions = {\n",
    "        agent: wrapped_env.batch_sample(key_a[i], agent)\n",
    "        for i, agent in enumerate(env.agents)\n",
    "    }\n",
    "    avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "    obs, env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        key_s, env_state, actions\n",
    "    )\n",
    "    timestep = Timestep(\n",
    "        obs=obs,\n",
    "        actions=actions,\n",
    "        rewards=rewards,\n",
    "        dones=dones,\n",
    "        avail_actions=avail_actions,\n",
    "    )\n",
    "    return env_state, timestep\n",
    "\n",
    "_, _env_state = wrapped_env.batch_reset(rng)\n",
    "_, sample_traj = jax.lax.scan(\n",
    "    _env_sample_step, _env_state, None, config[\"NUM_STEPS\"]\n",
    ")\n",
    "init_x = jnp.zeros((len(env.agents), 1, 1)) # q vals: agents, time, batch\n",
    "state_size = sample_traj.obs[\"__all__\"].shape[\n",
    "    -1\n",
    "]  # get the state shape from the buffer\n",
    "init_state = jnp.zeros((1, 1, state_size)) # (time_step, batch_size, obs_size)\n",
    "\n",
    "# Load trained mixer parameters\n",
    "dummy_mixer_params = mixer.init(key, init_x, init_state)\n",
    "with open(\"/vol/bitbucket/eww24/Masters_project/model_params/trained_qmix_mixer_params.msgpack\", \"rb\") as f:\n",
    "    loaded_mixer_params = from_bytes(dummy_mixer_params, f.read())\n",
    "print(\"Loaded mixer params\")\n",
    "\n",
    "init_x_batched = jnp.broadcast_to(jnp.expand_dims(init_x, 0), (batch_size-1, *init_x.shape))\n",
    "init_state_batched = jnp.broadcast_to(jnp.expand_dims(init_state, 0), (batch_size-1, *init_state.shape)) \n",
    "#mixer_params = mixer.init(subkey, init_x, init_state)\n",
    "mixer_params = jax.vmap(\n",
    "    mixer.init\n",
    ")(keys, init_x_batched, init_state_batched)\n",
    "\n",
    "# Add pretained solution \n",
    "# Add a batch axis \n",
    "loaded_agent_params = jax.tree.map(lambda p: jnp.expand_dims(p, 0), loaded_agent_params)\n",
    "loaded_mixer_params = jax.tree.map(lambda p: jnp.expand_dims(p, 0), loaded_mixer_params)\n",
    "# Append pretrained params at the end of the random ones\n",
    "combined_agent_params = jax.tree.map(\n",
    "    lambda rand, pre: jnp.concatenate([rand, pre], axis=0),\n",
    "    agent_params, loaded_agent_params\n",
    ")\n",
    "\n",
    "combined_mixer_params = jax.tree.map(\n",
    "    lambda rand, pre: jnp.concatenate([rand, pre], axis=0),\n",
    "    mixer_params, loaded_mixer_params\n",
    ")\n",
    "\n",
    "#network_params = {'agent': agent_params, 'mixer': mixer_params}\n",
    "\n",
    "network_params = {\"agent\": combined_agent_params, \"mixer\": combined_mixer_params,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ca9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(x: dict):\n",
    "    return jnp.stack([x[agent] for agent in env.agents], axis=0)\n",
    "\n",
    "def unbatchify(x: jnp.ndarray):\n",
    "    return {agent: x[i] for i, agent in enumerate(env.agents)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1703911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to play a step with the policy in the environment\n",
    "def play_step_fn(\n",
    "    runner_state\n",
    "):\n",
    "    \"\"\"\n",
    "    Play an environment step and return the updated state and the transition.\n",
    "    \"\"\"\n",
    "    #hs, last_obs, last_dones, env_state, rng = carry\n",
    "    policy_params, env_state, last_obs, last_dones, hstate, rng = runner_state\n",
    "\n",
    "    rng, rng_a, rng_s = jax.random.split(rng, 3)\n",
    "\n",
    "    # (num_agents, 1 (dummy time), num_envs, obs_size)\n",
    "    _obs = batchify(last_obs)[:, np.newaxis]\n",
    "    _dones = batchify(last_dones)[:, np.newaxis]\n",
    "    #_obs = batchify_multi(last_obs)[:, :, np.newaxis]    # [batch, num_agents, 1, num_envs, obs_dim]\n",
    "    #_dones = batchify_multi(last_dones)[:, :, np.newaxis] # [batch, num_agents, 1, num_envs]\n",
    "\n",
    "    #print(\"hstate shape:\", hstate.shape)  # should be [BATCH_SIZE, NUM_ENVS, NUM_AGENTS, HIDDEN_SIZE]\n",
    "    #print(\"_obs shape:\", _obs.shape)      # should be [BATCH_SIZE, NUM_ENVS, OBS_DIM]\n",
    "    #print(\"_dones shape:\", _dones.shape)  # should be [BATCH_SIZE, NUM_ENVS, OBS_DIM]\n",
    "\n",
    "    new_hstate, q_vals = jax.vmap(\n",
    "        policy_network.apply, in_axes=(None, 0, 0, 0)\n",
    "    )(  # vmap across the agent dim\n",
    "        policy_params['agent'],\n",
    "        hstate,\n",
    "        _obs,\n",
    "        _dones,\n",
    "    )\n",
    "    #print(\"new_hstate shape:\", new_hstate.shape)  # should be [BATCH_SIZE, NUM_ENVS, NUM_AGENTS, HIDDEN_SIZE]\n",
    "\n",
    "    q_vals = q_vals.squeeze(\n",
    "        axis=1\n",
    "    )  # (num_agents, num_envs, num_actions) remove the time dim\n",
    "\n",
    "    # explore\n",
    "    avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "    avail_actions_batchified = batchify(avail_actions)\n",
    "\n",
    "    #eps = eps_scheduler(train_state.n_updates)\n",
    "    #_rngs = jax.random.split(rng_a, env.num_agents)\n",
    "    #actions = jax.vmap(eps_greedy_exploration, in_axes=(0, 0, None, 0))(\n",
    "    #    _rngs, q_vals, eps, batchify(avail_actions)\n",
    "    #)\n",
    "    \n",
    "    unavail_actions = 1 - avail_actions_batchified\n",
    "    q_vals = q_vals - (unavail_actions * 1e10)\n",
    "    actions_array = jnp.argmax(q_vals, axis=-1)\n",
    "    actions_dict = unbatchify(actions_array)\n",
    "    #print(\"avail_actions_batchified\", avail_actions_batchified.shape)\n",
    "    #print(\"q_vals\", q_vals.shape)\n",
    "    #print(\"actions\", actions_array.shape)\n",
    "    #print(\"actions\", actions_dict)\n",
    "\n",
    "    #print(\"keys shape: {}\", rng_s.shape)\n",
    "    #print(\"states shape: {}\", jax.tree.map(lambda x: x.shape, env_state))\n",
    "    #print(\"actions_dict shapes: {}\", {k: v.shape for k, v in actions_dict.items()})\n",
    "\n",
    "\n",
    "    new_obs, new_env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        rng_s, env_state, actions_dict\n",
    "    )\n",
    "    \n",
    "    rewards = jax.tree.map(lambda x:config[\"REW_SCALE\"]*x, rewards)\n",
    "\n",
    "    timestep = Timestep(\n",
    "        obs=last_obs,\n",
    "        actions=actions_dict,\n",
    "        rewards=rewards, #jax.tree.map(lambda x:config.get(\"REW_SCALE\", 1)*x, rewards),\n",
    "        dones=last_dones,\n",
    "        avail_actions=avail_actions,\n",
    "    )\n",
    "\n",
    "    #per_agent_dones = jnp.stack(\n",
    "    #    [dones[agent] for agent in env.agents], axis=-1\n",
    "    #)  # shape: [num_envs, num_agents]\n",
    "\n",
    "    transition = Transition(\n",
    "        #jnp.tile(dones[\"__all__\"], env.num_agents),\n",
    "        #last_dones,\n",
    "        #actions_array.squeeze(),\n",
    "        #batchify(rewards).reshape(-1),#.reshape(batch_size, config[\"NUM_ENVS\"], -1),  #batchify(rewards, env.agents, config[\"NUM_ACTORS\"]).squeeze(),\n",
    "        #_obs,\n",
    "        env_state.env_state.state,\n",
    "        infos,\n",
    "        #avail_actions,\n",
    "    )\n",
    "\n",
    "    runner_state = (policy_params, new_env_state, new_obs, dones, new_hstate, rng)\n",
    "    \n",
    "    return runner_state, (transition, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72cf259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unroll(\n",
    "    runner_state,\n",
    "    episode_length: int,\n",
    "    play_step_fn: Callable[\n",
    "        [EnvState, Params, RNGKey],\n",
    "        Tuple[\n",
    "            EnvState,\n",
    "            Params,\n",
    "            RNGKey,\n",
    "            Transition,\n",
    "        ],\n",
    "    ],\n",
    ") -> Tuple[EnvState, Transition]:\n",
    "    \"\"\"Generates an episode according to the agent's policy, returns the final state of\n",
    "    the episode and the transitions of the episode.\n",
    "\n",
    "    Args:\n",
    "        init_state: first state of the rollout.\n",
    "        policy_params: params of the individual.\n",
    "        key: random key for stochasiticity handling.\n",
    "        episode_length: length of the rollout.\n",
    "        play_step_fn: function describing how a step need to be taken.\n",
    "\n",
    "    Returns:\n",
    "        A new state, the experienced transition.\n",
    "    \"\"\"\n",
    "\n",
    "    def _scan_play_step_fn(\n",
    "        carry, unused_arg: Any #: Tuple[EnvState, Params, RNGKey]\n",
    "    ) -> Tuple[Tuple[EnvState, Params, RNGKey], Transition]:\n",
    "        runner_state, (transitions, timestep) = play_step_fn(carry)\n",
    "        return runner_state, (transitions, timestep)\n",
    "\n",
    "    runner_state, (transitions, timestep) = jax.lax.scan(\n",
    "        _scan_play_step_fn,\n",
    "        runner_state,\n",
    "        (),\n",
    "        length=episode_length,\n",
    "    )\n",
    "    return runner_state, (transitions, timestep)\n",
    "\n",
    "\n",
    "def get_mask_from_transitions(\n",
    "    data: Transition,\n",
    ") -> jnp.ndarray:\n",
    "    is_done = jnp.clip(jnp.cumsum(data.global_done, axis=1), 0, 1)\n",
    "    mask = jnp.roll(is_done, 1, axis=1)\n",
    "    mask = mask.at[:, 0].set(0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d817b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_function(\n",
    "    policy_params: Genotype,\n",
    "    key: RNGKey,\n",
    "    episode_length: int,\n",
    "    play_reset_fn: Callable[[RNGKey], EnvState],\n",
    "    play_step_fn: Callable[\n",
    "        [EnvState, Params, RNGKey], Tuple[EnvState, Params, RNGKey, QDTransition]\n",
    "    ],\n",
    "    descriptor_extractor: Callable[[QDTransition, jnp.ndarray], Descriptor],\n",
    ") -> Tuple[Fitness, Descriptor, ExtraScores]:\n",
    "    \"\"\"Evaluates policies contained in policies_params in parallel.\n",
    "    The play_reset_fn function allows for a more general scoring_function that can be\n",
    "    called with different batch-size and not only with a batch-size of the same\n",
    "    dimension as init_states.\n",
    "\n",
    "    To define purely stochastic environments, using the reset function from the\n",
    "    environment, use \"play_reset_fn = env.reset\".\n",
    "\n",
    "    To define purely deterministic environments, as in \"scoring_function\", generate\n",
    "    a single init_state using \"init_state = env.reset(key)\", then use\n",
    "    \"play_reset_fn = lambda key: init_state\".\n",
    "\n",
    "    Args:\n",
    "        policies_params: The parameters of closed-loop controllers/policies to evaluate.\n",
    "        key: A jax random key\n",
    "        episode_length: The maximal rollout length.\n",
    "        play_reset_fn: The function to reset the environment and obtain initial states.\n",
    "        play_step_fn: The function to play a step of the environment.\n",
    "        descriptor_extractor: The function to extract the descriptor.\n",
    "\n",
    "    Returns:\n",
    "        fitness: Array of fitnesses of all evaluated policies\n",
    "        descriptor: Behavioural descriptors of all evaluated policies\n",
    "        extra_scores: Additional information resulting from the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Reset environments\n",
    "    key, subkey = jax.random.split(key)\n",
    "    #keys = jax.random.split(subkey, jax.tree.leaves(policies_params)[0].shape[0])\n",
    "    #keys = jax.random.split(subkey, config[\"NUM_ENVS\"])\n",
    "    #init_obs, init_env_state = jax.vmap(play_reset_fn, in_axes=(0,))(keys)\n",
    "    init_obs, init_env_state = play_reset_fn(key)\n",
    "    #print(\"init_obs is a dict with keys:\", init_obs.keys())\n",
    "    #for k, v in init_obs.items():\n",
    "    #    print(f\"init_obs[{k}] shape:\", v.shape) \n",
    "    \n",
    "    keys = jax.random.split(subkey, batch_size)\n",
    "\n",
    "    #init_dones = {\n",
    "    #    agent: jnp.zeros((config[\"NUM_ENVS\"]), dtype=bool)\n",
    "    #    for agent in env.agents + [\"__all__\"]\n",
    "    #}\n",
    "    init_hstate = ScannedRNN.initialize_carry(\n",
    "        config[\"HIDDEN_SIZE\"], len(env.agents), config[\"NUM_ENVS\"]\n",
    "    )\n",
    "    \n",
    "    batched_env_state = jax.tree.map(lambda x: jnp.stack([x] * batch_size), init_env_state)\n",
    "    batched_obs = jax.tree.map(lambda x: jnp.stack([x] * batch_size), init_obs)\n",
    "    batched_dones = {\n",
    "        agent: jnp.stack([jnp.zeros(config[\"NUM_ENVS\"], dtype=bool)] * batch_size)\n",
    "        for agent in env.agents + [\"__all__\"]\n",
    "    }\n",
    "    batched_hstate = jnp.stack([init_hstate] * batch_size)\n",
    "\n",
    "    #print(\"batched_obs is a dict with keys:\", batched_obs.keys())\n",
    "    #for k, v in batched_obs.items():\n",
    "    #    print(f\"batched_obs[{k}] shape:\", v.shape) \n",
    "\n",
    "    init_runner_state = (policy_params, batched_env_state, batched_obs, batched_dones, batched_hstate, keys)\n",
    "    #print(\"init_runner_state:\")\n",
    "    #jax.tree.map(lambda x: print(x.shape), init_runner_state)\n",
    "    \n",
    "    # Step environments\n",
    "    unroll_fn = functools.partial(\n",
    "        generate_unroll,\n",
    "        episode_length=episode_length,\n",
    "        play_step_fn=play_step_fn,\n",
    "    )\n",
    "    #keys = jax.random.split(key, jax.tree.leaves(policies_params)[0].shape[0])\n",
    "    _, (data, timestep) = jax.vmap(unroll_fn)(init_runner_state) # data = Transistions data struc\n",
    "    #jax.debug.print(\"after vmap timestep shape: {}\", \n",
    "    #jax.tree.map(lambda x: x.shape, timestep))\n",
    "\n",
    "    # Create a mask to extract data properly\n",
    "    #mask = get_mask_from_transitions(data)\n",
    "    mask = data.infos[\"returned_episode\"]\n",
    "\n",
    "    # Evaluate\n",
    "    #print(\"data.reward shape:\", data.reward.shape)\n",
    "    #print(\"data.global_done shape:\", data.global_done.shape)\n",
    "    #print(\"mask shape:\", mask.shape)\n",
    "    \n",
    "    #print(type(data.infos[\"returned_episode_returns\"]))\n",
    "    #print(data.infos[\"returned_episode_returns\"].shape)\n",
    "\n",
    "    # Shape: (num_offspring, episode_len, num_envs, 1)\n",
    "    returns = data.infos[\"returned_episode_returns\"][..., 0]  # (batch_size, episode_length, num_envs)\n",
    "    #print(\"returns shape\", returns.shape)\n",
    "\n",
    "    # Take the max over time to extract the one non-zero final return per env\n",
    "    final_returns = jnp.max(returns, axis=1)  # (batch_size, num_envs)\n",
    "    #print(\"final returns shape\", final_returns.shape)\n",
    "\n",
    "    # Average over the environments per offspring\n",
    "    mean_return = jnp.mean(final_returns, axis=1, keepdims=True)  # shape: (batch_size, 1)\n",
    "    var_return = jnp.var(final_returns, axis=1, keepdims=True)\n",
    "\n",
    "    # === Ally survival reward ===\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)  # (B, T, E, A)\n",
    "    teams = data.env_state.unit_teams                      # (B, T, E, A)\n",
    "    is_ally = (teams == 0).astype(jnp.float32)              # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                            # (B, T, E, A)\n",
    "    #print(\"ally_alive shape:\", ally_alive.shape)\n",
    "\n",
    "    # Final timestep allies alive\n",
    "    final_ally_alive = ally_alive[:, -1, :, :]              # (B, E, A)\n",
    "    #print(\"final_ally_alive shape:\", final_ally_alive.shape)\n",
    "    total_alive_allies = jnp.sum(final_ally_alive, axis=(1, 2))  # (B,)\n",
    "    #print(\"total_alive_allies shape:\", total_alive_allies.shape)\n",
    "\n",
    "    # Total possible allies\n",
    "    total_possible_allies = jnp.sum(is_ally[:, 0, :, :], axis=(1, 2))  # (B,)\n",
    "    #print(\"total_possible_allies shape:\", total_possible_allies.shape)\n",
    "    ally_alive_reward = (total_alive_allies / total_possible_allies)[:, None]  # (B, 1)   \n",
    "    #print(\"ally_alive_reward shape:\", ally_alive_reward.shape)\n",
    "\n",
    "    # === Final fitness ===\n",
    "    fitnesses = (mean_return - var_return) + ally_alive_reward # (B, 1)\n",
    "\n",
    "    descriptors = descriptor_extractor(data, mask)\n",
    "\n",
    "    #print(\"fitness shape:\", fitnesses.shape)\n",
    "    #print(\"descriptors shape:\", descriptors.shape)\n",
    "\n",
    "    return fitnesses, descriptors, {\"transitions\": timestep}#data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b647f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_descriptors(data):\\n    \"\"\"\\n    Compute per-trajectory descriptors:\\n    - % of actions that were movement actions over the whole episode (per batch item)\\n    - % of actions that were attack actions over the whole episode (per batch item)\\n    - Avg ally-ally distance averaged over all steps (per batch item)\\n\\n    Output: shape (batch_size, 3)\\n    \"\"\"\\n    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\\n    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\\n    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\\n    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\\n    teams = data.env_state.unit_teams                                # (B, T, E, A)\\n\\n    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\\n    ally_alive = alive * is_ally                                     # (B, T, E, A)\\n\\n    # Movement mask: True where movement_actions != 0 on either coordinate\\n    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\\n    moved = moved * ally_alive                                       # only alive allies\\n\\n    # Attack mask: True where attack_actions > 0\\n    attacked = (attack_actions > 0).astype(jnp.float32)              # (B, T, E, A)\\n    attacked = attacked * ally_alive                                 # only alive allies\\n\\n    # Total number of movement and attack actions per batch\\n    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\\n    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\\n\\n    # Total actions = moves + attacks\\n    total_actions = num_move_actions + num_attack_actions + 1e-8\\n\\n    # Movement and attack percent over whole episode\\n    movement_pct = num_move_actions / total_actions\\n    attack_pct = num_attack_actions / total_actions\\n\\n    # Pairwise distance function (same as before)\\n    def avg_pairwise_distance(pos, mask):\\n        \"\"\"\\n        pos: (A, 2)\\n        mask: (A,)\\n        returns: scalar distance\\n        \"\"\"\\n        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\\n        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\\n        pair_mask = mask[:, None] * mask[None, :]      # (A, A)\\n        not_self = 1 - jnp.eye(mask.shape[0])\\n        valid_pairs = pair_mask * not_self\\n        total_dist = jnp.sum(dists * valid_pairs)\\n        num_pairs = jnp.sum(valid_pairs)\\n        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\\n\\n    # Compute avg distances over *all* time steps\\n    ally_mask_full = (teams == 0) * alive  # (B, T, E, A)\\n\\n    # vmap over batch, time, env\\n    # Output: (B, T, E)\\n    all_step_dists = jax.vmap(\\n        jax.vmap(\\n            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),  # over envs\\n            in_axes=(0, 0)  # over time\\n        ),\\n        in_axes=(0, 0)  # over batch\\n    )(positions, ally_mask_full)\\n\\n    # Average over envs, then over time steps  (B,)\\n    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\\n\\n    # Normalize and clip\\n    max_distance = 32\\n    quarter_max = 0.25 * max_distance \\n    norm_dist = avg_dists_over_time / quarter_max\\n    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\\n\\n    # Stack all descriptors  shape (B, 3)\\n    #return jnp.stack([movement_pct, attack_pct, norm_dist], axis=-1)\\n    return jnp.stack([movement_pct, norm_dist], axis=-1)\\n\\n\\ndef descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\\n    \"\"\"Compute final xy position.\\n\\n    This function suppose that state descriptor is the xy position, as it\\n    just select the final one of the state descriptors given.\\n    \"\"\"\\n    # reshape mask for descriptor extraction\\n    mask = jnp.expand_dims(mask, axis=-1)\\n\\n    # Get descriptor\\n    #last_index = jnp.int32(jnp.sum(1.0 - mask, axis=1)) - 1\\n    #descriptors = jax.vmap(lambda x, y: x[y])(data.state_desc, last_index)\\n    descriptors = compute_descriptors(data)\\n\\n    # remove the dim coming from the trajectory\\n    return descriptors#.squeeze(axis=1)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def compute_descriptors(data):\n",
    "    \"\"\"\n",
    "    Compute per-trajectory descriptors:\n",
    "    - % of actions that were movement actions over the whole episode (per batch item)\n",
    "    - % of actions that were attack actions over the whole episode (per batch item)\n",
    "    - Avg ally-ally distance averaged over all steps (per batch item)\n",
    "    \n",
    "    Output: shape (batch_size, 3)\n",
    "    \"\"\"\n",
    "    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\n",
    "    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\n",
    "    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\n",
    "    teams = data.env_state.unit_teams                                # (B, T, E, A)\n",
    "\n",
    "    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                                     # (B, T, E, A)\n",
    "\n",
    "    # Movement mask: True where movement_actions != 0 on either coordinate\n",
    "    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\n",
    "    moved = moved * ally_alive                                       # only alive allies\n",
    "\n",
    "    # Attack mask: True where attack_actions > 0\n",
    "    attacked = (attack_actions > 0).astype(jnp.float32)              # (B, T, E, A)\n",
    "    attacked = attacked * ally_alive                                 # only alive allies\n",
    "\n",
    "    # Total number of movement and attack actions per batch\n",
    "    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\n",
    "    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\n",
    "\n",
    "    # Total actions = moves + attacks\n",
    "    total_actions = num_move_actions + num_attack_actions + 1e-8\n",
    "\n",
    "    # Movement and attack percent over whole episode\n",
    "    movement_pct = num_move_actions / total_actions\n",
    "    attack_pct = num_attack_actions / total_actions\n",
    "\n",
    "    # Pairwise distance function (same as before)\n",
    "    def avg_pairwise_distance(pos, mask):\n",
    "        \"\"\"\n",
    "        pos: (A, 2)\n",
    "        mask: (A,)\n",
    "        returns: scalar distance\n",
    "        \"\"\"\n",
    "        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\n",
    "        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\n",
    "        pair_mask = mask[:, None] * mask[None, :]      # (A, A)\n",
    "        not_self = 1 - jnp.eye(mask.shape[0])\n",
    "        valid_pairs = pair_mask * not_self\n",
    "        total_dist = jnp.sum(dists * valid_pairs)\n",
    "        num_pairs = jnp.sum(valid_pairs)\n",
    "        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\n",
    "\n",
    "    # Compute avg distances over *all* time steps\n",
    "    ally_mask_full = (teams == 0) * alive  # (B, T, E, A)\n",
    "\n",
    "    # vmap over batch, time, env\n",
    "    # Output: (B, T, E)\n",
    "    all_step_dists = jax.vmap(\n",
    "        jax.vmap(\n",
    "            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),  # over envs\n",
    "            in_axes=(0, 0)  # over time\n",
    "        ),\n",
    "        in_axes=(0, 0)  # over batch\n",
    "    )(positions, ally_mask_full)\n",
    "\n",
    "    # Average over envs, then over time steps  (B,)\n",
    "    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\n",
    "\n",
    "    # Normalize and clip\n",
    "    max_distance = 32\n",
    "    quarter_max = 0.25 * max_distance \n",
    "    norm_dist = avg_dists_over_time / quarter_max\n",
    "    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\n",
    "\n",
    "    # Stack all descriptors  shape (B, 3)\n",
    "    #return jnp.stack([movement_pct, attack_pct, norm_dist], axis=-1)\n",
    "    return jnp.stack([movement_pct, norm_dist], axis=-1)\n",
    "\n",
    "\n",
    "def descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\n",
    "    \"\"\"Compute final xy position.\n",
    "\n",
    "    This function suppose that state descriptor is the xy position, as it\n",
    "    just select the final one of the state descriptors given.\n",
    "    \"\"\"\n",
    "    # reshape mask for descriptor extraction\n",
    "    mask = jnp.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Get descriptor\n",
    "    #last_index = jnp.int32(jnp.sum(1.0 - mask, axis=1)) - 1\n",
    "    #descriptors = jax.vmap(lambda x, y: x[y])(data.state_desc, last_index)\n",
    "    descriptors = compute_descriptors(data)\n",
    "\n",
    "    # remove the dim coming from the trajectory\n",
    "    return descriptors#.squeeze(axis=1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa23523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_descriptors(data, full_mask):\n",
    "    \"\"\"\n",
    "    Compute per-trajectory descriptors:\n",
    "    - % of actions that were movement actions over the whole episode (per batch item)\n",
    "    - Avg ally-ally distance averaged over all steps (per batch item)\n",
    "\n",
    "    Output: shape (batch_size, 2)\n",
    "    \"\"\"\n",
    "    movement_actions = data.env_state.prev_movement_actions          # (B, T, E, A, 2)\n",
    "    attack_actions = data.env_state.prev_attack_actions              # (B, T, E, A)\n",
    "    alive = data.env_state.unit_alive.astype(jnp.float32)            # (B, T, E, A)\n",
    "    positions = data.env_state.unit_positions                        # (B, T, E, A, 2)\n",
    "    teams = data.env_state.unit_teams                                # (B, T, E, A)\n",
    "\n",
    "    is_ally = (teams == 0).astype(jnp.float32)                       # (B, T, E, A)\n",
    "    ally_alive = alive * is_ally                                     # (B, T, E, A)\n",
    "\n",
    "    # === Apply mask: ignore masked steps ===\n",
    "    full_mask = jnp.asarray(full_mask)\n",
    "    full_mask = 1.0 - full_mask  # Mask where 1 means usable data\n",
    "    ally_alive = ally_alive * full_mask\n",
    "\n",
    "    # Movement mask\n",
    "    moved = jnp.any(movement_actions != 0.0, axis=-1)                # (B, T, E, A)\n",
    "    moved = moved * ally_alive\n",
    "\n",
    "    # Attack mask\n",
    "    attacked = (attack_actions > 0).astype(jnp.float32)\n",
    "    attacked = attacked * ally_alive\n",
    "\n",
    "    num_move_actions = jnp.sum(moved, axis=(1, 2, 3))                # (B,)\n",
    "    num_attack_actions = jnp.sum(attacked, axis=(1, 2, 3))           # (B,)\n",
    "    total_actions = num_move_actions + num_attack_actions + 1e-8\n",
    "\n",
    "    movement_pct = num_move_actions / total_actions\n",
    "\n",
    "    # === Distance computation ===\n",
    "    def avg_pairwise_distance(pos, mask):\n",
    "        diffs = pos[:, None, :] - pos[None, :, :]      # (A, A, 2)\n",
    "        dists = jnp.linalg.norm(diffs, axis=-1)        # (A, A)\n",
    "        pair_mask = mask[:, None] * mask[None, :]\n",
    "        not_self = 1 - jnp.eye(mask.shape[0])\n",
    "        valid_pairs = pair_mask * not_self\n",
    "        total_dist = jnp.sum(dists * valid_pairs)\n",
    "        num_pairs = jnp.sum(valid_pairs)\n",
    "        return jnp.where(num_pairs > 0, total_dist / num_pairs, 0.0)\n",
    "\n",
    "    ally_mask_full = is_ally * alive * full_mask       # shape (B, T, E, A)\n",
    "\n",
    "    # (B, T, E)\n",
    "    all_step_dists = jax.vmap(\n",
    "        jax.vmap(\n",
    "            jax.vmap(avg_pairwise_distance, in_axes=(0, 0)),\n",
    "            in_axes=(0, 0)\n",
    "        ),\n",
    "        in_axes=(0, 0)\n",
    "    )(positions, ally_mask_full)\n",
    "\n",
    "    avg_dists_over_time = jnp.mean(all_step_dists, axis=(1, 2))\n",
    "\n",
    "    max_distance = 32\n",
    "    quarter_max = 0.25 * max_distance\n",
    "    norm_dist = avg_dists_over_time / quarter_max\n",
    "    norm_dist = jnp.clip(norm_dist, 0.0, 1.0)\n",
    "\n",
    "    return jnp.stack([movement_pct, norm_dist], axis=-1)  # shape (B, 2)\n",
    "\n",
    "def descriptor_extraction_fn(data: Transition, mask: jnp.ndarray) -> Descriptor:\n",
    "    \"\"\"Compute trajectory descriptors, with mask expanded to match env_state agent dim.\"\"\"\n",
    "\n",
    "    B, T, E, A_total = data.env_state.unit_alive.shape\n",
    "    A_ally = mask.shape[-1]\n",
    "\n",
    "    # Expand to match shape of alive/env_state: assume allies are first\n",
    "    full_mask = jnp.zeros((B, T, E, A_total))\n",
    "    full_mask = full_mask.at[..., :A_ally].set(mask)\n",
    "\n",
    "    # Call descriptor computation with full mask\n",
    "    descriptors = compute_descriptors(data, full_mask)\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "682e6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qmix_loss_fn(\n",
    "        policy_fn: Callable[[Params, Observation], jnp.ndarray],\n",
    "        reward_scaling: float,\n",
    "        discount: float,\n",
    ") -> Callable[[Params, Transition], jnp.ndarray]:\n",
    "    \"\"\"Creates the loss functions for IQL.\n",
    "\n",
    "    Args:\n",
    "        policy_fn: forward pass through the neural network defining the policy.\n",
    "        reward_scaling: value to multiply the reward given by the environment.\n",
    "        discount: discount factor.\n",
    "\n",
    "    Returns:\n",
    "        Return the loss functions used to train the policy.\n",
    "    \"\"\"\n",
    "    def _policy_loss_fn(\n",
    "        policy_params: Params,\n",
    "        target_policy_params: Params,\n",
    "        minibatch: Transition,\n",
    "        #emitter_state: CustomQualityPGEmitterState,\n",
    "    ) -> jnp.ndarray:\n",
    "        #minibatch = emitter_state.buffer.sample(emitter_state.buffer_state, emitter_state.key).experience\n",
    "\n",
    "        minibatch = jax.tree.map(\n",
    "            lambda x: jnp.swapaxes(\n",
    "                x[:, 0], 0, 1\n",
    "            ),  # remove the dummy sequence dim (1) and swap batch and temporal dims\n",
    "            minibatch,\n",
    "        )  # (max_time_steps, batch_size, ...)\n",
    "\n",
    "        # preprocess network input\n",
    "        init_hs = ScannedRNN.initialize_carry(\n",
    "            config[\"HIDDEN_SIZE\"],\n",
    "            len(env.agents),\n",
    "            config[\"BUFFER_BATCH_SIZE\"],\n",
    "        )\n",
    "        # num_agents, timesteps, batch_size, ...\n",
    "        _obs = batchify(minibatch.obs)\n",
    "        _dones = batchify(minibatch.dones)\n",
    "        _actions = batchify(minibatch.actions)\n",
    "        _rewards = batchify(minibatch.rewards)\n",
    "        _avail_actions = batchify(minibatch.avail_actions)\n",
    "        ###################################################################################################\n",
    "        #print(\"init_hs.shape\", init_hs.shape)\n",
    "        #print(\"_obs.shape\", _obs.shape)\n",
    "        #print(\"_does.shape\", _dones.shape)\n",
    "        #print(\"init_hs.shape\", init_hs.shape)\n",
    "        ###################################################################################################\n",
    "        _, q_next_target = jax.vmap(policy_fn, in_axes=(None, 0, 0, 0))(\n",
    "            target_policy_params['agent'], #train_state.target_network_params,\n",
    "            init_hs,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )  # (num_agents, timesteps, batch_size, num_actions)\n",
    "\n",
    "        _, q_vals = jax.vmap(policy_fn, in_axes=(None, 0, 0, 0))(\n",
    "            policy_params['agent'],\n",
    "            init_hs,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )  # (num_agents, timesteps, batch_size, num_actions)\n",
    "\n",
    "        # get logits of the chosen actions\n",
    "        chosen_action_q_vals = jnp.take_along_axis(\n",
    "            q_vals,\n",
    "            _actions[..., np.newaxis],\n",
    "            axis=-1,\n",
    "        ).squeeze(-1)  # (num_agents, timesteps, batch_size,)\n",
    "\n",
    "        unavailable_actions = 1 - _avail_actions\n",
    "        valid_q_vals = q_vals - (unavailable_actions * 1e10)\n",
    "\n",
    "        # get the q values of the next state\n",
    "        q_next = jnp.take_along_axis(\n",
    "            q_next_target,\n",
    "            jnp.argmax(valid_q_vals, axis=-1)[..., np.newaxis],\n",
    "            axis=-1,\n",
    "        ).squeeze(-1)  # (num_agents, timesteps, batch_size,)\n",
    "\n",
    "        qmix_next = mixer.apply(target_policy_params['mixer'], q_next, minibatch.obs[\"__all__\"])\n",
    "        qmix_target = (\n",
    "            minibatch.rewards[\"__all__\"][:-1]\n",
    "            + (\n",
    "                1 - minibatch.dones[\"__all__\"][:-1]\n",
    "            )  # use next done because last done was saved for rnn re-init\n",
    "            * config[\"GAMMA\"]\n",
    "            * qmix_next[1:]  # sum over agents\n",
    "        )\n",
    "\n",
    "        qmix = mixer.apply(policy_params['mixer'], chosen_action_q_vals, minibatch.obs[\"__all__\"])[:-1]\n",
    "        loss = jnp.mean(\n",
    "            (qmix - jax.lax.stop_gradient(qmix_target)) ** 2\n",
    "        )\n",
    "\n",
    "        #return loss, chosen_action_q_vals.mean()\n",
    "        return loss\n",
    "    \n",
    "    return _policy_loss_fn\n",
    "\n",
    "#class CustomQualityPGEmitterState(QualityPGEmitterState):\n",
    "    #target_network_params: Any\n",
    "#    buffer_state: Any\n",
    "\n",
    "@chex.dataclass(frozen=True)\n",
    "class CustomQualityPGEmitterState:\n",
    "    #target_network_params: Any\n",
    "    buffer_state: Any\n",
    "    #replay_buffer: Any = struct.field(pytree_node=False)  # Static Python object\n",
    "    key: RNGKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf22424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myQualityPGEmitter(Emitter):\n",
    "    \"\"\"\n",
    "    A policy gradient emitter used to implement the Policy Gradient Assisted MAP-Elites\n",
    "    (PGA-Map-Elites) algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: QualityPGConfig,\n",
    "        policy_network: nn.Module,\n",
    "        env: QDEnv,\n",
    "        selector: Optional[Selector] = None,\n",
    "    ) -> None:\n",
    "        self._config = config\n",
    "        self._env = env\n",
    "        self._selector = selector\n",
    "        self._actor_critic_iterations = int(\n",
    "            config.num_critic_training_steps / config.policy_delay\n",
    "        )  # actor and critic training are packed into a single function\n",
    "\n",
    "        # Init Critics\n",
    "        #critic_network = QModule(\n",
    "        #    n_critics=2, hidden_layer_sizes=self._config.critic_hidden_layer_size\n",
    "        #)\n",
    "        #critic_network = CriticRNN(action_dim=env.action_space(env.agents[0]).n, config=config, n_critics=2)\n",
    "        #target_q_network = RNNQNetwork(\n",
    "        #    action_dim=wrapped_env.max_action_space,\n",
    "        #    hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "        #)\n",
    "        \n",
    "        #self._critic_network = target_q_network #critic_network\n",
    "\n",
    "        # Set up the losses and optimizers - return the opt states\n",
    "        self._policy_loss_fn = make_qmix_loss_fn( #make_td3_loss_fn(\n",
    "            policy_fn=policy_network.apply,\n",
    "            #critic_fn=critic_network.apply,\n",
    "            reward_scaling=self._config.reward_scaling,\n",
    "            discount=self._config.discount,\n",
    "            #noise_clip=self._config.noise_clip,\n",
    "            #policy_noise=self._config.policy_noise,\n",
    "        )\n",
    "\n",
    "        # Init optimizers\n",
    "        #self._actor_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.actor_learning_rate\n",
    "        #)\n",
    "        #self._critic_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.critic_learning_rate\n",
    "        #)\n",
    "        #self._policies_optimizer = optax.adam(\n",
    "        #    learning_rate=self._config.policy_learning_rate\n",
    "        #)\n",
    "        \n",
    "        #lr_scheduler = optax.linear_schedule(\n",
    "        #    init_value=config[\"LR\"],\n",
    "        #    end_value=1e-10,\n",
    "        #    transition_steps=(config[\"NUM_EPOCHS\"]) * config[\"NUM_UPDATES\"],\n",
    "        #)\n",
    "        #lr = lr_scheduler if config.get(\"LR_LINEAR_DECAY\", False) else config[\"LR\"]\n",
    "        #tx = optax.chain(\n",
    "        #    optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "        #    optax.radam(learning_rate=lr),\n",
    "        #)\n",
    "        #self._policies_optimizer = tx\n",
    "\n",
    "        buffer = fbx.make_trajectory_buffer(\n",
    "            max_length_time_axis=self._config.replay_buffer_size // (self._config.num_envs * batch_size), #batch_size,\n",
    "            min_length_time_axis=self._config.batch_size,\n",
    "            sample_batch_size=self._config.batch_size,\n",
    "            add_batch_size=self._config.num_envs * batch_size, # batch_size different to self._config.batch_size and is accessed globally\n",
    "            sample_sequence_length=1,\n",
    "            period=1,\n",
    "        )\n",
    "        self._buffer = buffer\n",
    "\n",
    "        # Init optimizers\n",
    "        self._policies_optimizer = optax.adam(\n",
    "            learning_rate=self._config.policy_learning_rate\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def batch_size(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            the batch size emitted by the emitter.\n",
    "        \"\"\"\n",
    "        return self._config.env_batch_size\n",
    "\n",
    "    @property\n",
    "    def use_all_data(self) -> bool:\n",
    "        \"\"\"Whether to use all data or not when used along other emitters.\n",
    "\n",
    "        QualityPGEmitter uses the transitions from the genotypes that were generated\n",
    "        by other emitters.\n",
    "        \"\"\"\n",
    "        return True\n",
    "\n",
    "    def init(\n",
    "        self,\n",
    "        key: RNGKey,\n",
    "        repertoire: Repertoire,\n",
    "        genotypes: Genotype,\n",
    "        fitnesses: Fitness,\n",
    "        descriptors: Descriptor,\n",
    "        extra_scores: ExtraScores,\n",
    "    ) -> CustomQualityPGEmitterState:\n",
    "        \"\"\"Initializes the emitter state.\n",
    "\n",
    "        Args:\n",
    "            genotypes: The initial population.\n",
    "            key: A random key.\n",
    "\n",
    "        Returns:\n",
    "            The initial state of the PGAMEEmitter.\n",
    "        \"\"\"\n",
    "        '''\n",
    "        #observation_size = self._env.observation_size\n",
    "        #action_size = self._env.action_size\n",
    "        #descriptor_size = self._env.state_descriptor_length\n",
    "\n",
    "        obs_space = self._env.observation_space(env.agents[0])#.shape[0]\n",
    "        action_space = self._env.action_space(env.agents[0])#.shape[0]\n",
    "\n",
    "        observation_size = int(np.prod(obs_space.shape))\n",
    "        action_size = int(np.prod(action_space.shape))\n",
    "        descriptor_size = 2 # hardcoded\n",
    "\n",
    "        # Initialise critic, greedy actor and population\n",
    "        #key, subkey = jax.random.split(key)\n",
    "        #fake_obs = jnp.zeros(shape=(observation_size,))\n",
    "        #fake_action = jnp.zeros(shape=(action_size,))\n",
    "        #critic_params = self._critic_network.init(\n",
    "        #    subkey, obs=fake_obs, actions=fake_action\n",
    "        #)\n",
    "\n",
    "        #init_hstate = ScannedRNN.initialize_carry(1, config[\"GRU_HIDDEN_DIM\"])\n",
    "        key, subkey = jax.random.split(key)\n",
    "        #fake_hstate = jnp.stack([init_hstate] * 1) \n",
    "        #fake_obs = tuple(jnp.stack([x] * batch_size) for x in init_x)\n",
    "        #fake_action = jnp.zeros(shape=(action_size,))\n",
    "        #critic_params = self._critic_network.init(subkey, fake_hstate, fake_obs, fake_action)\n",
    "\n",
    "        fake_x = (\n",
    "            jnp.zeros(\n",
    "                (1, config[\"NUM_ENVS\"], env.observation_space(env.agents[0]).shape[0])\n",
    "            ),\n",
    "            jnp.zeros((1, config[\"NUM_ENVS\"])),\n",
    "            jnp.zeros((1, config[\"NUM_ENVS\"], env.action_space(env.agents[0]).n)),\n",
    "        )\n",
    "        fake_hstate = ScannedRNN.initialize_carry(config[\"NUM_ENVS\"], config[\"GRU_HIDDEN_DIM\"])\n",
    "        fake_action = jnp.zeros(shape=(action_size,))\n",
    "        critic_params = self._critic_network.init(subkey, fake_hstate, fake_x, fake_action)\n",
    "\n",
    "        #target_critic_params = jax.tree.map(lambda x: x, critic_params)\n",
    "\n",
    "        #actor_params = jax.tree.map(lambda x: x[0], genotypes)\n",
    "        #target_actor_params = jax.tree.map(lambda x: x[0], genotypes)\n",
    "\n",
    "        # Prepare init optimizer states\n",
    "        #critic_optimizer_state = self._critic_optimizer.init(critic_params)\n",
    "        #actor_optimizer_state = self._actor_optimizer.init(actor_params)\n",
    "\n",
    "        # Initialize replay buffer\n",
    "        dummy_transition = QDTransition.init_dummy(\n",
    "            observation_dim=observation_size,\n",
    "            action_dim=action_size,\n",
    "            descriptor_dim=descriptor_size,\n",
    "        )\n",
    "\n",
    "        replay_buffer = ReplayBuffer.init(\n",
    "            buffer_size=self._config.replay_buffer_size, transition=dummy_transition\n",
    "        )\n",
    "\n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        #print(\"Transitions type:\", type(transitions))\n",
    "        #print(\"Transitions fields:\", transitions)\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        replay_buffer = replay_buffer.insert(transitions)\n",
    "\n",
    "        '''\n",
    "\n",
    "        ###########################################################################################################################################\n",
    "        '''\n",
    "        init_x = (\n",
    "            jnp.zeros(\n",
    "                (1, 1, wrapped_env.obs_size)\n",
    "            ),  # (time_step, batch_size, obs_size)\n",
    "            jnp.zeros((1, 1)),  # (time_step, batch size)\n",
    "        )\n",
    "        init_hs = ScannedRNN.initialize_carry(\n",
    "            config[\"HIDDEN_SIZE\"], 1\n",
    "        )  # (batch_size, hidden_dim)\n",
    "        network_params = policy_network.init(rng, init_hs, *init_x)\n",
    "\n",
    "        lr_scheduler = optax.linear_schedule(\n",
    "            init_value=config[\"LR\"],\n",
    "            end_value=1e-10,\n",
    "            transition_steps=(config[\"NUM_EPOCHS\"]) * config[\"NUM_UPDATES\"],\n",
    "        )\n",
    "\n",
    "        lr = lr_scheduler if config.get(\"LR_LINEAR_DECAY\", False) else config[\"LR\"]\n",
    "\n",
    "        tx = optax.chain(\n",
    "            optax.clip_by_global_norm(config[\"MAX_GRAD_NORM\"]),\n",
    "            optax.radam(learning_rate=lr),\n",
    "        )\n",
    "\n",
    "        train_state = CustomTrainState.create(\n",
    "            apply_fn=policy_network.apply,\n",
    "            params=network_params,\n",
    "            target_network_params=network_params,\n",
    "            tx=tx,\n",
    "        )\n",
    "        '''\n",
    "        # INIT BUFFER\n",
    "        # to initalize the buffer is necessary to sample a trajectory to know its strucutre\n",
    "        def _env_sample_step(env_state, unused):\n",
    "            rng, key_a, key_s = jax.random.split(\n",
    "                jax.random.PRNGKey(0), 3\n",
    "            )  # use a dummy rng here\n",
    "            key_a = jax.random.split(key_a, env.num_agents)\n",
    "            actions = {\n",
    "                agent: self._env.batch_sample(key_a[i], agent)\n",
    "                for i, agent in enumerate(env.agents)\n",
    "            }\n",
    "            avail_actions = self._env.get_valid_actions(env_state.env_state)\n",
    "            obs, env_state, rewards, dones, infos = self._env.batch_step(\n",
    "                key_s, env_state, actions\n",
    "            )\n",
    "            timestep = Timestep(\n",
    "                obs=obs,\n",
    "                actions=actions,\n",
    "                rewards=rewards,\n",
    "                dones=dones,\n",
    "                avail_actions=avail_actions,\n",
    "            )\n",
    "            return env_state, timestep\n",
    "\n",
    "        _, _env_state = self._env.batch_reset(key)\n",
    "        _, sample_traj = jax.lax.scan(\n",
    "            _env_sample_step, _env_state, None, self._config.num_steps\n",
    "        )\n",
    "        sample_traj_unbatched = jax.tree.map(\n",
    "            lambda x: x[:, 0], sample_traj\n",
    "        )  # remove the NUM_ENV dim\n",
    "        \n",
    "        # Remove time dimension\n",
    "        sample_traj_unbatched = jax.tree.map(lambda x: x[:, 0], sample_traj)  # (16, )\n",
    "        # Tile across parallel_policies(batch_size) to match real add_batch_size\n",
    "        #sample_traj_unbatched = jax.tree.map(\n",
    "        #    lambda x: jnp.repeat(x, batch_size, axis=0),\n",
    "        #    sample_traj_unbatched\n",
    "        #)  # now (128, )\n",
    "        \n",
    "        #print(\"Init sample_traj shape:\", jax.tree.map(lambda x: x.shape, sample_traj_unbatched))\n",
    "        buffer_state = self._buffer.init(sample_traj_unbatched)\n",
    "        \n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        #replay_buffer = replay_buffer.insert(transitions)\n",
    "        # BUFFER UPDATE\n",
    "        #print(\"Transitions keys:\", transitions.keys())\n",
    "        #for k, v in transitions.items():\n",
    "        #    print(k, v.shape, v.dtype)\n",
    "        \n",
    "        #jax.tree.map(lambda x: print(x.shape), transitions)\n",
    "        #jax.tree.map(lambda x: print(\"Buffer expects:\", x.shape), buffer_state.experience)\n",
    "        \n",
    "        def prepare_for_buffer(x):\n",
    "            # x: (P, T, E, *feat_dims)\n",
    "            P, T, E, *feat_dims = x.shape\n",
    "\n",
    "            # First move to (P, E, T, *feat_dims)\n",
    "            x = x.transpose(0, 2, 1, *range(3, x.ndim))\n",
    "\n",
    "            # Merge P * E into batch\n",
    "            x = x.reshape(P * E, T, *feat_dims)\n",
    "\n",
    "            # Add dummy seq_len=1 in the middle -> (batch, 1, T, feat_dim...)\n",
    "            x = x[:, np.newaxis, ...]\n",
    "\n",
    "            return x\n",
    "        \n",
    "        buffer_traj_batch = jax.tree.map(\n",
    "            prepare_for_buffer,\n",
    "            transitions\n",
    "        )\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(x, 0, 1)[\n",
    "        #        :, np.newaxis\n",
    "        #    ],  # put the batch dim first and add a dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)  # (num_envs, 1, time_steps, ...)\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(\n",
    "        #        # Reorder from (num_policies, time_steps, num_envs, )\n",
    "        #        #  (time_steps, num_policies, num_envs, )\n",
    "        #        x.transpose(1, 0, 2, *range(3, x.ndim))\n",
    "        #        # Merge num_policies * num_envs into one dimension\n",
    "        #        .reshape(x.shape[1], -1, *x.shape[3:]),\n",
    "        #        0, 1  # swap (time_steps, merged_envs, )  (merged_envs, time_steps, )\n",
    "        #    )[:, np.newaxis],  # add dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)\n",
    "        #print(\"Runtime sample_traj shape:\", jax.tree.map(lambda x: x.shape, buffer_traj_batch))\n",
    "\n",
    "        buffer_state = self._buffer.add(buffer_state, buffer_traj_batch)\n",
    "\n",
    "\n",
    "        # Initial training state\n",
    "        #emitter_state = QualityPGEmitterState(\n",
    "        #    critic_params=critic_params,\n",
    "        #    critic_optimizer_state=critic_optimizer_state,\n",
    "        #    actor_params=actor_params,\n",
    "        #    actor_opt_state=actor_optimizer_state,\n",
    "        #    target_critic_params=target_critic_params,\n",
    "        #    target_actor_params=target_actor_params,\n",
    "        #    replay_buffer=replay_buffer,\n",
    "        #    key=key,\n",
    "        #)\n",
    "\n",
    "        # Initial training state\n",
    "        emitter_state = CustomQualityPGEmitterState(\n",
    "            #critic_params=None, #critic_params,\n",
    "            #critic_optimizer_state=None, #critic_optimizer_state,\n",
    "            #actor_params=None, #actor_params,\n",
    "            #actor_opt_state=None, #actor_optimizer_state,\n",
    "            #target_critic_params=None, #target_critic_params,\n",
    "            #target_actor_params=None, #target_actor_params,\n",
    "            #replay_buffer=buffer,\n",
    "            buffer_state=buffer_state,\n",
    "            key=key,\n",
    "        )\n",
    "\n",
    "        return emitter_state\n",
    "\n",
    "    def emit(  # type: ignore\n",
    "        self,\n",
    "        repertoire: GARepertoire,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        key: RNGKey,\n",
    "    ) -> Tuple[Genotype, ExtraScores]:\n",
    "        \"\"\"Do a step of PG emission.\n",
    "\n",
    "        Args:\n",
    "            repertoire: the current repertoire of genotypes\n",
    "            emitter_state: the state of the emitter used\n",
    "            key: a random key\n",
    "\n",
    "        Returns:\n",
    "            A batch of offspring, a empty dict for signature.\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = self._config.env_batch_size\n",
    "\n",
    "        # sample parents\n",
    "        mutation_pg_batch_size = int(batch_size) #int(batch_size - 1)\n",
    "        parents = repertoire.select(\n",
    "            key, mutation_pg_batch_size, selector=self._selector\n",
    "        ).genotypes\n",
    "\n",
    "        # apply the pg mutation\n",
    "        offsprings_pg = self.emit_pg(emitter_state, parents)\n",
    "\n",
    "        # get the actor (greedy actor)\n",
    "        #offspring_actor = self.emit_actor(emitter_state)\n",
    "\n",
    "        # add dimension for concatenation\n",
    "        #offspring_actor = jax.tree.map(\n",
    "        #    lambda x: jnp.expand_dims(x, axis=0), offspring_actor\n",
    "        #)\n",
    "        # gather offspring\n",
    "        #genotypes = jax.tree.map(\n",
    "        #    lambda x, y: jnp.concatenate([x, y], axis=0),\n",
    "        #    offsprings_pg,\n",
    "        #    offspring_actor,\n",
    "        #)\n",
    "        genotypes = offsprings_pg\n",
    "\n",
    "        return genotypes, {}\n",
    "\n",
    "    def emit_pg(\n",
    "        self, emitter_state: CustomQualityPGEmitterState, parents: Genotype\n",
    "    ) -> Genotype:\n",
    "        \"\"\"Emit the offsprings generated through pg mutation.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: current emitter state, contains critic and\n",
    "                replay buffer.\n",
    "            parents: the parents selected to be applied gradients in order\n",
    "                to mutate towards better performance.\n",
    "\n",
    "        Returns:\n",
    "            A new set of offsprings.\n",
    "        \"\"\"\n",
    "\n",
    "        # create a batch of policy optimizer states\n",
    "        policy_opt_states = jax.vmap(self._policies_optimizer.init)(parents)\n",
    "\n",
    "        # prepare the batched policy update function with vmapping\n",
    "        batched_policy_update_fn = jax.vmap(\n",
    "            partial(self._update_policy, emitter_state=emitter_state), #critic_params=emitter_state.critic_params),\n",
    "            in_axes=(0, 0)#, None),\n",
    "        )\n",
    "\n",
    "        def scan_update_policies(\n",
    "            carry: Tuple[Params, optax.OptState, RNGKey],\n",
    "            _: None,\n",
    "        ) -> Tuple[Tuple[Params, optax.OptState, RNGKey], Any]:\n",
    "\n",
    "            # Unpack the carry\n",
    "            (policy_params, policy_opt_state, key) = carry\n",
    "            key, subkey = jax.random.split(key)\n",
    "\n",
    "            # sample a mini-batch of data from the replay-buffer\n",
    "            #transitions = emitter_state.replay_buffer.sample(\n",
    "            #    subkey, self._config.batch_size\n",
    "            #)\n",
    "\n",
    "            #transitions = emitter_state.replay_buffer.sample(emitter_state.buffer_state, key).experience\n",
    "            (\n",
    "                new_policy_params,\n",
    "                new_policy_opt_states,\n",
    "            ) = batched_policy_update_fn(policy_params, policy_opt_state)#transitions)\n",
    "            return (new_policy_params, new_policy_opt_states, key), ()\n",
    "\n",
    "        (\n",
    "            final_policy_params,\n",
    "            final_policy_opt_state,\n",
    "            final_key,\n",
    "        ), _ = jax.lax.scan(\n",
    "            scan_update_policies,\n",
    "            (parents, policy_opt_states, emitter_state.key),\n",
    "            length=self._config.num_pg_training_steps,\n",
    "        )\n",
    "\n",
    "        return final_policy_params\n",
    "\n",
    "    def emit_actor(self, emitter_state: CustomQualityPGEmitterState) -> Genotype:\n",
    "        \"\"\"Emit the greedy actor.\n",
    "\n",
    "        Simply needs to be retrieved from the emitter state.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: the current emitter state, it stores the\n",
    "                greedy actor.\n",
    "\n",
    "        Returns:\n",
    "            The parameters of the actor.\n",
    "        \"\"\"\n",
    "        return emitter_state.actor_params\n",
    "\n",
    "    def state_update(  # type: ignore\n",
    "        self,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        repertoire: Optional[Repertoire],\n",
    "        genotypes: Optional[Genotype],\n",
    "        fitnesses: Optional[Fitness],\n",
    "        descriptors: Optional[Descriptor],\n",
    "        extra_scores: ExtraScores,\n",
    "    ) -> CustomQualityPGEmitterState:\n",
    "        \"\"\"This function gives an opportunity to update the emitter state\n",
    "        after the genotypes have been scored.\n",
    "\n",
    "        Here it is used to fill the Replay Buffer with the transitions\n",
    "        from the scoring of the genotypes, and then the training of the\n",
    "        critic/actor happens. Hence the params of critic/actor are updated,\n",
    "        as well as their optimizer states.\n",
    "\n",
    "        Args:\n",
    "            emitter_state: current emitter state.\n",
    "            repertoire: the current genotypes repertoire\n",
    "            genotypes: unused here - but compulsory in the signature.\n",
    "            fitnesses: unused here - but compulsory in the signature.\n",
    "            descriptors: unused here - but compulsory in the signature.\n",
    "            extra_scores: extra information coming from the scoring function,\n",
    "                this contains the transitions added to the replay buffer.\n",
    "\n",
    "        Returns:\n",
    "            New emitter state where the replay buffer has been filled with\n",
    "            the new experienced transitions.\n",
    "        \"\"\"\n",
    "        # get the transitions out of the dictionary\n",
    "        assert \"transitions\" in extra_scores.keys(), \"Missing transitions or wrong key\"\n",
    "        transitions = extra_scores[\"transitions\"]\n",
    "\n",
    "        def prepare_for_buffer(x):\n",
    "            # x: (P, T, E, *feat_dims)\n",
    "            P, T, E, *feat_dims = x.shape\n",
    "\n",
    "            # First move to (P, E, T, *feat_dims)\n",
    "            x = x.transpose(0, 2, 1, *range(3, x.ndim))\n",
    "\n",
    "            # Merge P * E into batch\n",
    "            x = x.reshape(P * E, T, *feat_dims)\n",
    "\n",
    "            # Add dummy seq_len=1 in the middle -> (batch, 1, T, feat_dim...)\n",
    "            x = x[:, np.newaxis, ...]\n",
    "\n",
    "            return x\n",
    "        \n",
    "        buffer_traj_batch = jax.tree.map(\n",
    "            prepare_for_buffer,\n",
    "            transitions\n",
    "        )\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(x, 0, 1)[\n",
    "        #        :, np.newaxis\n",
    "        #    ],  # put the batch dim first and add a dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)  # (num_envs, 1, time_steps, ...)\n",
    "        #buffer_traj_batch = jax.tree.map(\n",
    "        #    lambda x: jnp.swapaxes(\n",
    "        #        # Reorder from (num_policies, time_steps, num_envs, )\n",
    "        #        #  (time_steps, num_policies, num_envs, )\n",
    "        #        x.transpose(1, 0, 2, *range(3, x.ndim))\n",
    "        #        # Merge num_policies * num_envs into one dimension\n",
    "        #        .reshape(x.shape[1], -1, *x.shape[3:]),\n",
    "        #        0, 1  # swap (time_steps, merged_envs, )  (merged_envs, time_steps, )\n",
    "        #    )[:, np.newaxis],  # add dummy sequence dim\n",
    "        #    transitions,\n",
    "        #)\n",
    "        new_buffer_state = self._buffer.add(emitter_state.buffer_state, buffer_traj_batch)\n",
    "        final_emitter_state = emitter_state.replace(buffer_state=new_buffer_state)\n",
    "\n",
    "        # add transitions in the replay buffer\n",
    "        #emitter_state = emitter_state.replace(\n",
    "        #    replay_buffer=emitter_state.replay_buffer.insert(transitions)\n",
    "        #)\n",
    "        \n",
    "        # Conduct Actor-Critic training\n",
    "        #final_emitter_state, _ = jax.lax.scan(\n",
    "        #    self._scan_actor_critic_training,\n",
    "        #    emitter_state,\n",
    "        #    length=self._actor_critic_iterations,\n",
    "        #)\n",
    "\n",
    "        return final_emitter_state  # type: ignore\n",
    "\n",
    "    def _update_policy(\n",
    "        self,\n",
    "        policy_params: Params,\n",
    "        policy_opt_state: optax.OptState,\n",
    "        #transitions: QDTransition,\n",
    "        emitter_state: CustomQualityPGEmitterState,\n",
    "        #critic_params: Params,\n",
    "    ) -> Tuple[optax.OptState, Params]:\n",
    "        \"\"\"\n",
    "        Perform one step of PG update on the off-spring policy.\n",
    "        This function is vmapped to mutate the entire batch of off-springs\n",
    "        in parallel.\n",
    "\n",
    "        Args:\n",
    "            policy_params: the parameters of the policy.\n",
    "            policy_opt_state: the optimiser state of the policy.\n",
    "            transitions: a mini-batch of transitions for gradient computation\n",
    "            critic_params: the parameters of the critic networks serving as\n",
    "                a differentiable target. This is fixed in each iteration.\n",
    "\n",
    "        Returns:\n",
    "            new_policy_params: new policy parameters\n",
    "            new_policy_opt_state: updated optimiser state\n",
    "        \"\"\"\n",
    "        new_target_params = policy_params\n",
    "\n",
    "        # SAMPLE minibatches for each grad update\n",
    "        key = emitter_state.key\n",
    "        minibatches_list = []\n",
    "\n",
    "        for _ in range(self._config.target_update_interval):\n",
    "            key, subkey = jax.random.split(key)\n",
    "            minibatch = self._buffer.sample(emitter_state.buffer_state, subkey).experience\n",
    "            minibatches_list.append(minibatch)\n",
    "\n",
    "        # Stack into [num_updates, ...] pytree\n",
    "        minibatches = jax.tree.map(lambda *xs: jnp.stack(xs), *minibatches_list)\n",
    "\n",
    "        # Update key back into emitter_state\n",
    "        emitter_state = emitter_state.replace(key=key)\n",
    "\n",
    "        def _apply_grad_update(carry, minibatch):\n",
    "            # Compute the policy gradient\n",
    "            policy_params, policy_opt_state = carry\n",
    "\n",
    "            policy_gradient = jax.grad(self._policy_loss_fn)(\n",
    "                policy_params,\n",
    "                #critic_params,\n",
    "                #transitions,\n",
    "                new_target_params,\n",
    "                #emitter_state\n",
    "                minibatch\n",
    "            )\n",
    "            # Apply the update on the policy\n",
    "            (\n",
    "                policy_updates,\n",
    "                new_policy_opt_state,\n",
    "            ) = self._policies_optimizer.update(policy_gradient, policy_opt_state)\n",
    "            new_policy_params = optax.apply_updates(policy_params, policy_updates)\n",
    "\n",
    "            return (new_policy_params, new_policy_opt_state), ()\n",
    "        \n",
    "        (new_policy_params, new_policy_opt_state), _ = jax.lax.scan(\n",
    "            _apply_grad_update, \n",
    "            (policy_params, policy_opt_state), \n",
    "            #length=config[\"TARGET_UPDATE_INTERVAL\"]\n",
    "            minibatches,\n",
    "            )\n",
    "        \n",
    "        new_target_params = optax.incremental_update(\n",
    "                        new_policy_params, #train_state.params,\n",
    "                        new_target_params, #train_state.target_network_params,\n",
    "                        self._config.tau,\n",
    "                    )\n",
    "\n",
    "        return new_target_params, new_policy_opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02557c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the scoring function\n",
    "# descriptor_extraction_fn = environments.descriptor_extractor[env_name] # Need to write my own function to extract descriptors\n",
    "scoring_fn = functools.partial(\n",
    "    scoring_function,\n",
    "    episode_length=episode_length,\n",
    "    play_reset_fn=reset_fn,\n",
    "    play_step_fn=play_step_fn,\n",
    "    descriptor_extractor=descriptor_extraction_fn,\n",
    ")\n",
    "\n",
    "# Get minimum reward value to make sure qd_score are positive\n",
    "#reward_offset = environments.reward_offset[env_name]\n",
    "\n",
    "# Define a metrics function\n",
    "metrics_function = functools.partial(\n",
    "    default_qd_metrics,\n",
    "    qd_offset=1#reward_offset * episode_length, # Used to ensure QD score is positive could set to 1 if not needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb38e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myPGAMEEmitter(MultiEmitter):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: PGAMEConfig,\n",
    "        policy_network: nn.Module,\n",
    "        env: QDEnv,\n",
    "        variation_fn: Callable[[Params, Params, RNGKey], Tuple[Params, RNGKey]],\n",
    "        selector: Optional[Selector] = None,\n",
    "    ) -> None:\n",
    "\n",
    "        self._config = config\n",
    "        self._policy_network = policy_network\n",
    "        self._env = env\n",
    "        self._variation_fn = variation_fn\n",
    "\n",
    "        ga_batch_size = int(self._config.proportion_mutation_ga * config.env_batch_size)\n",
    "        qpg_batch_size = config.env_batch_size - ga_batch_size\n",
    "\n",
    "        @dataclass\n",
    "        class CustomQualityPGConfig(QualityPGConfig):\n",
    "            num_envs: Any = None\n",
    "            num_steps: Any = None\n",
    "            target_update_interval: Any = None\n",
    "            tau: Any = None\n",
    "                \n",
    "        qpg_config = CustomQualityPGConfig(\n",
    "            env_batch_size=qpg_batch_size,\n",
    "            num_critic_training_steps=config.num_critic_training_steps,\n",
    "            num_pg_training_steps=config.num_pg_training_steps,\n",
    "            replay_buffer_size=config.replay_buffer_size,\n",
    "            critic_hidden_layer_size=config.critic_hidden_layer_size,\n",
    "            critic_learning_rate=config.critic_learning_rate,\n",
    "            actor_learning_rate=config.greedy_learning_rate,\n",
    "            policy_learning_rate=config.policy_learning_rate,\n",
    "            noise_clip=config.noise_clip,\n",
    "            policy_noise=config.policy_noise,\n",
    "            discount=config.discount,\n",
    "            reward_scaling=config.reward_scaling,\n",
    "            batch_size=config.batch_size,\n",
    "            soft_tau_update=config.soft_tau_update,\n",
    "            policy_delay=config.policy_delay,\n",
    "\n",
    "            num_envs = config.num_envs,\n",
    "            num_steps = config.num_steps,\n",
    "            target_update_interval = config.target_update_interval,\n",
    "            tau = config.tau,\n",
    "        )\n",
    "\n",
    "        # define the quality emitter\n",
    "        q_emitter = myQualityPGEmitter(\n",
    "            config=qpg_config,\n",
    "            policy_network=policy_network,\n",
    "            env=env,\n",
    "            selector=selector,\n",
    "        )\n",
    "\n",
    "        # define the GA emitter\n",
    "        ga_emitter = MixingEmitter(\n",
    "            mutation_fn=lambda x, r: (x, r),\n",
    "            variation_fn=variation_fn,\n",
    "            variation_percentage=1.0,\n",
    "            batch_size=ga_batch_size,\n",
    "            selector=selector,\n",
    "        )\n",
    "\n",
    "        super().__init__(emitters=(q_emitter, ga_emitter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cd1bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define emitter\n",
    "variation_fn = functools.partial(\n",
    "    isoline_variation, iso_sigma=iso_sigma, line_sigma=line_sigma\n",
    ")\n",
    "\n",
    "mixing_emitter = MixingEmitter(\n",
    "    mutation_fn=None,\n",
    "    variation_fn=variation_fn,\n",
    "    variation_percentage=1.0,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "pg_emitter = myPGAMEEmitter(\n",
    "    config=pga_emitter_config,\n",
    "    policy_network=policy_network,\n",
    "    env=wrapped_env, #env,\n",
    "    variation_fn=variation_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "598cdaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroids: (100, 2)\n",
      "Descriptor dim: 2\n",
      "Network params size (MB): 9.1295\n",
      "Expected repertoire memory (MB): 912.95\n"
     ]
    }
   ],
   "source": [
    "# Instantiate MAP-Elites\n",
    "map_elites = MAPElites(\n",
    "    scoring_function=scoring_fn,\n",
    "    emitter=pg_emitter, #mixing_emitter,\n",
    "    metrics_function=metrics_function,\n",
    ")\n",
    "\n",
    "# Compute the centroids\n",
    "key, subkey = jax.random.split(key)\n",
    "#centroids = compute_cvt_centroids(\n",
    "#    num_descriptors=number_of_descriptors,#env.descriptor_length, # Num of dimensions in the descriptor\n",
    "#    num_init_cvt_samples=num_init_cvt_samples,\n",
    "#    num_centroids=num_centroids,\n",
    "#    minval=min_descriptor,\n",
    "#    maxval=max_descriptor,\n",
    "#    key=subkey,\n",
    "#)\n",
    "grid_shape = (10, 10) # (500, 500)\n",
    "centroids = compute_euclidean_centroids(\n",
    "    grid_shape=grid_shape,\n",
    "    minval=min_descriptor,\n",
    "    maxval=max_descriptor,\n",
    ")\n",
    "\n",
    "print(\"Centroids:\", centroids.shape)   # how many?\n",
    "print(\"Descriptor dim:\", centroids.shape[-1])\n",
    "\n",
    "param_bytes = sum(x.size * x.dtype.itemsize for x in jax.tree.leaves(network_params))\n",
    "print(\"Network params size (MB):\", param_bytes / 1e6)\n",
    "\n",
    "total_repertoire_mem_mb = param_bytes/1e6 * centroids.shape[0]\n",
    "print(\"Expected repertoire memory (MB):\", total_repertoire_mem_mb)\n",
    "\n",
    "# Compute initial repertoire and emitter state\n",
    "key, subkey = jax.random.split(key)\n",
    "repertoire, emitter_state, init_metrics = map_elites.init(network_params, centroids, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c314a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_solution_near_descriptor(\n",
    "    repertoire: MapElitesRepertoire,\n",
    "    target_descriptor: jnp.ndarray,\n",
    "    initial_radius: float = 0.1,\n",
    "    max_radius: float = 2.0,\n",
    "    step: float = 0.05,\n",
    ") -> Tuple[Dict[str, jnp.ndarray], float, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Find the best solution near the target descriptor by expanding the radius until one is found.\n",
    "    \"\"\"\n",
    "\n",
    "    radius = initial_radius\n",
    "    found = False\n",
    "    best_params = None\n",
    "    best_fitness = -jnp.inf\n",
    "    best_descriptor = None\n",
    "\n",
    "    while radius <= max_radius and not found:\n",
    "        # Compute distances to centroids\n",
    "        distances = jnp.linalg.norm(repertoire.centroids - target_descriptor, axis=1)\n",
    "\n",
    "        # Find candidates within the radius\n",
    "        candidate_indices = jnp.where(distances < radius)[0]\n",
    "        candidate_fitnesses = repertoire.fitnesses[candidate_indices]\n",
    "        is_valid = candidate_fitnesses > -jnp.inf\n",
    "        #valid_indices = candidate_indices[is_valid]\n",
    "        valid_indices = candidate_indices[is_valid.ravel()]\n",
    "\n",
    "        if valid_indices.size > 0:\n",
    "            found = True\n",
    "            valid_fitnesses = repertoire.fitnesses[valid_indices]\n",
    "            best_idx_in_valid = jnp.argmax(valid_fitnesses)\n",
    "            best_index = valid_indices[best_idx_in_valid]\n",
    "\n",
    "            best_params = jax.tree.map(lambda x: x[best_index], repertoire.genotypes)\n",
    "            best_fitness = repertoire.fitnesses[best_index]\n",
    "            best_descriptor = repertoire.descriptors[best_index]\n",
    "        else:\n",
    "            radius += step\n",
    "\n",
    "    if not found:\n",
    "        # Fall back to dummy values if no solution found at all\n",
    "        best_params = jax.tree.map(lambda x: jnp.zeros_like(x[0]), repertoire.genotypes)\n",
    "        best_descriptor = jnp.zeros_like(repertoire.descriptors[0])\n",
    "        best_fitness = -jnp.inf\n",
    "\n",
    "    return best_params, best_fitness, best_descriptor\n",
    "\n",
    "def get_top_genotypes(repertoire, top_k):\n",
    "    \"\"\"Extract top_k genotypes from a repertoire, returning a clean stacked PyTree.\"\"\"\n",
    "    fitnesses = repertoire.fitnesses\n",
    "    valid_mask = fitnesses > -jnp.inf\n",
    "    valid_fitnesses = jnp.where(valid_mask, fitnesses, -jnp.inf)\n",
    "\n",
    "    # Sort indices by descending fitness\n",
    "    sorted_indices = jnp.argsort(valid_fitnesses)[::-1]\n",
    "    top_indices = sorted_indices[:top_k]\n",
    "\n",
    "    # Extract and squeeze each top genotype into a PyTree\n",
    "    top_genotypes_list = [\n",
    "        jax.tree_util.tree_map(lambda x: jnp.squeeze(x[i], axis=0), repertoire.genotypes)\n",
    "        for i in top_indices\n",
    "    ]\n",
    "\n",
    "    # Stack into batched PyTree\n",
    "    top_genotypes = jax.tree_util.tree_map(lambda *xs: jnp.stack(xs), *top_genotypes_list)\n",
    "\n",
    "    return top_genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1d79f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start main loop, num of loops  976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 14:17:23.400191: W external/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc:3021] Can't reduce memory use below 2.05GiB (2203149117 bytes) by rematerialization; only reduced to 5.79GiB (6217011391 bytes), down from 5.82GiB (6251883811 bytes) originally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 1/976\n",
      "loop 2/976\n",
      "loop 3/976\n",
      "loop 4/976\n",
      "loop 5/976\n",
      "loop 6/976\n",
      "loop 7/976\n",
      "loop 8/976\n",
      "loop 9/976\n",
      "loop 10/976\n",
      "loop 11/976\n",
      "loop 12/976\n",
      "loop 13/976\n",
      "loop 14/976\n",
      "loop 15/976\n",
      "loop 16/976\n",
      "loop 17/976\n",
      "loop 18/976\n",
      "loop 19/976\n",
      "loop 20/976\n",
      "loop 21/976\n",
      "loop 22/976\n",
      "loop 23/976\n",
      "loop 24/976\n",
      "loop 25/976\n",
      "loop 26/976\n",
      "loop 27/976\n",
      "loop 28/976\n",
      "loop 29/976\n",
      "loop 30/976\n",
      "loop 31/976\n",
      "loop 32/976\n",
      "loop 33/976\n",
      "loop 34/976\n",
      "loop 35/976\n",
      "loop 36/976\n",
      "loop 37/976\n",
      "loop 38/976\n",
      "loop 39/976\n",
      "loop 40/976\n",
      "loop 41/976\n",
      "loop 42/976\n",
      "loop 43/976\n",
      "loop 44/976\n",
      "loop 45/976\n",
      "loop 46/976\n",
      "loop 47/976\n",
      "loop 48/976\n",
      "loop 49/976\n",
      "loop 50/976\n",
      "loop 51/976\n",
      "loop 52/976\n",
      "loop 53/976\n",
      "loop 54/976\n",
      "loop 55/976\n",
      "loop 56/976\n",
      "loop 57/976\n",
      "loop 58/976\n",
      "loop 59/976\n",
      "loop 60/976\n",
      "loop 61/976\n",
      "loop 62/976\n",
      "loop 63/976\n",
      "loop 64/976\n",
      "loop 65/976\n",
      "loop 66/976\n",
      "loop 67/976\n",
      "loop 68/976\n",
      "loop 69/976\n",
      "loop 70/976\n",
      "loop 71/976\n",
      "loop 72/976\n",
      "loop 73/976\n",
      "loop 74/976\n",
      "loop 75/976\n",
      "loop 76/976\n",
      "loop 77/976\n",
      "loop 78/976\n",
      "loop 79/976\n",
      "loop 80/976\n",
      "loop 81/976\n",
      "loop 82/976\n",
      "loop 83/976\n",
      "loop 84/976\n",
      "loop 85/976\n",
      "loop 86/976\n",
      "loop 87/976\n",
      "loop 88/976\n",
      "loop 89/976\n",
      "loop 90/976\n",
      "loop 91/976\n",
      "loop 92/976\n",
      "loop 93/976\n",
      "loop 94/976\n",
      "loop 95/976\n",
      "loop 96/976\n",
      "loop 97/976\n",
      "loop 98/976\n",
      "loop 99/976\n",
      "loop 100/976\n",
      "loop 101/976\n",
      "loop 102/976\n",
      "loop 103/976\n",
      "loop 104/976\n",
      "loop 105/976\n",
      "loop 106/976\n",
      "loop 107/976\n",
      "loop 108/976\n",
      "loop 109/976\n",
      "loop 110/976\n",
      "loop 111/976\n",
      "loop 112/976\n",
      "loop 113/976\n",
      "loop 114/976\n",
      "loop 115/976\n",
      "loop 116/976\n",
      "loop 117/976\n",
      "loop 118/976\n",
      "loop 119/976\n",
      "loop 120/976\n",
      "loop 121/976\n",
      "loop 122/976\n",
      "loop 123/976\n",
      "loop 124/976\n",
      "loop 125/976\n",
      "loop 126/976\n",
      "loop 127/976\n",
      "loop 128/976\n",
      "loop 129/976\n",
      "loop 130/976\n",
      "loop 131/976\n",
      "loop 132/976\n",
      "loop 133/976\n",
      "loop 134/976\n",
      "loop 135/976\n",
      "loop 136/976\n",
      "loop 137/976\n",
      "loop 138/976\n",
      "loop 139/976\n",
      "loop 140/976\n",
      "loop 141/976\n",
      "loop 142/976\n",
      "loop 143/976\n",
      "loop 144/976\n",
      "loop 145/976\n",
      "loop 146/976\n",
      "loop 147/976\n",
      "loop 148/976\n",
      "loop 149/976\n",
      "loop 150/976\n",
      "loop 151/976\n",
      "loop 152/976\n",
      "loop 153/976\n",
      "loop 154/976\n",
      "loop 155/976\n",
      "loop 156/976\n",
      "loop 157/976\n",
      "loop 158/976\n",
      "loop 159/976\n",
      "loop 160/976\n",
      "loop 161/976\n",
      "loop 162/976\n",
      "loop 163/976\n",
      "loop 164/976\n",
      "loop 165/976\n",
      "loop 166/976\n",
      "loop 167/976\n",
      "loop 168/976\n",
      "loop 169/976\n",
      "loop 170/976\n",
      "loop 171/976\n",
      "loop 172/976\n",
      "loop 173/976\n",
      "loop 174/976\n",
      "loop 175/976\n",
      "loop 176/976\n",
      "loop 177/976\n",
      "loop 178/976\n",
      "loop 179/976\n",
      "loop 180/976\n",
      "loop 181/976\n",
      "loop 182/976\n",
      "loop 183/976\n",
      "loop 184/976\n",
      "loop 185/976\n",
      "loop 186/976\n",
      "loop 187/976\n",
      "loop 188/976\n",
      "loop 189/976\n",
      "loop 190/976\n",
      "loop 191/976\n",
      "loop 192/976\n",
      "loop 193/976\n",
      "loop 194/976\n",
      "loop 195/976\n",
      "loop 196/976\n",
      "loop 197/976\n",
      "loop 198/976\n",
      "loop 199/976\n",
      "loop 200/976\n",
      "loop 201/976\n",
      "loop 202/976\n",
      "loop 203/976\n",
      "loop 204/976\n",
      "loop 205/976\n",
      "loop 206/976\n",
      "loop 207/976\n",
      "loop 208/976\n",
      "loop 209/976\n",
      "loop 210/976\n",
      "loop 211/976\n",
      "loop 212/976\n",
      "loop 213/976\n",
      "loop 214/976\n",
      "loop 215/976\n",
      "loop 216/976\n",
      "loop 217/976\n",
      "loop 218/976\n",
      "loop 219/976\n",
      "loop 220/976\n",
      "loop 221/976\n",
      "loop 222/976\n",
      "loop 223/976\n",
      "loop 224/976\n",
      "loop 225/976\n",
      "loop 226/976\n",
      "loop 227/976\n",
      "loop 228/976\n",
      "loop 229/976\n",
      "loop 230/976\n",
      "loop 231/976\n",
      "loop 232/976\n",
      "loop 233/976\n",
      "loop 234/976\n",
      "loop 235/976\n",
      "loop 236/976\n",
      "loop 237/976\n",
      "loop 238/976\n",
      "loop 239/976\n",
      "loop 240/976\n",
      "loop 241/976\n",
      "loop 242/976\n",
      "loop 243/976\n",
      "loop 244/976\n",
      "loop 245/976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0820 15:42:28.814107 2553996 hlo_lexer.cc:443] Failed to parse int literal: 07258731385375554245137\n",
      "E0820 15:42:28.814167 2553996 hlo_lexer.cc:443] Failed to parse int literal: 07258731385375554245137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loop 246/976\n",
      "loop 247/976\n",
      "loop 248/976\n",
      "loop 249/976\n",
      "loop 250/976\n",
      "loop 251/976\n",
      "loop 252/976\n",
      "loop 253/976\n",
      "loop 254/976\n",
      "loop 255/976\n",
      "loop 256/976\n",
      "loop 257/976\n",
      "loop 258/976\n",
      "loop 259/976\n",
      "loop 260/976\n",
      "loop 261/976\n",
      "loop 262/976\n",
      "loop 263/976\n",
      "loop 264/976\n",
      "loop 265/976\n",
      "loop 266/976\n",
      "loop 267/976\n",
      "loop 268/976\n",
      "loop 269/976\n",
      "loop 270/976\n",
      "loop 271/976\n",
      "loop 272/976\n",
      "loop 273/976\n",
      "loop 274/976\n",
      "loop 275/976\n",
      "loop 276/976\n",
      "loop 277/976\n",
      "loop 278/976\n",
      "loop 279/976\n",
      "loop 280/976\n",
      "loop 281/976\n",
      "loop 282/976\n",
      "loop 283/976\n",
      "loop 284/976\n",
      "loop 285/976\n",
      "loop 286/976\n",
      "loop 287/976\n",
      "loop 288/976\n",
      "loop 289/976\n",
      "loop 290/976\n",
      "loop 291/976\n",
      "loop 292/976\n",
      "loop 293/976\n",
      "loop 294/976\n",
      "loop 295/976\n",
      "loop 296/976\n",
      "loop 297/976\n",
      "loop 298/976\n",
      "loop 299/976\n",
      "loop 300/976\n",
      "loop 301/976\n",
      "loop 302/976\n",
      "loop 303/976\n",
      "loop 304/976\n",
      "loop 305/976\n",
      "loop 306/976\n",
      "loop 307/976\n",
      "loop 308/976\n",
      "loop 309/976\n",
      "loop 310/976\n",
      "loop 311/976\n",
      "loop 312/976\n",
      "loop 313/976\n",
      "loop 314/976\n",
      "loop 315/976\n",
      "loop 316/976\n",
      "loop 317/976\n",
      "loop 318/976\n",
      "loop 319/976\n",
      "loop 320/976\n",
      "loop 321/976\n",
      "loop 322/976\n",
      "loop 323/976\n",
      "loop 324/976\n",
      "loop 325/976\n",
      "loop 326/976\n",
      "loop 327/976\n",
      "loop 328/976\n",
      "loop 329/976\n",
      "loop 330/976\n",
      "loop 331/976\n",
      "loop 332/976\n",
      "loop 333/976\n",
      "loop 334/976\n",
      "loop 335/976\n",
      "loop 336/976\n",
      "loop 337/976\n",
      "loop 338/976\n",
      "loop 339/976\n",
      "loop 340/976\n",
      "loop 341/976\n",
      "loop 342/976\n",
      "loop 343/976\n",
      "loop 344/976\n",
      "loop 345/976\n",
      "loop 346/976\n",
      "loop 347/976\n",
      "loop 348/976\n",
      "loop 349/976\n",
      "loop 350/976\n",
      "loop 351/976\n",
      "loop 352/976\n",
      "loop 353/976\n",
      "loop 354/976\n",
      "loop 355/976\n",
      "loop 356/976\n",
      "loop 357/976\n",
      "loop 358/976\n",
      "loop 359/976\n",
      "loop 360/976\n",
      "loop 361/976\n",
      "loop 362/976\n",
      "loop 363/976\n",
      "loop 364/976\n",
      "loop 365/976\n",
      "loop 366/976\n",
      "loop 367/976\n",
      "loop 368/976\n",
      "loop 369/976\n",
      "loop 370/976\n",
      "loop 371/976\n",
      "loop 372/976\n",
      "loop 373/976\n",
      "loop 374/976\n",
      "loop 375/976\n",
      "loop 376/976\n",
      "loop 377/976\n",
      "loop 378/976\n",
      "loop 379/976\n",
      "loop 380/976\n",
      "loop 381/976\n",
      "loop 382/976\n",
      "loop 383/976\n",
      "loop 384/976\n",
      "loop 385/976\n",
      "loop 386/976\n",
      "loop 387/976\n",
      "loop 388/976\n",
      "loop 389/976\n",
      "loop 390/976\n",
      "loop 391/976\n",
      "loop 392/976\n",
      "loop 393/976\n",
      "loop 394/976\n",
      "loop 395/976\n",
      "loop 396/976\n",
      "loop 397/976\n",
      "loop 398/976\n",
      "loop 399/976\n",
      "loop 400/976\n",
      "loop 401/976\n",
      "loop 402/976\n",
      "loop 403/976\n",
      "loop 404/976\n",
      "loop 405/976\n",
      "loop 406/976\n",
      "loop 407/976\n",
      "loop 408/976\n",
      "loop 409/976\n",
      "loop 410/976\n",
      "loop 411/976\n",
      "loop 412/976\n",
      "loop 413/976\n",
      "loop 414/976\n",
      "loop 415/976\n",
      "loop 416/976\n",
      "loop 417/976\n",
      "loop 418/976\n",
      "loop 419/976\n",
      "loop 420/976\n",
      "loop 421/976\n",
      "loop 422/976\n",
      "loop 423/976\n",
      "loop 424/976\n",
      "loop 425/976\n",
      "loop 426/976\n",
      "loop 427/976\n",
      "loop 428/976\n",
      "loop 429/976\n",
      "loop 430/976\n",
      "loop 431/976\n",
      "loop 432/976\n",
      "loop 433/976\n",
      "loop 434/976\n",
      "loop 435/976\n",
      "loop 436/976\n",
      "loop 437/976\n",
      "loop 438/976\n",
      "loop 439/976\n",
      "loop 440/976\n",
      "loop 441/976\n",
      "loop 442/976\n",
      "loop 443/976\n",
      "loop 444/976\n",
      "loop 445/976\n",
      "loop 446/976\n",
      "loop 447/976\n",
      "loop 448/976\n",
      "loop 449/976\n",
      "loop 450/976\n",
      "loop 451/976\n",
      "loop 452/976\n",
      "loop 453/976\n",
      "loop 454/976\n",
      "loop 455/976\n",
      "loop 456/976\n",
      "loop 457/976\n",
      "loop 458/976\n",
      "loop 459/976\n",
      "loop 460/976\n",
      "loop 461/976\n",
      "loop 462/976\n",
      "loop 463/976\n",
      "loop 464/976\n",
      "loop 465/976\n",
      "loop 466/976\n",
      "loop 467/976\n",
      "loop 468/976\n",
      "loop 469/976\n",
      "loop 470/976\n",
      "loop 471/976\n",
      "loop 472/976\n",
      "loop 473/976\n",
      "loop 474/976\n",
      "loop 475/976\n",
      "loop 476/976\n",
      "loop 477/976\n",
      "loop 478/976\n",
      "loop 479/976\n",
      "loop 480/976\n",
      "loop 481/976\n",
      "loop 482/976\n",
      "loop 483/976\n",
      "loop 484/976\n",
      "loop 485/976\n",
      "loop 486/976\n",
      "loop 487/976\n",
      "loop 488/976\n",
      "loop 489/976\n",
      "loop 490/976\n",
      "loop 491/976\n",
      "loop 492/976\n",
      "loop 493/976\n",
      "loop 494/976\n",
      "loop 495/976\n",
      "loop 496/976\n",
      "loop 497/976\n",
      "loop 498/976\n",
      "loop 499/976\n",
      "loop 500/976\n",
      "loop 501/976\n",
      "loop 502/976\n",
      "loop 503/976\n",
      "loop 504/976\n",
      "loop 505/976\n",
      "loop 506/976\n",
      "loop 507/976\n",
      "loop 508/976\n",
      "loop 509/976\n",
      "loop 510/976\n",
      "loop 511/976\n",
      "loop 512/976\n",
      "loop 513/976\n",
      "loop 514/976\n",
      "loop 515/976\n",
      "loop 516/976\n",
      "loop 517/976\n",
      "loop 518/976\n",
      "loop 519/976\n",
      "loop 520/976\n",
      "loop 521/976\n",
      "loop 522/976\n",
      "loop 523/976\n",
      "loop 524/976\n",
      "loop 525/976\n",
      "loop 526/976\n",
      "loop 527/976\n",
      "loop 528/976\n",
      "loop 529/976\n",
      "loop 530/976\n",
      "loop 531/976\n",
      "loop 532/976\n",
      "loop 533/976\n",
      "loop 534/976\n",
      "loop 535/976\n",
      "loop 536/976\n",
      "loop 537/976\n",
      "loop 538/976\n",
      "loop 539/976\n",
      "loop 540/976\n",
      "loop 541/976\n",
      "loop 542/976\n",
      "loop 543/976\n",
      "loop 544/976\n",
      "loop 545/976\n",
      "loop 546/976\n",
      "loop 547/976\n",
      "loop 548/976\n",
      "loop 549/976\n",
      "loop 550/976\n",
      "loop 551/976\n",
      "loop 552/976\n",
      "loop 553/976\n",
      "loop 554/976\n",
      "loop 555/976\n",
      "loop 556/976\n",
      "loop 557/976\n",
      "loop 558/976\n",
      "loop 559/976\n",
      "loop 560/976\n",
      "loop 561/976\n",
      "loop 562/976\n",
      "loop 563/976\n",
      "loop 564/976\n",
      "loop 565/976\n",
      "loop 566/976\n",
      "loop 567/976\n",
      "loop 568/976\n",
      "loop 569/976\n",
      "loop 570/976\n",
      "loop 571/976\n",
      "loop 572/976\n",
      "loop 573/976\n",
      "loop 574/976\n",
      "loop 575/976\n",
      "loop 576/976\n",
      "loop 577/976\n",
      "loop 578/976\n",
      "loop 579/976\n",
      "loop 580/976\n",
      "loop 581/976\n",
      "loop 582/976\n",
      "loop 583/976\n",
      "loop 584/976\n",
      "loop 585/976\n",
      "loop 586/976\n",
      "loop 587/976\n",
      "loop 588/976\n",
      "loop 589/976\n",
      "loop 590/976\n",
      "loop 591/976\n",
      "loop 592/976\n",
      "loop 593/976\n",
      "loop 594/976\n",
      "loop 595/976\n",
      "loop 596/976\n",
      "loop 597/976\n",
      "loop 598/976\n",
      "loop 599/976\n",
      "loop 600/976\n",
      "loop 601/976\n",
      "loop 602/976\n",
      "loop 603/976\n",
      "loop 604/976\n",
      "loop 605/976\n",
      "loop 606/976\n",
      "loop 607/976\n",
      "loop 608/976\n",
      "loop 609/976\n",
      "loop 610/976\n",
      "loop 611/976\n",
      "loop 612/976\n",
      "loop 613/976\n",
      "loop 614/976\n",
      "loop 615/976\n",
      "loop 616/976\n",
      "loop 617/976\n",
      "loop 618/976\n",
      "loop 619/976\n",
      "loop 620/976\n",
      "loop 621/976\n",
      "loop 622/976\n",
      "loop 623/976\n",
      "loop 624/976\n",
      "loop 625/976\n",
      "loop 626/976\n",
      "loop 627/976\n",
      "loop 628/976\n",
      "loop 629/976\n",
      "loop 630/976\n",
      "loop 631/976\n",
      "loop 632/976\n",
      "loop 633/976\n",
      "loop 634/976\n",
      "loop 635/976\n",
      "loop 636/976\n",
      "loop 637/976\n",
      "loop 638/976\n",
      "loop 639/976\n",
      "loop 640/976\n",
      "loop 641/976\n",
      "loop 642/976\n",
      "loop 643/976\n",
      "loop 644/976\n",
      "loop 645/976\n",
      "loop 646/976\n",
      "loop 647/976\n",
      "loop 648/976\n",
      "loop 649/976\n",
      "loop 650/976\n",
      "loop 651/976\n",
      "loop 652/976\n",
      "loop 653/976\n",
      "loop 654/976\n",
      "loop 655/976\n",
      "loop 656/976\n",
      "loop 657/976\n",
      "loop 658/976\n",
      "loop 659/976\n",
      "loop 660/976\n",
      "loop 661/976\n",
      "loop 662/976\n",
      "loop 663/976\n",
      "loop 664/976\n",
      "loop 665/976\n",
      "loop 666/976\n",
      "loop 667/976\n",
      "loop 668/976\n",
      "loop 669/976\n",
      "loop 670/976\n",
      "loop 671/976\n",
      "loop 672/976\n",
      "loop 673/976\n",
      "loop 674/976\n",
      "loop 675/976\n",
      "loop 676/976\n",
      "loop 677/976\n",
      "loop 678/976\n",
      "loop 679/976\n",
      "loop 680/976\n",
      "loop 681/976\n",
      "loop 682/976\n",
      "loop 683/976\n",
      "loop 684/976\n",
      "loop 685/976\n",
      "loop 686/976\n",
      "loop 687/976\n",
      "loop 688/976\n",
      "loop 689/976\n",
      "loop 690/976\n",
      "loop 691/976\n",
      "loop 692/976\n",
      "loop 693/976\n",
      "loop 694/976\n",
      "loop 695/976\n",
      "loop 696/976\n",
      "loop 697/976\n",
      "loop 698/976\n",
      "loop 699/976\n",
      "loop 700/976\n",
      "loop 701/976\n",
      "loop 702/976\n",
      "loop 703/976\n",
      "loop 704/976\n",
      "loop 705/976\n",
      "loop 706/976\n",
      "loop 707/976\n",
      "loop 708/976\n",
      "loop 709/976\n",
      "loop 710/976\n",
      "loop 711/976\n",
      "loop 712/976\n",
      "loop 713/976\n",
      "loop 714/976\n",
      "loop 715/976\n",
      "loop 716/976\n",
      "loop 717/976\n",
      "loop 718/976\n",
      "loop 719/976\n",
      "loop 720/976\n",
      "loop 721/976\n",
      "loop 722/976\n",
      "loop 723/976\n",
      "loop 724/976\n",
      "loop 725/976\n",
      "loop 726/976\n",
      "loop 727/976\n",
      "loop 728/976\n",
      "loop 729/976\n",
      "loop 730/976\n",
      "loop 731/976\n",
      "loop 732/976\n",
      "loop 733/976\n",
      "loop 734/976\n",
      "loop 735/976\n",
      "loop 736/976\n",
      "loop 737/976\n",
      "loop 738/976\n",
      "loop 739/976\n",
      "loop 740/976\n",
      "loop 741/976\n",
      "loop 742/976\n",
      "loop 743/976\n",
      "loop 744/976\n",
      "loop 745/976\n",
      "loop 746/976\n",
      "loop 747/976\n",
      "loop 748/976\n",
      "loop 749/976\n",
      "loop 750/976\n",
      "loop 751/976\n",
      "loop 752/976\n",
      "loop 753/976\n",
      "loop 754/976\n",
      "loop 755/976\n",
      "loop 756/976\n",
      "loop 757/976\n",
      "loop 758/976\n",
      "loop 759/976\n",
      "loop 760/976\n",
      "loop 761/976\n",
      "loop 762/976\n",
      "loop 763/976\n",
      "loop 764/976\n",
      "loop 765/976\n",
      "loop 766/976\n",
      "loop 767/976\n",
      "loop 768/976\n",
      "loop 769/976\n",
      "loop 770/976\n",
      "loop 771/976\n",
      "loop 772/976\n",
      "loop 773/976\n",
      "loop 774/976\n",
      "loop 775/976\n",
      "loop 776/976\n",
      "loop 777/976\n",
      "loop 778/976\n",
      "loop 779/976\n",
      "loop 780/976\n",
      "loop 781/976\n",
      "loop 782/976\n",
      "loop 783/976\n",
      "loop 784/976\n",
      "loop 785/976\n",
      "loop 786/976\n",
      "loop 787/976\n",
      "loop 788/976\n",
      "loop 789/976\n",
      "loop 790/976\n",
      "loop 791/976\n",
      "loop 792/976\n",
      "loop 793/976\n",
      "loop 794/976\n",
      "loop 795/976\n",
      "loop 796/976\n",
      "loop 797/976\n",
      "loop 798/976\n",
      "loop 799/976\n",
      "loop 800/976\n",
      "loop 801/976\n",
      "loop 802/976\n",
      "loop 803/976\n",
      "loop 804/976\n",
      "loop 805/976\n",
      "loop 806/976\n",
      "loop 807/976\n",
      "loop 808/976\n",
      "loop 809/976\n",
      "loop 810/976\n",
      "loop 811/976\n",
      "loop 812/976\n",
      "loop 813/976\n",
      "loop 814/976\n",
      "loop 815/976\n",
      "loop 816/976\n",
      "loop 817/976\n",
      "loop 818/976\n",
      "loop 819/976\n",
      "loop 820/976\n",
      "loop 821/976\n",
      "loop 822/976\n",
      "loop 823/976\n",
      "loop 824/976\n",
      "loop 825/976\n",
      "loop 826/976\n",
      "loop 827/976\n",
      "loop 828/976\n",
      "loop 829/976\n",
      "loop 830/976\n",
      "loop 831/976\n",
      "loop 832/976\n",
      "loop 833/976\n",
      "loop 834/976\n",
      "loop 835/976\n",
      "loop 836/976\n",
      "loop 837/976\n",
      "loop 838/976\n",
      "loop 839/976\n",
      "loop 840/976\n",
      "loop 841/976\n",
      "loop 842/976\n",
      "loop 843/976\n",
      "loop 844/976\n",
      "loop 845/976\n",
      "loop 846/976\n",
      "loop 847/976\n",
      "loop 848/976\n",
      "loop 849/976\n",
      "loop 850/976\n",
      "loop 851/976\n",
      "loop 852/976\n",
      "loop 853/976\n",
      "loop 854/976\n",
      "loop 855/976\n",
      "loop 856/976\n",
      "loop 857/976\n",
      "loop 858/976\n",
      "loop 859/976\n",
      "loop 860/976\n",
      "loop 861/976\n",
      "loop 862/976\n",
      "loop 863/976\n",
      "loop 864/976\n",
      "loop 865/976\n",
      "loop 866/976\n",
      "loop 867/976\n",
      "loop 868/976\n",
      "loop 869/976\n",
      "loop 870/976\n",
      "loop 871/976\n",
      "loop 872/976\n",
      "loop 873/976\n",
      "loop 874/976\n",
      "loop 875/976\n",
      "loop 876/976\n",
      "loop 877/976\n",
      "loop 878/976\n",
      "loop 879/976\n",
      "loop 880/976\n",
      "loop 881/976\n",
      "loop 882/976\n",
      "loop 883/976\n",
      "loop 884/976\n",
      "loop 885/976\n",
      "loop 886/976\n",
      "loop 887/976\n",
      "loop 888/976\n",
      "loop 889/976\n",
      "loop 890/976\n",
      "loop 891/976\n",
      "loop 892/976\n",
      "loop 893/976\n",
      "loop 894/976\n",
      "loop 895/976\n",
      "loop 896/976\n",
      "loop 897/976\n",
      "loop 898/976\n",
      "loop 899/976\n",
      "loop 900/976\n",
      "loop 901/976\n",
      "loop 902/976\n",
      "loop 903/976\n",
      "loop 904/976\n",
      "loop 905/976\n",
      "loop 906/976\n",
      "loop 907/976\n",
      "loop 908/976\n",
      "loop 909/976\n",
      "loop 910/976\n",
      "loop 911/976\n",
      "loop 912/976\n",
      "loop 913/976\n",
      "loop 914/976\n",
      "loop 915/976\n",
      "loop 916/976\n",
      "loop 917/976\n",
      "loop 918/976\n",
      "loop 919/976\n",
      "loop 920/976\n",
      "loop 921/976\n",
      "loop 922/976\n",
      "loop 923/976\n",
      "loop 924/976\n",
      "loop 925/976\n",
      "loop 926/976\n",
      "loop 927/976\n",
      "loop 928/976\n",
      "loop 929/976\n",
      "loop 930/976\n",
      "loop 931/976\n",
      "loop 932/976\n",
      "loop 933/976\n",
      "loop 934/976\n",
      "loop 935/976\n",
      "loop 936/976\n",
      "loop 937/976\n",
      "loop 938/976\n",
      "loop 939/976\n",
      "loop 940/976\n",
      "loop 941/976\n",
      "loop 942/976\n",
      "loop 943/976\n",
      "loop 944/976\n",
      "loop 945/976\n",
      "loop 946/976\n",
      "loop 947/976\n",
      "loop 948/976\n",
      "loop 949/976\n",
      "loop 950/976\n",
      "loop 951/976\n",
      "loop 952/976\n",
      "loop 953/976\n",
      "loop 954/976\n",
      "loop 955/976\n",
      "loop 956/976\n",
      "loop 957/976\n",
      "loop 958/976\n",
      "loop 959/976\n",
      "loop 960/976\n",
      "loop 961/976\n",
      "loop 962/976\n",
      "loop 963/976\n",
      "loop 964/976\n",
      "loop 965/976\n",
      "loop 966/976\n",
      "loop 967/976\n",
      "loop 968/976\n",
      "loop 969/976\n",
      "loop 970/976\n",
      "loop 971/976\n",
      "loop 972/976\n",
      "loop 973/976\n",
      "loop 974/976\n",
      "loop 975/976\n",
      "loop 976/976\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "log_period = 10\n",
    "num_loops = num_iterations // log_period\n",
    "\n",
    "# Initialize metrics\n",
    "metrics = {key: jnp.array([]) for key in [\"iteration\", \"qd_score\", \"coverage\", \"max_fitness\", \"time\"]}\n",
    "\n",
    "# Set up init metrics\n",
    "init_metrics = jax.tree.map(lambda x: jnp.array([x]) if x.shape == () else x, init_metrics)\n",
    "init_metrics[\"iteration\"] = jnp.array([0], dtype=jnp.int32)\n",
    "init_metrics[\"time\"] = jnp.array([0.0])  # No time recorded for initialization\n",
    "\n",
    "# Convert init_metrics to match the metrics dictionary structure\n",
    "metrics = jax.tree.map(lambda metric, init_metric: jnp.concatenate([metric, init_metric], axis=0), metrics, init_metrics)\n",
    "\n",
    "# Initialize CSV logger\n",
    "csv_logger = CSVLogger(\n",
    "    \"PGA_ME_QMIX-logs.csv\",\n",
    "    header=list(metrics.keys())\n",
    ")\n",
    "\n",
    "# Log initial metrics\n",
    "csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "\n",
    "# Main loop\n",
    "map_elites_scan_update = map_elites.scan_update\n",
    "#print(jax.tree_util.tree_structure((repertoire, emitter_state, key)))\n",
    "print(\"Start main loop, num of loops \", num_loops)\n",
    "for i in range(num_loops):\n",
    "    start_time = time.time()\n",
    "    (\n",
    "        repertoire,\n",
    "        emitter_state,\n",
    "        key,\n",
    "    ), current_metrics = jax.lax.scan(\n",
    "        map_elites_scan_update,\n",
    "        (repertoire, emitter_state, key),\n",
    "        (),\n",
    "        length=log_period,\n",
    "    )\n",
    "    timelapse = time.time() - start_time\n",
    "    print(f\"loop {i+1}/{num_loops}\")\n",
    "\n",
    "    # Metrics\n",
    "    current_metrics[\"iteration\"] = jnp.arange(1+log_period*i, 1+log_period*(i+1), dtype=jnp.int32)\n",
    "    current_metrics[\"time\"] = jnp.repeat(timelapse, log_period)\n",
    "    metrics = jax.tree.map(lambda metric, current_metric: jnp.concatenate([metric, current_metric], axis=0), metrics, current_metrics)\n",
    "\n",
    "    # Log\n",
    "    csv_logger.log(jax.tree.map(lambda x: x[-1], metrics))\n",
    "\n",
    "    '''\n",
    "    # Create a new env replacing the old wrapped env that uses an updated policy from the reportoire depending on descriptor\n",
    "    if ((i + 1) % 10 == 0) and ((i + 1) > 50):\n",
    "        \n",
    "        # Choose best policy within range of target descriptor\n",
    "        #target_descriptor = jnp.array([[0.3, 0.3]])  # example target\n",
    "        #best_params, best_fitness, best_descriptor = get_best_solution_near_descriptor(\n",
    "        #    repertoire, target_descriptor, initial_radius=0.5\n",
    "        #)\n",
    "        \n",
    "        # Choose best overall policy\n",
    "        best_idx = jnp.argmax(repertoire.fitnesses)\n",
    "        best_params = jax.tree.map(lambda x: x[best_idx], repertoire.genotypes)\n",
    "\n",
    "        env = LearnedPolicyEnemySMAX(policy = policy_network, params=best_params[\"agent\"], config=config, scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "        env = SMAXLogWrapper(env)\n",
    "        wrapped_env = CTRolloutManager(env, batch_size=config[\"NUM_ENVS\"])\n",
    "\n",
    "        reset_fn = jax.jit(wrapped_env.batch_reset)\n",
    "\n",
    "        new_scoring_fn = functools.partial(\n",
    "            scoring_function,\n",
    "            episode_length=episode_length,\n",
    "            play_reset_fn=reset_fn,\n",
    "            play_step_fn=play_step_fn,\n",
    "            descriptor_extractor=descriptor_extraction_fn,\n",
    "        )\n",
    "\n",
    "        new_pg_emitter = myPGAMEEmitter(\n",
    "            config=pga_emitter_config,\n",
    "            policy_network=policy_network,\n",
    "            env=wrapped_env,\n",
    "            variation_fn=variation_fn,\n",
    "        )\n",
    "\n",
    "        # Reinstantiate MAP-Elites\n",
    "        new_map_elites = MAPElites(\n",
    "            scoring_function=new_scoring_fn,\n",
    "            emitter=new_pg_emitter, #mixing_emitter,\n",
    "            metrics_function=metrics_function,\n",
    "        )\n",
    "\n",
    "        \n",
    "        # the best performing policies\n",
    "        top_genotypes = get_top_genotypes(repertoire, batch_size)\n",
    "\n",
    "        # Debug shape\n",
    "        #jax.tree_util.tree_map(lambda x: print(\"GENOTYPE SHAPE:\", x.shape), top_genotypes)\n",
    "        #jax.tree.map(lambda x: print(\"GENOTYPE SHAPE:\", x.shape), top_genotypes)\n",
    "\n",
    "        # Manually delete old objects\n",
    "        del repertoire\n",
    "        del emitter_state\n",
    "        del map_elites_scan_update\n",
    "\n",
    "        # Trigger Python garbage collection\n",
    "        gc.collect()\n",
    "        \n",
    "        # Create new reportoire and emitter state to use\n",
    "        key, subkey = jax.random.split(key)\n",
    "        repertoire, emitter_state, _ = new_map_elites.init(top_genotypes, centroids, subkey)\n",
    "        \n",
    "\n",
    "        # Update scan function with new_map_elites\n",
    "        map_elites_scan_update = new_map_elites.scan_update\n",
    "        \n",
    "        print(f\"loop updated at end of {i+1}/{num_loops}\")\n",
    "        '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21b2269c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 4000x1000 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the x-axis array\n",
    "#env_steps = metrics[\"iteration\"]\n",
    "env_steps = metrics[\"iteration\"] * batch_size * episode_length * config[\"NUM_ENVS\"]\n",
    "#print(jnp.max(env_steps))\n",
    "#print(jnp.max(metrics[\"iteration\"]))\n",
    "\n",
    "%matplotlib inline\n",
    "# Create the plots and the grid\n",
    "fig, axes = plot_map_elites_results(env_steps=env_steps, metrics=metrics, repertoire=repertoire, min_descriptor=min_descriptor, max_descriptor=max_descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1f36477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitness in the repertoire: 2.59\n",
      " Descriptor of the best individual in the repertoire: [0.37269878 0.42373762]\n",
      " Index in the repertoire of this individual: 43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_idx = jnp.argmax(repertoire.fitnesses)\n",
    "best_fitness = jnp.max(repertoire.fitnesses)\n",
    "best_descriptor = repertoire.descriptors[best_idx]\n",
    "print(\n",
    "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
    "    f\"Descriptor of the best individual in the repertoire: {best_descriptor}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ba84343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the parameters of the best individual\n",
    "my_params = jax.tree.map(\n",
    "    lambda x: x[best_idx],\n",
    "    repertoire.genotypes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ca1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from jaxmarl.environments.multi_agent_env import MultiAgentEnv\n",
    "\n",
    "class Visualizer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: MultiAgentEnv,\n",
    "        state_seq,\n",
    "        reward_seq=None,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.interval = 64\n",
    "\n",
    "        # Preload data to CPU to avoid GPU-to-CPU transfers during animation\n",
    "        self.state_seq = jax.device_get(state_seq)\n",
    "        self.reward_seq = jax.device_get(reward_seq) if reward_seq is not None else None\n",
    "\n",
    "        self.fig, self.ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    def animate(\n",
    "        self,\n",
    "        save_fname: Optional[str] = None,\n",
    "        view: bool = True,\n",
    "    ):\n",
    "        ani = animation.FuncAnimation(\n",
    "            self.fig,\n",
    "            self.update,\n",
    "            frames=len(self.state_seq),\n",
    "            init_func=self.init,\n",
    "            blit=True,  # Enables fast rendering\n",
    "            interval=self.interval,\n",
    "        )\n",
    "\n",
    "        if save_fname is not None:\n",
    "            ani.save(save_fname)\n",
    "\n",
    "        if view:\n",
    "            plt.show(block=True)\n",
    "\n",
    "    def init(self):\n",
    "        self.im = self.env.init_render(self.ax, self.state_seq[0])\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.im = self.env.update_render(self.im, self.state_seq[frame])\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "\n",
    "class SMAXVisualizer(Visualizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: MultiAgentEnv,\n",
    "        state_seq,\n",
    "        reward_seq=None,\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.raw_state_seq = state_seq  # GPU array until expanded\n",
    "        self.reward_seq = reward_seq\n",
    "        self.interval = 64\n",
    "        self.have_expanded = False\n",
    "        self.heuristic_enemy = isinstance(env, EnemySMAX)\n",
    "        self.fig, self.ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    def expand_state_seq(self):\n",
    "        \"\"\"Expands the state sequence for higher frame resolution.\"\"\"\n",
    "        expanded = self.env.expand_state_seq(self.raw_state_seq)\n",
    "        self.state_seq = jax.device_get(expanded)  # Preload to CPU\n",
    "        self.have_expanded = True\n",
    "\n",
    "    def animate(self, save_fname: Optional[str] = None, view: bool = True):\n",
    "        if not self.have_expanded:\n",
    "            self.expand_state_seq()\n",
    "        return super().animate(save_fname, view)\n",
    "\n",
    "    def init(self):\n",
    "        self.im = self.env.init_render(self.ax, self.state_seq[0], 0, 0)\n",
    "        return [self.im]  # Required for blitting\n",
    "\n",
    "    def update(self, frame):\n",
    "        self.im = self.env.update_render(\n",
    "            self.im,\n",
    "            self.state_seq[frame],\n",
    "            frame % self.env.world_steps_per_env_step,\n",
    "            frame // self.env.world_steps_per_env_step,\n",
    "        )\n",
    "        return [self.im]  # Required for blitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "424061d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_obs_with_id(obs_dict, env):\n",
    "    \"\"\"Simulate CTRolloutManager's preprocessing by adding one-hot agent IDs.\"\"\"\n",
    "    new_obs_dict = {}\n",
    "    num_agents = len(env.agents)\n",
    "    for i, agent in enumerate(env.agents):\n",
    "        obs = obs_dict[agent].flatten()\n",
    "        one_hot = jax.nn.one_hot(i, num_classes=num_agents)\n",
    "        new_obs_dict[agent] = jnp.concatenate([obs, one_hot])\n",
    "    return new_obs_dict\n",
    "\n",
    "\n",
    "def visualize_recurrent_policy(trained_params, env, config):\n",
    "    rng = jax.random.PRNGKey(config[\"SEED\"])\n",
    "    rng, rng = jax.random.split(rng)\n",
    "    #wrapped_env = CTRolloutManager(env, batch_size=1)\n",
    "\n",
    "    # Create policy network\n",
    "    #network = RNNQNetwork(\n",
    "    #    action_dim=wrapped_env.max_action_space,\n",
    "    #    hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "    #)\n",
    "    network = RNNQNetwork(\n",
    "        action_dim=env.action_space(env.agents[0]).n,\n",
    "        hidden_dim=config[\"HIDDEN_SIZE\"],\n",
    "    )\n",
    "    \n",
    "    # Reset environment\n",
    "    #obs, env_state = wrapped_env.batch_reset(reset_rng)\n",
    "    obs, env_state = env.reset(rng)\n",
    "    #dones = {\n",
    "    #    agent: jnp.zeros((1), dtype=bool)\n",
    "    #    for agent in env.agents + [\"__all__\"]\n",
    "    #}\n",
    "    dones = {agent: jnp.array(False) for agent in env.agents}\n",
    "    hstate = ScannedRNN.initialize_carry(\n",
    "        config[\"HIDDEN_SIZE\"], len(env.agents), 1\n",
    "    )\n",
    "    \n",
    "    # Collect all environment states\n",
    "    returns = {agent: 0.0 for agent in env.agents}\n",
    "    state_seq = []\n",
    "    max_steps = config[\"NUM_STEPS\"]\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        # Compute Q-values\n",
    "        # Prepare inputs for network\n",
    "        obs = preprocess_obs_with_id(obs, env)\n",
    "        _obs = batchify(obs)         # (num_agents, obs_dim)\n",
    "        _obs = _obs[:, None, :]                      # (num_agents, 1, obs_dim)\n",
    "\n",
    "        #_dones = batchify(dones)    # (num_agents,)\n",
    "        #_dones = _dones[:, None]                     # (num_agents, 1)\n",
    "        _dones = jnp.stack([jnp.array([dones[agent]]) for agent in env.agents])  # shape (num_agents, 1)\n",
    "        _dones = jnp.expand_dims(_dones, axis=-1)  # from (3, 1) to (3, 1, 1)\n",
    "\n",
    "        #print(\"_obs.shape:\", _obs.shape)\n",
    "        #print(\"_dones.shape:\", _dones.shape)\n",
    "        #print(\"hstate.shape:\", hstate.shape)\n",
    "\n",
    "        def apply_fn(h, o, d):\n",
    "            return network.apply(trained_params, h, o, d)\n",
    "\n",
    "        hstate, q_vals = jax.vmap(apply_fn, in_axes=(0, 0, 0))(\n",
    "            hstate,\n",
    "            _obs,\n",
    "            _dones,\n",
    "        )\n",
    "        #print(\"hstate.shape:\", hstate.shape)\n",
    "\n",
    "        #hstate = hstate[:, None, :]  # Already in (num_agents, hidden_dim)\n",
    "        q_vals = q_vals.squeeze(axis=1)  # (num_agents, num_envs, num_actions) remove the time dim\n",
    "        #print(\"q_vals.shape\", q_vals.shape)\n",
    "        \n",
    "        actions = {}\n",
    "        #avail_actions = wrapped_env.get_valid_actions(env_state.env_state)\n",
    "        avail_actions = env.get_avail_actions(env_state.env_state)\n",
    "\n",
    "        for i, agent in enumerate(env.agents):\n",
    "            avail_agent = avail_actions[agent][None, None, :]  # shape (1, 1, n_actions)\n",
    "            #print(\"avail_agent.shape\", avail_agent.shape)\n",
    "            \n",
    "            unavail_actions = 1 - avail_agent  # shape (1, 1, n_actions)\n",
    "            \n",
    "            # Select Q-values for this agent only\n",
    "            q_agent = q_vals[i][None, None, :]  # shape (1, 1, n_actions)\n",
    "            q_masked = q_agent - (unavail_actions * 1e10)\n",
    "\n",
    "            action = jnp.argmax(q_masked, axis=-1)  # shape (1, 1)\n",
    "            action = action.squeeze()               # scalar\n",
    "            #print(\"action.shape\", action.shape)\n",
    "\n",
    "            # Wrap in array with batch dim\n",
    "            actions[agent] = int(action)    # shape (1,)\n",
    "        \n",
    "        #rng, rng_s = jax.random.split(rng)\n",
    "        state_seq.append((rng, env_state.env_state, actions))\n",
    "\n",
    "        # Step environment\n",
    "\n",
    "        # Batch the actions dict\n",
    "        # Original actions: {'ally_0': 4, 'ally_1': 4, 'ally_2': 4}\n",
    "        #actions = {k: jnp.array([v]) for k, v in actions.items()}\n",
    "\n",
    "        #obs, env_state, rewards, dones, infos = wrapped_env.batch_step(\n",
    "        #    rng_s, env_state, actions\n",
    "        #)\n",
    "        obs, env_state, rewards, dones, infos = env.step(rng, env_state, actions)\n",
    "        returns = {a: returns[a] + rewards[a] for a in env.agents}\n",
    "        \n",
    "        if dones[\"__all__\"]:\n",
    "            break\n",
    "\n",
    "    # Visualization\n",
    "    print(\"Returns:\", returns)\n",
    "\n",
    "    viz = SMAXVisualizer(env, state_seq)\n",
    "    viz.animate(view=False, save_fname=\"trained_qmix_rnn.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed47f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returns: {'ally_0': Array(1.9999999, dtype=float32), 'ally_1': Array(1.9999999, dtype=float32), 'ally_2': Array(1.9999999, dtype=float32), 'ally_3': Array(1.9999999, dtype=float32), 'ally_4': Array(1.9999999, dtype=float32)}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAHOCAYAAAASUeeYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArDElEQVR4nO3deXRUZZ7/8U+RkEpYUhiIECCBbiMi+xonnDZgCxhWWyEEBETb0/QooCy2Nu0oojZog93DHAYPaI+4oDMstiIiKgxxZE2g1YNAJj0tYoCERUhV1kKS+/sjv1RbpgJVSSrJk3q/zqlzqHufe+/36aflw33qLjbLsiwBAGCwFo1dAAAAdUWYAQCMR5gBAIxHmAEAjEeYAQCMR5gBAIxHmAEAjEeYAQCMR5gBAIxHmCHk/e1vf9PcuXPVq1cvtW7dWpGRkeratauGDh2quXPnasuWLY1dYr3Yt2+f0tPTFR8fr4iICLVu3Vp9+/bV448/rnPnzvm9nylTpshms8lms+nNN98MYsWA/2w8zgqh7J133tE999wjt9ut9u3ba9CgQYqNjdWlS5f0xRdfKC8vT+3bt9eFCxe8thsxYoQ+/fRT7d69WyNGjGic4gOwZs0azZ07V5ZlqU+fPrr55ptVVFSkAwcO6NKlS7r++uv16aefqmfPnlfdz3/9139p6tSpstlssixLb7zxhmbMmNFAvQBqFt7YBQCN5ezZs5o1a5bcbrcWLVqk5557TpGRkV5tDh8+rM2bNzdShfXj7NmzWrBggSzL0vr16zVr1izPusLCQk2ePFkff/yx5s+frx07dlx1P3PmzNHAgQPVqlUr7d27tyHKB/zCNCNC1rZt21RUVKTOnTtr5cqV1YJMkgYPHqzly5c3QnX1Z8+ePbp8+bJ69erlFWSS1LZtWy1ZskSStH///qvuZ/bs2XK5XHr11VcVHs6/g9G0EGYIWWfPnpUkxcbG+r1NRkaGbDabPv30U0nSbbfd5vn9yGazaf369V7tL126pCVLlmjAgAFq27atWrVqpb59++q5555TSUlJtf0//fTTstlsevrpp3Xy5Ende++9iouLU2RkpHr06KGnn35apaWlAfXTV0j70qFDhxrXvf7669q6dasWL16s/v37B3R8oCHwzyuErISEBEnSV199pV27dun222+/5jadOnXSrFmztGPHDp09e1Z33HGHOnXq5FmfmJjo+fOxY8eUmpqq3NxcxcXF6Wc/+5latmypzMxMPfnkk9qyZYsyMjLkcDiqHefEiRMaPHiwwsPDlZKSotLSUu3evVtLly7Vzp07tXPnTr9DKjk5WQ6HQ8eOHdNrr73mdXZWVFSkpUuXSpJ+/etf+9z+9OnTeuSRR9SnTx898cQTfh0TaHAWEKIKCwutLl26WJIsm81mjRgxwnr22WetDz74wDp37txVtx0+fLglydq9e7fP9SUlJdYNN9xgSbL+5V/+xXK73Z51xcXF1rRp0yxJ1v333++13ZIlSyxJliTrzjvvtEpKSjzrcnNzrR49eliSrN/+9rcB9fXdd9+1WrdubUmy+vTpY6WlpVljx461rrvuOuu6666zfv/731sVFRU+t01NTbXCwsKsrKysav1/4403AqoDCBbCDCEtOzvbuuWWWzwB8sPPgAEDrJdeesm6cuVKte2uFWYvvfSSJckaP368z/WFhYXW9ddfb4WHh1sXL170LK8Ks6ioKCsvL6/adu+//74lyYqOjrZKS0sD6uuhQ4c8AfvDz+jRo62MjAyf26xbt85neBJmaGr4zQwh7aabbtKBAwd08OBBPfXUU7rjjjs8v6F98cUXevDBB5WamqrLly8HtN8PPvhAkpSenu5zfZs2bTRkyBBduXJFWVlZ1daPHj3aa/qyyvjx49W+fXu5XC799a9/9buel156ScnJyWrfvr0yMjLkdDqVm5urf//3f9eBAwf085//vNrvfSdPntSiRYt088036+mnn/b7WEBjIMwASUlJSVq6dKnnt7DDhw9r6tSpkqSdO3dq1apVAe3v66+/liTNnDnT6wKRH362b98uSTp//ny17X/yk5/UuO/u3btLkk6dOuVXLXv37tVDDz2kDh066OOPP9bw4cMVHR2trl276qGHHtLatWtVUVGh+fPnq6CgQJJkWZZ++ctfqri4WP/xH/8hu90eQO+BhscFIMCP2Gw2DRo0SG+//bZKSkq0detWvfvuu/rNb37j9z4qKiokSampqerYseNV23br1q1WdVp+Pu+g6oxr7NixPi82mTx5smbNmiWn06msrCyNGjVKTqdT//3f/602bdrot7/9bbVtvvjiC0nS73//e73yyisaMGCA/vVf/7VW/QDqA2EGXMXo0aO1devWak8AuZb4+HhlZ2frgQce0OTJkwM+7okTJ2pc980330iSunbt6te+vv32W0lSdHS0z/Xh4eFq3bq1Ll++rIsXL3qtKyoq8tyG4Et2drays7P9qgMIJqYZEbL8ObOpCoIfB0dERIQk6cqVKz63GzNmjCRp48aNtart448/9vm8xO3bt+u7775T27ZtNXjwYL/21aVLF0nSwYMHfa7/3//9X126dEnSP6Y327VrJ6vyAjGfn+HDh0uS3njjDVmWpYyMjEC7CNQrwgwha82aNZo1a5b27dtXbZ1lWXrnnXe0evVqSfL8flalKtyOHj3qc9+zZ89Wt27dtGnTJj3++OMqLCys1iY/P18vv/yyz+1LS0v14IMPet0gfebMGS1atEiS9M///M9+32dWdWa4b98+rVixwivEz507pwceeECS1KNHDw0ZMsSvfQJNTqNcQwk0AX/60588l6fHxsZao0ePtu655x5r7NixVvfu3T3rZsyYYZWXl3ttu23bNkuSFRERYY0fP9765S9/aT3wwAPW3r17PW2++uorz37atWtnpaSkWPfcc4/1i1/8wurVq5dls9msjh07eu236tL8e++914qJibE6depkpaWlWRMmTPDcJ5acnOx1/5k/fv3rX3v6k5iYaN19993WqFGjrOjoaE99Bw8e9Ht/XJqPpoYwQ8hyuVzWu+++a82bN89KSkqyunbtarVs2dKKioqybrjhBmvatGnWhx9+WOP2L7/8sjVo0CCrVatWnqB49dVXqx3jD3/4g5WcnGy1a9fOatmypRUXF2cNHTrU+s1vfmPt27fPq31VmC1ZssT6+uuvrWnTplkdO3a0IiIirMTEROupp56yiouLa9Xfd99915owYYIVFxfn6WevXr2sBQsWWLm5uQHtizBDU8MrYIAm5Omnn9bSpUu1ZMkS7u0CAsBvZgAA4xFmAADjEWYAAOPxmxkAwHicmQEAjEeYAQCMR5gBAIxHmAEAjEeYAQCMR5gBAIxHmAEAjNfkX85ZUVGhM2fOqG3btrLZbI1dDgCgAVmWpcLCQnXu3FktWtR8/tXkw+zMmTOKj49v7DIAAI0oNzf3qm9Xb/Jh1rZtW0mVHanpte8AgObJ5XIpPj7ekwU1afJhVjW1GB0dTZgBQIi61s9MXAACADAeYQYAMB5hBgAwHmEGADAeYQYAMB5hBgAwHmEGADAeYQYAMB5hBgAwHmEGADAeYQYAMB5hBgAwHmEGADAeYQYAMB5hBgAwHmEGADBeQGF29OhRpaWl6ac//alatWqlDh06KCUlRe+//361tsePH1dqaqratGmjmJgYzZw5U+fPn6+3wgEAqBLQm6ZPnjypwsJCzZo1S507d1ZJSYm2bNmiiRMnau3atZo9e7Yk6dSpU0pJSZHD4dCyZctUVFSklStX6siRI8rMzFRERERQOgMACE02y7KsuuygvLxcgwcPVllZmbKzsyVJDz30kNavX6/s7GwlJCRIknbu3KlRo0Z5hZ4/XC6XHA6HnE6noqOj61IqAMAw/mZAnX8zCwsLU3x8vAoKCjzLtmzZovHjx3uCTJJGjhypHj16aOPGjXU9JAAAXgKaZqxSXFys0tJSOZ1Obd26VR9++KHS09MlSadPn9a5c+c0ZMiQatslJSVp+/btV9232+2W2+32fHe5XLUpEQAQQmoVZosWLdLatWslSS1atNDdd9+t1atXS5Ly8vIkSXFxcdW2i4uL08WLF+V2u2W3233ue/ny5Vq6dGltygIAhKhaTTPOnz9fn3zyiV577TWNGTNG5eXlunz5siSptLRUknyGVWRkpFcbXxYvXiyn0+n55Obm1qZEAEAIqdWZWc+ePdWzZ09J0r333qvRo0drwoQJOnjwoKKioiTJa6qwSllZmSR52vhit9trPGsDAMCXerlpevLkycrKylJOTo5nerFquvGH8vLyFBMTQ1gBAOpVvYRZ1bSh0+lUly5dFBsbq0OHDlVrl5mZqQEDBtTHIQEA8AgozM6dO1dt2ffff6/XX39dUVFR6tWrlyRp0qRJ2rZtm9fvXbt27VJOTo7S0tLqWDIAAN4Cumn6rrvuksvlUkpKirp06aL8/Hxt2LBB2dnZevHFF7Vw4UJJUm5urgYOHKh27drpkUceUVFRkVasWKGuXbsqKysroGlGbpoGgNDlbwYEFGb/+Z//qT//+c86cuSIvvvuO7Vt21aDBw/WvHnzNHHiRK+2R48e1cKFC7Vnzx5FRERo3LhxevHFF9WxY8egdAQA0PwEJcwaA2EGAKGrwR5nBQBAYyPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxiPMAADGI8wAAMYjzAAAxgsozLKysjR37lz17t1brVu3VkJCgqZMmaKcnByvdvfdd59sNlu1T8+ePeu1eAAAJCk8kMYvvPCC9u7dq7S0NPXr10/5+flavXq1Bg0apAMHDqhPnz6etna7Xa+88orX9g6Ho36qBgDgBwIKs4ULF+qtt95SRESEZ1l6err69u2r559/Xm+++eY/dhwerhkzZtRfpQAA1CCgacZhw4Z5BZkk3Xjjjerdu7eOHz9erX15eblcLlfdKgQA4BrqfAGIZVk6e/asOnTo4LW8pKRE0dHRcjgciomJ0Zw5c1RUVHTN/bndbrlcLq8PAABXE9A0oy8bNmzQ6dOn9cwzz3iWxcXF6bHHHtOgQYNUUVGhHTt2aM2aNfryyy+VkZGh8PCaD7t8+XItXbq0rmUBAEKIzbIsq7YbZ2dn65ZbblHv3r312WefKSwsrMa2y5Yt0xNPPKG3335bU6dOrbGd2+2W2+32fHe5XIqPj5fT6VR0dHRtSwUAGMjlcsnhcFwzA2o9zZifn69x48bJ4XBo8+bNVw0ySVqwYIFatGihnTt3XrWd3W5XdHS01wcAgKup1TSj0+nUmDFjVFBQoM8++0ydO3e+5jZRUVFq3769Ll68WJtDAgBQo4DDrKysTBMmTFBOTo527typXr16+bVdYWGhLly4oNjY2ICLBADgagIKs/LycqWnp2v//v167733lJycXK1NWVmZvv/+e7Vt29Zr+bPPPivLspSamlq3igEA+JGAwmzRokXaunWrJkyYoIsXL3rdJC1JM2bMUH5+vgYOHKhp06Z5Hl/10Ucfafv27UpNTdWdd95Zf9UDAKAAr2YcMWKEPv300xrXW5algoICzZs3TwcOHNCZM2dUXl6uxMRETZ8+XY8++qhatmwZUIH+XskCAGh+/M2AOl2a3xAIMwAIXUG/NB8AgKaCMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABgvoDDLysrS3Llz1bt3b7Vu3VoJCQmaMmWKcnJyqrU9fvy4UlNT1aZNG8XExGjmzJk6f/58vRUOAECV8EAav/DCC9q7d6/S0tLUr18/5efna/Xq1Ro0aJAOHDigPn36SJJOnTqllJQUORwOLVu2TEVFRVq5cqWOHDmizMxMRUREBKUzAIDQFFCYLVy4UG+99ZZXGKWnp6tv3756/vnn9eabb0qSli1bpuLiYh0+fFgJCQmSpKSkJI0aNUrr16/X7Nmz67ELAIBQZ7Msy6rrTgYPHixJOnz4sCSpY8eOGj58uDZu3OjV7qabblJ8fLx27tzp975dLpccDoecTqeio6PrWioAwCD+ZkCdLwCxLEtnz55Vhw4dJEmnT5/WuXPnNGTIkGptk5KS9Pnnn9f1kAAAeKlzmG3YsEGnT59Wenq6JCkvL0+SFBcXV61tXFycLl68KLfbXeP+3G63XC6X1wcAgKupU5hlZ2drzpw5Sk5O1qxZsyRJpaWlkiS73V6tfWRkpFcbX5YvXy6Hw+H5xMfH16VEAEAIqHWY5efna9y4cXI4HNq8ebPCwsIkSVFRUZLk8+yrrKzMq40vixcvltPp9Hxyc3NrWyIAIEQEdDVjFafTqTFjxqigoECfffaZOnfu7FlXNb1YNd34Q3l5eYqJifF51lbFbrdfdT0AAD8WcJiVlZVpwoQJysnJ0c6dO9WrVy+v9V26dFFsbKwOHTpUbdvMzEwNGDCg1sUCAOBLQNOM5eXlSk9P1/79+7Vp0yYlJyf7bDdp0iRt27bNa4pw165dysnJUVpaWt0qBgDgRwK6z2z+/PlatWqVJkyYoClTplRbP2PGDElSbm6uBg4cqHbt2umRRx5RUVGRVqxYoa5duyorKyugaUTuMwOA0OVvBgQUZiNGjNCnn35a4/of7uro0aNauHCh9uzZo4iICI0bN04vvviiOnbs6O/hJBFmABDKghJmjYEwA4DQ1WBPAAEAoLERZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA44U3dgEAmh/Lkg4dko4elcrLpW7dpNtuk8LCGrsyNFeEGYB6Y1nSm29Kf/iD9NVX3uu6dJHmzZMWLpRatmyc+tB8Mc0IoF5YljR/vnTvvdKxY9XXnz4t/e530pgxUllZg5eHZo4wA1AvVq2S/u3fKv9cUeG7TUWFtHu39KtfNVxdCA2EGYA6u3xZeu45/9pWVEgbNkgnTgS3JoQWwgxAnf3lL9J331X++Ve/qjz72r1bysiQ3G6pVSvv9i1aSGvXNniZaMa4AARAne3fX3lRx/ffSy+/XPmRpDlzpP/5H6mkxLt9ebm0Z0/D14nmizADUGelpdWXde8uTZ8uDR/ue5vi4qCWhBDDNCOAOouNrbya8YfWrpXmzq08W/uxFi2kTp0apjaEBsIMQJ2lp0tXrvzj+4MPSllZ0l//6rt9RYV0zz0NUxtCA9OMAOqsb19p2DDp4EGpa1dp5syapxdtNsnhkNLSGrZGNG+cmQGoF2vWSHa79PjjldOOH3/8j6sa4+O92778shQZ2Th1onnizAxAvejfX9q1Sxo3rvIqRsn7d7QWLSqfzbh+vTR5cqOUiGaMMzMA9eaf/kn65pvKs7TevSsv12/RovLMbOlS6dtv+a0MwWGzrB9fg9S0uFwuORwOOZ1ORUdHN3Y5AAJQ9beLzda4dcBc/mYA04wAgqamEPvmG2ndOunw4cqHDsfHV140MmpU5ZkcECjCDECDKS6WHnhA2rixMrTKyyuXh4VVPq+xe3fprbek5ORGLRMG4t9AABpEaal0++3S5s2V049VQSb948/ffiuNGCF99lmjlAiDEWYAGsRTT1XeSP3DEPuxiorKm6/vuot3niEwhBmAoCspqXy8VU3vOfuhiorKJ/Bv2hT8utB8EGYAgu4vf5EKCyv/7O8rYtata/AyYTAuAAEQdCdOSOHhlVOI/rwipqJC+vvfG75OmIswAxB0vi7Rv9YrYrg3DYFgmhFA0N10k/dT9aWrvyImLEy6+eaGqQ3NA2EGIOgmTpTat//H92u9Iqa8vLIN4C/CDEDQRURIDz9cOXXYrVvl0z6WLvXdNiys8jUyEyc2bI0wW8BhVlRUpCVLlig1NVUxMTGy2Wxav359tXb33XefbDZbtU/Pnj3ro24Ahvnd76SxY6/+ipiwMKl1a2n79sqHFAP+CvgCkAsXLuiZZ55RQkKC+vfvr4yMjBrb2u12vfLKK17LHA5HwEUCMF94eOUl+osXSwsXVl6SHxZW+TSQqos9kpKkP/+Z38sQuIDDLC4uTnl5eerUqZMOHTqkoUOH1rzz8HDNmDGjTgUCaD5atpRWrpSefFJ6/XXp88+ly5eluLjKqcd+/Rq7Qpgq4DCz2+3q1KmT3+3Ly8tVXFzM61sAeDgc0rx5jV0FmpOgXgBSUlKi6OhoORwOxcTEaM6cOSoqKgrmIQEAIShoN03HxcXpscce06BBg1RRUaEdO3ZozZo1+vLLL5WRkaHwcN+Hdrvdcrvdnu8ulytYJQIAmomghdny5cu9vk+dOlU9evTQE088oc2bN2vq1Kk1bre0pmt2AQDwoUHvM1uwYIFatGihnTt31thm8eLFcjqdnk9ubm4DVggAMFGDPpsxKipK7du318WLF2tsY7fbZbfbG7AqAIDpGvTMrLCwUBcuXFBsbGxDHhYA0MwFJczKyspUWPXyoh949tlnZVmWUlNTg3FYAECIqtU04+rVq1VQUKAzZ85Ikt5//32dOnVKkjRv3jxdunRJAwcO1LRp0zyPr/roo4+0fft2paam6s4776yn8gEAkGyWZVmBbtS9e3edPHnS57oTJ06oXbt2mjdvng4cOKAzZ86ovLxciYmJmj59uh599FG1DOChay6XSw6HQ06nkxuvASDE+JsBtQqzhkSYAUDo8jcDeAUMAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHgBh1lRUZGWLFmi1NRUxcTEyGazaf369T7bHj9+XKmpqWrTpo1iYmI0c+ZMnT9/vq41AwDgJTzQDS5cuKBnnnlGCQkJ6t+/vzIyMny2O3XqlFJSUuRwOLRs2TIVFRVp5cqVOnLkiDIzMxUREVHX2gEAkFSLMIuLi1NeXp46deqkQ4cOaejQoT7bLVu2TMXFxTp8+LASEhIkSUlJSRo1apTWr1+v2bNn161yAAD+v4CnGe12uzp16nTNdlu2bNH48eM9QSZJI0eOVI8ePbRx48ZADwsAQI0CPjPzx+nTp3Xu3DkNGTKk2rqkpCRt3769xm3dbrfcbrfnu8vlCkaJAIBmJChXM+bl5UmqnJL8sbi4OF28eNErsH5o+fLlcjgcnk98fHwwSgQANCNBCbPS0lJJlVOSPxYZGenV5scWL14sp9Pp+eTm5gajRABAMxKUacaoqChJ8nn2VVZW5tXmx+x2u88QBACgJkE5M6uaXqyabvyhvLw8xcTEEFgAgHoTlDDr0qWLYmNjdejQoWrrMjMzNWDAgGAcFgAQooL2OKtJkyZp27ZtXr957dq1Szk5OUpLSwvWYQEAIahWv5mtXr1aBQUFOnPmjCTp/fff16lTpyRJ8+bNk8Ph0O9+9ztt2rRJt912mx555BEVFRVpxYoV6tu3r+6///766wEAIOTZLMuyAt2oe/fuOnnypM91J06cUPfu3SVJR48e1cKFC7Vnzx5FRERo3LhxevHFF9WxY0e/j+VyueRwOOR0OhUdHR1oqQAAg/mbAbUKs4ZEmAFA6PI3A3gFDADAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeIQZAMB4hBkAwHiEGQDAeEELs4yMDNlsNp+fAwcOBOuwAIAQFB7sAzz88MMaOnSo17LExMRgHxYAEEKCHma33nqrJk+eHOzDAABCWIP8ZlZYWKgrV640xKEAACEo6GF2//33Kzo6WpGRkbrtttt06NChq7Z3u91yuVxeHwAAriZoYRYREaFJkyZp1apVeu+99/Tcc8/pyJEjuvXWW/X555/XuN3y5cvlcDg8n/j4+GCVCABoJmyWZVkNdbD/+7//U79+/ZSSkqIdO3b4bON2u+V2uz3fXS6X4uPj5XQ6FR0d3VClAgCaAJfLJYfDcc0MCPoFID+UmJioO++8U++8847Ky8sVFhZWrY3dbpfdbm/IsgAAhmvwm6bj4+N1+fJlFRcXN/ShAQDNVIOH2ddff63IyEi1adOmoQ8NAGimghZm58+fr7bsyy+/1NatWzV69Gi1aMGTtAAA9SNov5mlp6crKipKw4YN0/XXX69jx45p3bp1atWqlZ5//vlgHRYAEIKCFma/+MUvtGHDBv3xj3+Uy+VSbGys7r77bi1ZsoTHWQEA6lWDXppfG/5elgkAaH78zQB+uAIAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGI8wAwAYjzADABiPMAMAGC+oYeZ2u/X444+rc+fOioqK0i233KJPPvkkmIcEAISgoIbZfffdpz/+8Y+aPn26Vq1apbCwMI0dO1Z79uwJ5mEBACHGZlmWFYwdZ2Zm6pZbbtGKFSv06KOPSpLKysrUp08fXX/99dq3b59f+3G5XHI4HHI6nYqOjg5GqQCAJsrfDAjamdnmzZsVFham2bNne5ZFRkbqgQce0P79+5WbmxusQwMAQkx4sHb8+eefq0ePHtWSNCkpSZL0xRdfKD4+vtp2brdbbrfb893pdEqqTGcAQGip+rv/WpOIQQuzvLw8xcXFVVtetezMmTM+t1u+fLmWLl1abbmv4AMAhIbCwkI5HI4a1wctzEpLS2W326stj4yM9Kz3ZfHixVq4cKHne0FBgbp166Zvv/32qh1pLlwul+Lj45WbmxsSvxHS3+Yt1PorhV6fg91fy7JUWFiozp07X7Vd0MIsKirKa7qwSllZmWe9L3a73WcIOhyOkPg/RpXo6Gj624zR3+Yv1PoczP76cyITtAtA4uLilJeXV2151bJrpSwAAP4KWpgNGDBAOTk51S7cOHjwoGc9AAD1IWhhNnnyZJWXl2vdunWeZW63W6+++qpuueUWvy/osNvtWrJkic+px+aI/jZv9Lf5C7U+N5X+Bu2maUmaMmWK/vKXv2jBggVKTEzUa6+9pszMTO3atUspKSnBOiwAIMQENczKysr05JNP6s0339SlS5fUr18/Pfvss7rjjjuCdUgAQAgKapgBANAQeAUMAMB4hBkAwHiEGQDAeE02zELpxZ4ZGRmy2Ww+PwcOHGjs8uqkqKhIS5YsUWpqqmJiYmSz2bR+/XqfbY8fP67U1FS1adNGMTExmjlzps6fP9+wBdcDf/t83333+Rzznj17NnzRtZSVlaW5c+eqd+/eat26tRISEjRlyhTl5ORUa9scxtff/jaHsa1y9OhRpaWl6ac//alatWqlDh06KCUlRe+//361to05xkF7nFVd3Xfffdq8ebPmz5+vG2+8UevXr9fYsWO1e/du/exnP2vs8oLi4Ycf1tChQ72WJSYmNlI19ePChQt65plnlJCQoP79+ysjI8Nnu1OnTiklJUUOh0PLli1TUVGRVq5cqSNHjigzM1MRERENW3gd+NtnqfIenVdeecVrmUnPIH3hhRe0d+9epaWlqV+/fsrPz9fq1as1aNAgHThwQH369JHUfMbX3/5K5o9tlZMnT6qwsFCzZs1S586dVVJSoi1btmjixIlau3at5zVfjT7GVhN08OBBS5K1YsUKz7LS0lLrhhtusJKTkxuxsuDYvXu3JcnatGlTY5dS78rKyqy8vDzLsiwrKyvLkmS9+uqr1do9+OCDVlRUlHXy5EnPsk8++cSSZK1du7ahyq0X/vZ51qxZVuvWrRu4uvq1d+9ey+12ey3Lycmx7Ha7NX36dM+y5jK+/va3OYzt1Vy5csXq37+/ddNNN3mWNfYYN8lpxlB+sWdhYaGuXLnS2GXUG7vdrk6dOl2z3ZYtWzR+/HglJCR4lo0cOVI9evTQxo0bg1livfO3z1XKy8uNfV/fsGHDqv2L+8Ybb1Tv3r11/Phxz7LmMr7+9reKyWN7NWFhYYqPj1dBQYFnWWOPcZMMM39e7Nkc3X///YqOjlZkZKRuu+02HTp0qLFLahCnT5/WuXPnNGTIkGrrkpKS9PnnnzdCVQ2jpKRE0dHRcjgciomJ0Zw5c1RUVNTYZdWJZVk6e/asOnToIKn5j++P+1uluY1tcXGxLly4oL///e/605/+pA8//FC33367pKYxxk3yN7PavtjTVBEREZo0aZLGjh2rDh066NixY1q5cqVuvfVW7du3TwMHDmzsEoOq6k0KNY35xYsX5Xa7G/3Zb/UtLi5Ojz32mAYNGqSKigrt2LFDa9as0ZdffqmMjAyFhzfJ/zyvacOGDTp9+rSeeeYZSc1/fH/cX6l5ju2iRYu0du1aSVKLFi109913a/Xq1ZKaxhg3yf9Fa/tiT1MNGzZMw4YN83yfOHGiJk+erH79+mnx4sXasWNHI1YXfFXjea0xN/Uvu5osX77c6/vUqVPVo0cPPfHEE9q8ebOmTp3aSJXVXnZ2tubMmaPk5GTNmjVLUvMeX1/9lZrn2M6fP1+TJ0/WmTNntHHjRpWXl+vy5cuSmsYYN8lpxtq+2LM5SUxM1J133qndu3ervLy8scsJqqrxDPUxl6QFCxaoRYsW2rlzZ2OXErD8/HyNGzdODofD87u31HzHt6b+1sTksZWknj17auTIkbr33nu1bds2FRUVacKECbIsq0mMcZMMM17sWSk+Pl6XL19WcXFxY5cSVFVTEzWNeUxMjJH/aq+NqKgotW/fXhcvXmzsUgLidDo1ZswYFRQUaMeOHV7/jTbH8b1af2ti6tjWZPLkycrKylJOTk6TGOMmGWa82LPS119/rcjISLVp06axSwmqLl26KDY21ucFL5mZmSEz3lLl1awXLlxQbGxsY5fit7KyMk2YMEE5OTnatm2bevXq5bW+uY3vtfpbExPH9mqqphadTmeTGOMmGWb19WJPU/i6Q/7LL7/U1q1bNXr0aLVo0SSHqV5NmjRJ27Zt87rtYteuXcrJyVFaWlojVhYcZWVlKiwsrLb82WeflWVZSk1NbYSqAldeXq709HTt379fmzZtUnJyss92zWV8/elvcxnbKufOnau27Pvvv9frr7+uqKgoT5g39hg32VfAhNKLPX/+858rKipKw4YN0/XXX69jx45p3bp1atmypfbv36+bb765sUusk9WrV6ugoEBnzpzRSy+9pLvvvttzhea8efPkcDiUm5urgQMHql27dnrkkUdUVFSkFStWqGvXrsrKyjJuGupafb506ZIGDhyoadOmeR5x9NFHH2n79u1KTU3VBx98YMQ/YubPn69Vq1ZpwoQJmjJlSrX1M2bMkKRmM77+9Pebb75pFmNb5a677pLL5VJKSoq6dOmi/Px8bdiwQdnZ2XrxxRe1cOFCSU1gjIN+W3YtlZaWWo8++qjVqVMny263W0OHDrV27NjR2GUFxapVq6ykpCQrJibGCg8Pt+Li4qwZM2ZYf/vb3xq7tHrRrVs3S5LPz4kTJzztvvrqK2v06NFWq1atrHbt2lnTp0+38vPzG6/wOrhWny9dumTNmDHDSkxMtFq1amXZ7Xard+/e1rJly6zLly83dvl+Gz58eI39/PFfL81hfP3pb3MZ2ypvv/22NXLkSKtjx45WeHi4dd1111kjR4603nvvvWptG3OMm+yZGQAA/jLnXBcAgBoQZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADjEWYAAOMRZgAA4xFmAADj/T/6kXHPrAe6wwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario = map_name_to_scenario(config[\"MAP_NAME\"])\n",
    "#env = HeuristicEnemySMAX(scenario=scenario, **config[\"ENV_KWARGS\"])\n",
    "#env = SMAXLogWrapper(env)\n",
    "env = wrapped_env\n",
    "\n",
    "visualize_recurrent_policy(my_params['agent'], env, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4a09329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from flax.serialization import to_state_dict\n",
    "from flax.serialization import from_state_dict\n",
    "\n",
    "\n",
    "def save_repertoire(repertoire: MapElitesRepertoire, filepath: str):\n",
    "    # Convert the object to a savable dictionary\n",
    "    state_dict = {\n",
    "        \"genotypes\": to_state_dict(repertoire.genotypes),\n",
    "        \"fitnesses\": repertoire.fitnesses,\n",
    "        \"descriptors\": repertoire.descriptors,\n",
    "        \"centroids\": repertoire.centroids,\n",
    "        \"extra_scores\": to_state_dict(repertoire.extra_scores),\n",
    "        \"keys_extra_scores\": repertoire.keys_extra_scores,\n",
    "    }\n",
    "    \n",
    "    with open(filepath, \"wb\") as f:\n",
    "        pickle.dump(state_dict, f)\n",
    "\n",
    "def load_repertoire(filepath: str) -> MapElitesRepertoire:\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        state_dict = pickle.load(f)\n",
    "\n",
    "    # Rebuild the object using the saved state\n",
    "    genotypes = from_state_dict(state_dict[\"genotypes\"], state_dict[\"genotypes\"])\n",
    "    extra_scores = from_state_dict(state_dict[\"extra_scores\"], state_dict[\"extra_scores\"])\n",
    "\n",
    "    return MapElitesRepertoire(\n",
    "        genotypes=genotypes,\n",
    "        fitnesses=state_dict[\"fitnesses\"],\n",
    "        descriptors=state_dict[\"descriptors\"],\n",
    "        centroids=state_dict[\"centroids\"],\n",
    "        extra_scores=extra_scores,\n",
    "        keys_extra_scores=state_dict[\"keys_extra_scores\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb2c9771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved reportoire\n"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "\n",
    "#os.makedirs(\"/vol/bitbucket/eww24/Masters_project/repertoire\", exist_ok=True)\n",
    "\n",
    "filepath = \"/vol/bitbucket/eww24/Masters_project/repertoire/qmix_transfer_repertoire_2s3z.pkl\"\n",
    "save_repertoire(repertoire, filepath)\n",
    "print(\"saved reportoire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "895bf9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repertoire loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "loaded_repertoire = load_repertoire(filepath)\n",
    "print(\"Repertoire loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2adae51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitness in the repertoire: 2.59\n",
      " Descriptor of the best individual in the repertoire: [0.37269878 0.42373762]\n",
      " Index in the repertoire of this individual: 43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_idx = jnp.argmax(loaded_repertoire.fitnesses)\n",
    "best_fitness = jnp.max(loaded_repertoire.fitnesses)\n",
    "best_descriptor = loaded_repertoire.descriptors[best_idx]\n",
    "print(\n",
    "    f\"Best fitness in the repertoire: {best_fitness:.2f}\\n\",\n",
    "    f\"Descriptor of the best individual in the repertoire: {best_descriptor}\\n\",\n",
    "    f\"Index in the repertoire of this individual: {best_idx}\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaxMARL (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
